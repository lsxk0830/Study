# 第五章 3D模型与动画

## 美术资源的规范

### 如何确定美术资源规范的大小

#### 1， 根据运用的场景而不同。

像汤姆猫这种强调单一主角的场景，主要资源全部投入到主角一个人的，对主角进行精细化的雕琢是很有必要的。

这种场景的人物模型做到1万面也不为过，主角的骨骼也可以做得很精细，骨骼数量可以达到50-100个，贴图大小也可以在512 x 512左右，如果需要 1024 x 1024 的贴图我觉得问题也不是很大，只是如果需求中有换装时，需要考虑下包体大小。

第三人称视角的RPG游戏，由于视角与角色的距离有限，同时看到的场景范围有限，可以使用动态场景地图加载的方式控制内存使用量，主要是同屏单位数量会决定模型面数。如果人模模型面数控制在3000-4000面，骨骼数量控制在30个左右，至于建筑模型面数因为大小差异太多无法统一，不过我们可以用整体面数统计法来规范资源。贴图可以控制在 256 x 256 及以下，比如主贴图为 256 x 256，副贴图为 128 x 128。

总的来说美术资源规范就是限制模型的面数，限制贴图的大小，限制一个材质球的贴图张数，限制一个人物身上的材质球数量，限制骨骼数量，具体数字是多少需要因项目而定，不过这里可以给一个大多数项目使用的标准，3000面左右的模型，不超过256大小的贴图，一个材质球内至多3张贴图，一个人物不超过2个材质球使用量，30个左右的骨骼数量。

如果做的是《塞尔达传说》，《魔兽世界》这种超大型的游戏场景，可以从高空俯瞰整个场景的这种情况，渲染压力比较大，除了制定美术规范外，我们也需要借用用其他方法比如LOD，它能把渲染压力和渲染质量平衡的很好。后面章节中会具体介绍LOD在优化中的运用。

#### 2， 使用反推计算来得出规范。

对于一些模型物体大小差异比较大的，无法统一模型与贴图面数的，我们可以用全场景总面数来控制。

我们可以用这种方式来举个例子，假如我们在场景中同屏面熟控制在6万面左右，然后再开始部署，地形模型总共3万面左右，数量多的小件模型在100面以下平均50面，中型建筑在500-1500面平均下1000面好了，大型建筑在2000-5000面以下平均3000面。这样的情况下，除了地形模型剩下的还有3万面，小件模型可以放100件也就是5千面，中型建筑可以放10件1万面，大型建筑5件，1万面，总共3万面差不多满足了6万面左右的需求。

贴图大小也可以同样按照这种方法进行规范，假如我们设定总体内存中贴图的大小不得超过100MB，倒推出去平均有多少种小件模型在场景内，平均有多少种中型模型在场景内，平均有多少种大型建筑在场景内。如果小件平均有30种，中型模型有20种，大型模型有10种，那么小件每个贴图不得超过0.3MB，中型模型每个贴图不得超过1MB，大型模型每个贴图不得超过2MB。

除了占用内存的大小，也可以用总张数和size大小来进行规范。例如我们设定场景的总体贴图大小设置为不得超过 20张 1024 x 1024，那么在小件平均30种，中型模型平均20种，大型模型平均10种的情况下，我们就可以规定为小件贴图大小在128 x 128以下，中型模型贴图大小在256 x 256以下，大型模型贴图大小在 512 x 512 以下。

用反推的计算方法来计算和规范，一整个地形场景的模型和贴图的规范就会相对容易些，对于整体的内存和计算量的把控会加强很多。

#### 3， 规范的自动检测

无论什么方法，都敌不过实际测试。如果可以在项目前加入实际的压力测试环节，或者在项目进行中加入渲染压力测试的环境，会更有利于对美术资源的规范，专门有人做渲染压力的实际测试是有必要的。

专门派遣一个人来完成这件事情，做好前期的计划和测试是对项目负责的做法，是对项目有更好前程的安全保障。但仍然有许多项目和公司，由于人才缺乏成本高企等问题下，没有派人去做各种渲染测试，只是一味的求快求速度是有问题的。不过现实仍然打败了大多数人和项目，更多时候也是无奈的选择，有时我们只能边做边测，遇到具体问题寻找自己的答案。

只是人工去寻找美术资源规范问题仍然会有很多遗漏，不能形成系统化的流程与规范，导致大家都是有一枪打一枪，发现就修一个，无法确定是否有遗漏，以及完全也不知道什么时候有人一不小心又提交了不符合的资源。

因此我们要建立自动规范的检测程序，这些测试程序应该设定为每个2-3小时运行一次，运行后提醒我们有多少资源存在不规范的情况，分别是哪些资源罗列出来，甚至可以细化到是最近一次谁提交的。

## 合并3D模型

### Animation 和 Animator的选择。

Unity3D引擎已经不再对Animation动画系统进行维护。但不维护也并不是说一定不能用，很多旧的项目任然在用，只是在老版本中使用。新动画系统 Mecanim 中有了新的动画组件 Animator

为什么要用新系统 Mecanim 呢？原因如下几个方面：

1. Mecanim 系统使用多线程计算，比Animation的单线程性能要高出一点。
2. Unity3D本身就自带对 Mecanim 系统的优化选项“Optimize GameObject”。开启该选项，Animator.Update和MeshSkinning.Update的CPU占用均会一定程度的降低。
3. Animator的功能更加多，Retargeting功能让不同角色使用同一套动画资源，比如游戏中的角色的空闲动画，就可以使用同一个动画文件省去了动画资源内存的开销。Animator状态机的接入，让动画可以在不同的条件下可以自动的切换。

### Unity3D 3D模型中SubMesh的意义

在模型中可以有很多网格，一个模型可以由很多个网格构成。因此在Unity3D中一个Mesh网格的构成可以由多个子Mesh组成也就是SubMesh，即一个Mesh里可以有多个SubMesh。

引擎在渲染的时候，每个SubMesh都需要对应一个Material材质球来匹配做渲染，说白了一个SubMesh本身就是普通的模型有很多个三角形构成它也需要材质球支持以达成渲染。在美术人员制作3D模型过程中，可以将SubMesh拆分成独立的Mesh，也可以并成多个子模型即SubMesh。

这里可能大家有个疑问，为什么美术人员在制作3D模型时不把网格都编成一个而要制作成多个SubMesh？这是有原因：

一种情况是，3D模型制作人员在制作模型的时候，希望一个模型中一部分Mesh用一种材质球来表现效果，另一部分Mesh则用另一种材质球来表现效果，这时就需要将模型拆分开来。因为一个Mesh只能对应一个材质球做渲染，一个材质球只能表现一种效果，当他们需要表现两种完全不同的效果时就需要拆分。

第二种情况是，模型中的某部分的贴图，在众多模型中共同使用的频率比较高，为了不重复制作以及减少重复劳动，那么就会让原本可以整体的模型单独拆分出来一部分公共材质的部分让它们都使用同一个材质球。

第三种情况是，在制作动画时，由于动画过于复杂导致如果使用同一个模型去表现的话，骨骼数量就会成倍增加。为了能更好的表现动画，也为了能更节省骨骼的使用量，拆分出一部分模型让他们单独成为模型动画的一部分。

以上三种情况都是我们在制作模型过程中需要着重考虑的问题，通常情况下都会用拆分模型的方式来解决这些问题。

其实SubMesh有诸多好处，与没有SubMesh的Mesh相比，拥有多个SubMesh一样可以有动画，另外它还能针对不同部分的Mesh选择有个性化的材质球来表现效果，从功能上来看比单个Mesh要灵活的多。但它也有些许缺点，由于每个SubMesh都多出了材质球，导致SubMesh越多，增加的Drawcall也越多。Mesh中存在多个SubMesh，在动作和拆分材质球渲染上确实有很好的优势，但无法与其他Mesh合并，导致优化的一个重要环节被阻断。

SubMesh虽然功能很强大，但对性能的开销也需要注意，需要我们慎重使用。有时我们也可以选择用完全拆分Mesh为其他Mesh的形式来代替SubMesh，这样在合并Mesh时就有更多的选择了。下面我们就来深入浅出的聊聊合并模型的方法和途径。

### 动态合并3D模型。

每个3D物体都需要有一个材质球支持，导致每个模型都会产生一个Drawcall（渲染管线的调用），众多的3D模型会产生很多Drawcall，CPU在等待渲染GPU在忙于处理Drawcall，使得帧率下降画面卡顿感强烈。

#### 动态批处理

动态批处理即意味着随时都在做的模型合并批量处理，当我们把 Dynamic Batch 动态批处理开启时，Unity3D可以自动批处理场景中某些物体成为同一个Drawcall，如果是他们使用的是同一个材质球并且满足一些条件的话动态批处理会自动完成的，我们不需要增加额外的操作。

其中需要满足的动态批处理的条件是，

```
1，动态批处理的物体的顶点数目要在一定范围之内，动态批处理只能应用在少于900个顶点的Mesh中。

	如果你的Shader使用顶点坐标，法线，单独的UV，那么只能动态批处理300个顶点内的网格，

	如果你的Shader使用顶点坐标，法线，UV0，UV1和切线，则只能有180个顶点了。

2，两个物体的缩放比例一定是相同，假如两个物体不在同一个缩放单位上，它们将不会进行动态批处理（例如物体A的缩放比例是(1,1,1)，物体B的缩放比例是是(1,1,2)，他们的缩放比例不同则不会被合并处理，除非A的缩放比例改为(1,1,2)，或者B的缩放比例改为(1,1,1)）

3，使用相同的材质球的模型才会被合并，使用不同的材质球是不会被动态批处理的，即使他们模型是同一个或者看起来像是同一个。

4，多管线(Pipeline)Shader会中断动态批处理。

	很多Unity3D里的Shader支持多个灯光的前置渲染增加了多个渲染通道，这些多个通道的材质球是无法用于动态批处理渲染的。

	Legacy Deferred(灯光前置通道)传统延迟渲染路径已经被动态处理关闭，因为它必须绘制物体两次。

	所有多个pass的Shader增加了渲染管道，不会被动态批处理。
```

**动态批处理的条件是很苛刻的，在项目中很多模型是不符合动态批处理的**。另外动态批处理要消耗CPU转换所有物体的顶点到世界空间的操作，所以它唯一的优势是如果它的工作能让Drawcall变少。

最后我们需要理解一味的减少Drawcall不是万能，它的资源需求取决于很多因素，主要被图形API使用。例如一个控制台或流行的API像Apple Metal这样的，Drawcall的开销会普遍很低，因此动态批处理时常在优化方面的优势并不是很大。

#### 静态批处理

静态批处理允许引擎在离线的情况下去做模型合并的批处理以降低Drawcall，无论模型多大只要使用同一个材质球都会被静态批处理优化。他通常比动态批处理有用（因为它不需要实时转换顶点来消耗CPU），但也消耗了更多的内存。

为了让静态批处理起作用，我们需要将物体置为静态不同的，即我们需要去确认指定的物体是否是静态的不能动，不能移动、不能旋转或者缩放。因此我们需要给这物体在面板上标记一个静态的标记以确定性的告诉Unity3D引擎，此物体是不能动不能缩放的，可以对该物体做静态批处理的预处理。

**使用静态批处理需要增加额外的内存来存储合并的模型。在静态批处理下如果一些物体在静态批处理前共用一个模型，那么Unity3D会复制每个物体的模型以用来合并，在Editor里或者在实时运行状态下都会做这个操作。**这可能不总是有益的，因为这样做会带来大量的内存增加，因此有时我们需要减少对物体的静态处理来减少内存的使用量，虽然这样做会牺牲了渲染性能，不过我觉得内存换CPU是值得的，但是如果100兆的内存来换1%的CPU效率任然是不划算的，所以我们还是应该谨慎。

静态批处理的具体做法是，将所有静态物体放入世界空间，并且把他们以材质球为分类标准分别合并起来，并构建一个大的顶点集合和索引缓存，所有可见的同类物体就会被同一批的Drawcall处理，这就会让一系列的Drawcall减少从而实现优化的效果。

**技术上来说静态批处理并没有节省3D API Drawcall数量，但他节省了他们之间的状态改变导致的消耗。**在大多数平台上，批处理被限制在6万4千个顶点和6万4千个索引(OpenGLES上为48k，macOS上为32k)，所以倘若我们超过这个数量需要取消一些静态批处理对象。

现在我们知道动态批处理 和 静态批处理是什么了，我们来做个简单总结：

```
	1，	动态批处理条件是，使用同一材质球，顶点数量不超过900个，有法线的不超过300个顶点，有两个UV的不超过150个顶点，缩放大小要一致，Shader不能有多通道。

	2，	静态批处理条件是，必须是点上静态标记的物体，不能动，不能旋转，不能缩放，不能有动画。
```

动态批处理的规则是极其严格的，在具体的场景中能用到的模型是相对简单的，它对顶点限制太紧，而且缩放比例还要相同，渲染管道也只能有一个。

静态批处理的使用范围更广一些，但要求物体是静态不能移动，旋转，缩放。这个限制太固定，用到的地方只有完全不动的场景中的固定物体。

动态批处理限制太大，静态批处理又不满足我们的需求，所以有时我们也只能自己手动合并模型来替代Unity3D的批处理。也只有用自己程序合并的模型才能体现自定义动态批处理的用途。比如构建场景后的动态建筑，动态小件合并，人物模型更换装备，发型，首饰，衣裤等导致多个模型挂载的需要合并模型来优化渲染。

### 自己来编写合并3D模型的程序

为了编写自己的合并3D模型程序需要调用些Unity3D的API，我们来了解下Unity3D的几个类和接口：

```
	Mesh类有个CombineMeshes的接口提供了合并3D模型的入口。

	MeshFilter类，是承载Mesh数据的类。

	MeshRenderer类，是绘制Mesh网格的类。
```

在使用这几个类前我们首先需要弄明白几个概念：

1. SubMesh的意义。

```
	前文用专门的一节来解释它的意义。这里简单阐述下，SubMesh是Mesh里拆出来的子模型，SubMesh需要额外多个的材质球，而普通的Mesh只有一个材质球。
```

2. MeshFilter 和 MeshRenderer中的 mesh 和 shareMesh ，material 和 shareMaterial 的区别。

```
	mesh 和 material 都是实例型的变量，对 mesh 和 material 进行任何操作都会额外复制一份后再进行重新赋值，即使只是get操作也同样会发生复制效果。也就是说对 mesh 和 material 进行操作后就会变成另一个实例，虽然看上去一样，但其实已经是同的实例了。

	sharedMesh 和 sharedMaterial 与前面两个变量不同，他们是共享型的。多个3D模型可以共用同一个指定的 sharedMesh 和 sharedMaterial，当你修改sharedMesh或sharedMaterial里面的参数时，多个同是指向同一个 sharedMesh 和 sharedMaterial的模型就会同时改变效果。也就是说 sharedMesh 和 sharedMaterial 被改变后，所有使用sharedMesh 和 sharedMaterial资源的3D模型会有同一个表现效果。
```

3. materials 和 sharedMaterials 的区别。

```
	与前面 material 和 sharedMaterial 同样的区别， materials 是实例型，sharedMaterials 是共享型，只不过现在他们变成了数组形式。

	materials 只要对它进行任何操作都会复制一份一模一样的来替换，sharedMaterials 操作后所有指向这个材质球的模型都会改变效果。而 materials 和 material，与 sharedMaterials 和 sharedMaterial 的区别是，materials和sharedMaterials可以针对不同的subMesh，而material和sharedMaterial只针对主Mesh。也就是说 material 和 sharedMaterial 等于 materials[0] 和 sharedMaterials[0]。
```

4. Mesh，MeshFilter，MeshRenderer的关系。

```
	Mesh是数据资源，它可以有自己的资源文件，比如XXX.FBX。Mesh里存储了，顶点，uv，顶点颜色，三角形，切线，法线，骨骼，骨骼权重等提供渲染必要的数据。

	MeshFilter是一个承载Mesh数据的类，Mesh被实例化后存储在MeshFilter，MeshFilter有两种类型即实例型和共享型的变量，mesh和sharedMesh，对mesh的操作将生成新的mesh实例，而对sharedMesh操作将改变与其他模型共同拥有的那个指定的Mesh数据实例。

	MeshRenderer具有渲染功能，它会提取MeshFilter中的Mesh数据，结合自身的materials或者sharedMaterials进行渲染。
```

5. CombineInstance即合并数据实例类。

```
	合并时我们需要为每个需要合并的 Mesh 创建一个CombineInstance实例并往里面放入，mesh，subMesh的索引，lightmap的缩放和偏移，以及realtimeLightmap的缩放和偏移(如果有的话)，和世界坐标矩阵。CombineInstance承载了所有需要合并的数据，通过将CombineInstance数组传入到合并接口，即通过Mesh.CombineMeshes接口进行合并。
```

理清以上概念后，我们在编写合并3D模型程序时难度会降低很多。下面来看下合并3D模型的具体步骤：

1. 建立合并数据数组

```c#
CombineInstance[] combine = new CombineInstance[mMeshFilter.Count];
```

2. 填入合并数据

```c#
for(int i = 0 ; i< mMeshFilter.Count ; i++)
{
    combine[i].mesh = mMeshFilter[i].sharedMesh;
    combine[i].transform = mMeshFilter.transform.localToWorldMatrix;
    combine[i].subMeshIndex = i; //标识Material的索引位置，可以为0，1，2等
}
```

3. 合并所有Mesh为单独一个

```c#
new_meshFilter.sharedMesh.CombineMeshes(combine);
```

或者，合并后保留SubMesh

```c#
		new_meshFilter.sharedMesh.CombineMeshes(combine,false);
```

4. CombineMeshes接口定义为

```c#
public void CombineMeshes(CombineInstance[] combine, bool mergeSubMeshes = true, bool useMatrices = true, bool hasLightmapData = false);
```

完整代码为：

```c#
CombineInstance[] combine = new CombineInstance[mMeshFilter.Count];

for(int i = 0 ; i< mMeshFilter.Count ; i++)
{
    combine[i].mesh = mMeshFilter[i].sharedMesh;
    combine[i].transform = mMeshFilter.transform.localToWorldMatrix;
    combine[i].subMeshIndex = i;//标识Material的索引位置，可以为0，1，2等
}

new_meshFilter.sharedMesh.CombineMeshes(combine);
```



## 状态机

### 如何用状态机模拟人物行为动作

什么是状态机？状态机有两种，一种是有限状态机，一种是无限状态机。有限状态机运用的地方比较多，无限状态机使用的情况比较少，在编译原理中可能会用到，在游戏算法中很难见到，这节我们主要来讲讲有限状态机的使用。

有限状态机可以简单描述为，实例本身有很多种状态，实例从一种状态切换到另一种状态的动作就是状态机转换，而转换是有条件的，这个转换条件就是状态机之间的连线。

打个比方，人有三个状态：健康，感冒，康复中。触发的条件有淋雨（t1），吃药（t2），打针（t3），休息（t4）。状态机的连接图可以是这样：

```
	健康-（t4休息）->健康；

	健康-（t1淋雨）->感冒；

	感冒-（t3打针）->健康；

	感冒-（t2吃药）->康复中；

	康复中-（t4休息）->健康
```

状态在不同的条件下跳转到不同状态中去，每个状态要转移到其他状态都必须有他们之间的连线条件，而且不一定状态与状态之间有连线，因为有可能是不允许转换的，例如‘健康’就不允许转换到‘康复’。

状态机可归纳为4个要素，即现态、条件、动作、次态。这样的归纳主要是出于对状态机的内在因果关系的考虑。“现态”和“条件”是因，“动作”和“次态”是果。详解如下：

```
现态：是指当前所处的状态。

条件：又称为“事件”，当一个条件被满足，将会触发一个动作，或者执行一次状态的迁移。

动作：条件满足后执行的动作。动作执行完毕后，可以迁移到新的状态，也可以仍旧保持原状态。动作不是必需的，当条件满足后，也可以不执行任何动作，直接迁移到新状态。

次态：条件满足后要迁往的新状态。“次态”是相对于“现态”而言的，“次态”一旦被激活，就转变成新的“现态”了。
```

### 游戏中人物行为动作中使用状态机

游戏项目中状态机的关键是事件机制和控制状态的控制类。状态机的数量和作用都会因系统的不同而不同，触发条件也各异的，唯有事件机制和控制类是状态机的不变的功能。

事件机制使得状态在切换时，在进入状态和退出状态时触发了进入事件和退出事件，这个是状态启动运作和停止运作的关键点。

当状态在满足转换条件时，在即将退出状态前向当前状态发起退出事件，告诉当前状态机你将停止运行，停止运行前需要处理什么逻辑请赶快处理，等待退出逻辑处理完毕后，再向新状态发起进入事件，告诉新状态你将要开始运作，运作前的有什么逻辑或者准备工作请尽快处理。这样每次状态的切换都能合理的告诉当前状态和将要切换的状态进行事件的调用处理。

### 状态机在游戏项目中哪些地方会使用到呢？

1. 场景切换。

场景是独立的，而且只能有一个场景展示在游戏中，因此场景的切换可以用状态机来表示。例如当前为登录场景，点击登录后切换到游戏场景，这时需要把登录场景的UI销毁，UI的销毁工作是登录场景状态在退出时触发的退出事件中做的事。同样的，在之后进入到游戏场景状态时，要先把游戏场景的UI创建出来，这个操作是游戏场景状态在触发启动事件时要做的事。

2. 人物行为状态切换。

人物一般只能有一个动作状态，比如攻击状态，比如防守状态，比如死亡状态，又比如人物跑步状态，这些行为都只能用单独的一个状态来表示，但也有人物边跑步边吃东西的时候，这时我们也会有几种方式去实现，比如我们把人物跑步且吃东西另外创建一个新的状态来运行，也可以把跑步状态里加一个吃东西的参数，让跑步这个状态机来运行不一样的跑步动作。

3. 宝箱，机关等具有多动画的元素都可以构成独立的状态。

可以把宝箱或机关的每个动画都看成一个状态，比如打开状态的宝箱和关闭状态的宝箱，以及打开时的机关状态以及关闭时的机关状态。

4. AI。

用状态机来做AI是比较常见到的方式，每个AI状态都可以看成一个独立运行的状态。比如AI状态中的激怒状态，一般来说怪物在此状态中会不断向周围的敌人发起攻击，如果20秒后恢复到平静状态后就不再攻击则认为AI状态由激怒状态转换到了空闲状态，又比如AI巡逻状态，在某个点周围或者按一定路线进行走动，如果5米内发现敌人就会激活条件转换到AI激怒状态。

以上都是状态机在游戏项目各个逻辑模块中的运用，下面我们重点来介绍下人物行为的状态机结构，我们先按常见的需求把人物行为动作划分一下：

```
	1，	休息状态。原地不动，并且重复做一个休息的动画。

	2，	攻击状态。播放攻击动画，并且对目标或前方进行攻击。

	3，	技能状态。技能稍微复杂点，因为每个技能都不一样，所以技能状态里面的逻辑可以由不同的技能类来实现。比如建个技能基类class SkillBase，里面有几个统一的接口，然后子类对基类进行继承后，细化技能的细节。

	4，	防御状态。播放防御动画，当受到攻击时，不切换受伤状态。

	5，	受伤状态。播放受伤动画，完毕后自动进入休息状态。

	6，	行走与跑步状态。播放行走或跑步动画，并根据操作输入移动方向。

	7，	跳跃状态。播放跳跃动画，并上下移动人物进行跳跃，下落时底部受到碰撞就进入休息状态。

	8，	死亡状态。播放死亡动画，并且不再受到任何指令而转入任何状态。
```



## 3D模型的变与换1

### 3D模型的基础知识

在模型的世界里，众多的顶点勾画出了一个完整的3D模型，顶点之间的连线组成了三角形或多边形，大部分情况下我们的模型还是以三角形为主，任意多边形网格也都能转换成三角形网格。三角形以其简单性而吸引人，相对于一般多边形网格许多操作对三角网格会更容易些，除了细分着色器和几何着色器这两个不常用的着色器可以处理多边形外，许多重要阶段的顶点处理方式都是以三角形为单位进行处理的。

这么多的顶点是怎么表达三角形网格的呢。通常使用索引三角形网格的表达方式，索引三角形网格它有两个列表，一个是顶点列表，里面存储了网格所有的顶点，另一个是索引列表，里面存储了所有成形三角形的索引，列表从头部到尾部依次排开，每三个索引指向三个顶点，这三个顶点代表一个三角形。除了顶点其实我们还需要其他信息，包括纹理映射坐标uv、表面法向量和切向量，顶点颜色值等等附加数据，这些数据都需要自己建立一个与顶点列表同样大小的列表来存储以便在顶点传入时提取相对应的数据传入到GPU处理。

三个索引指向了三个顶点组成了一个三角形，所以索引的顺序也很重要，我们必须考虑面的“正向”和“反向”从而决定我们是否要渲染它们。因此我们用顺时针方向列出顶点，以确保我们能顺利计算出面的朝向。

使用索引的方式表示三角形也并不代表图形卡中一定需要传入索引，10年前大多数图形卡都不直接支持索引而是通过传入三个一组的顶点来代表三角形，当时一个网格中有很多三角形且他们都有各自的领边共享的话，传入图形卡的数据会有很大的顶点冗余，一个顶点可能被当做多个三角形的顶点传入很多次。但现在不同了，我们所用的设备几乎都支持索引的方式渲染网格，我们只需要传入模型的顶点和构成三角面的索引就可以渲染出整个模型网格。

无论怎么样CPU与GPU之间的数据传输速率还是有限的，因此为了节省数据传输的消耗，通常图形卡都会有三种方式去做优化，第一种就是缓存命中，就像CPU的高速缓存那样，图形卡也做了缓存操作，当传入的顶点数据命中，即已经在缓存中的数据，则不必再传入数据，可以直接从显存中取，如果没有命中则需要传入顶点数据并临时保存于缓存中。其次是三角带方式，以共享边的方式把所有三角形排开每个顶点加上共享边则可以成为一个三角形，这种方式省去了索引表和也节省了顶点传入数据量，但很多复杂的多边形网格需要被拆分成共享边形式的数据并且需要在传入引擎做些预计算，灵活度相对比较低。另外一种三角扇，灵活度则更低，它以一个顶点为中心点，其他相邻的两个顶点与中心点的连线形成三角形，在复杂的网格上也需要拆分数据并且也同样需要对网格做预计算，这种方式与三角带的方式所需要传入的顶点数据差不多却更为不灵活，实际项目中很少使用。

因此顶点索引是主流的三角形表达方式，其他方式都是为了优化索引这个数组而设计出来的，应用的范围相对小一点。

顶点索引在程序中的表现为，把所有顶点放进一个数组里，再用另一个整数数组作为索引来表达三角形的组成（整数代表顶点数组里的index下标）。在索引数组里，每3个索引组成一个三角形，当4个顶点的数组表达了一个矩形网格时，这个矩形网格相当于两个三角形组成的面片，索引的数组大小就是6个，其中前3个索引表达第一个三角形，后3个索引表达了另一个三角形。

我们来看看这个矩形网格数据：(0,0,0), (0,1,0), (1,1,0), (1,0,0) 这个4个顶点构成了正方形。索引数组中的数据为，0,1,2,2,3,0 ，其中前三个0,1,2构成一个三角形，后三个2,3,0构成另一个三角形，每三个索引单元描述三角形的三个顶点。更复杂的网格数据与上述格式一样，在顶点数组中存储了所有顶点坐标的数据，在索引数组中每3个索引指向3个顶点构成了一个三角形网格，所有三角形网格描绘了整个网格上具体的面片。

我们再来完整的叙述一遍网格数据从制作到渲染的过程。首先通常3D模型由3D美术同学制作出来并导出成 Unity3D 能够识别的格式即 FBX 文件，里面已经包含了顶点和索引数据，我们在程序中将 FBX 实例化成 Unity3D 的 GameObject 后他们身上附带的 MeshFilter 组件存储了网格的顶点数据和索引数据(我们也可以通过自己创建顶点数组和索引数据，以手动的方式输入顶点数据与索引数据，就如我们上面描述矩形网格那样)。有了 MeshFilter 帮助我们存储顶点和索引数据，就可以通过 MeshRender 或 SkinMeshRender 来渲染模型，这些顶点数据通常都会和材质球结合在渲染时一起送入图形卡，其中与我们想象的不一样的是在送入时并不会有索引数据的送入，而是由三个顶点一组组成的三角形顶点送入图形卡。接着又图形卡处理我们送入的数据后渲染到帧缓存并输出到屏幕。

除了顶点和索引描述了模型的轮廓，我们还需要其他数据来渲染模型，包括贴图，uv，颜色，法线等。下面我们就来讲一讲这些常见的数据是如何作用在模型渲染上的。

那么贴图是怎么渲染上去的呢？

如果把3D空间中的三角形当做一个2D的面片来看待就会好理解一些，一个2D的三角形面片为了把图片贴上去，就需要在图片上也指定三个点，当贴图上的三个点形成的三角形与顶点三角形比例一致时，这部分三角形贴图贴到对应的顶点上后就会有顶点与图片的拟合，如果贴图上的三角形与顶点上的三角形比例不对称也可以贴，只是我们看起来会感觉拉伸或扭曲。这三个在贴图上的点坐标就叫uv，它们由2个浮点数组成，这两个浮点数的范围是0到1，0表示贴图的左上角起始位置，1表示贴图的最大偏移位置也就是右下角，一听uv二个字母我们就应该要知道是说的是图片上的坐标。

用这种三角形贴图的方式贴到3D模型的每个三角形上，就可以如期的绘制出有’皮‘的3D模型了。这样一来我们在绘制3D模型时，除了顶点和索引数组外就又多了另一个数组叫uv数组，这个uv数组是用于存储uv坐标而存在，由于已经有了索引来表达三角形的三个顶点，所以uv数组就不再需要索引来表达了，只需要按照顶点的索引形成的三角形来定制uv的顺序就可以了。

我们还是用简单的矩形网格数据举例来说明：

[(0,0,0), (0,1,0), (1,1,0), (1,0,0)] 这个4个顶点构成了正方形。

[0,1,2,2,3,0] 组成了顶点索引，它表达了2个三角形的形成。

[(0,0), (0,1), (1,1), (1,1), (1,0), (0,0)] 组成了uv数组，表达了两个三角形上贴图的绘制范围。

如果有一个带着材质球的贴图传入图形卡，这面这些数据将会在画面上显示这个正方形的图片。我们可不能小看这些基础知识，所有花里胡哨的技巧都是建立在基础知识之上的，这些基础知识在平时的实践中有很大很大的用途。下面就来介绍些我们在具体实践中的一些技巧，看看这些基础知识是如何灵活的运用在这些技巧上的。

### 顶点在拆分模型时的表现

模型切割也即模型的分裂，在游戏中是比较常见的手法。我们来说说如何用直线切割的方式切割模型，就如’切水果游戏‘那样，横向或纵向的直线切割。

我们知道在Unity3D中一个3D模型是由一个渲染实例构成，也就是说一个Render组件（MeshRender或者SkinnedMeshRender,这里统一称为Render组件）只能渲染一个模型。那么要把一个Render渲染的模型切割成2个，就相当于把这个渲染组件，变成两个Render渲染组件，从而渲染两个不同的模型。

有了这个大的方向就会容易多，我们可以把原来的Render渲染组件中的顶点数组、顶点索引数组，uv数组，都提取出来，并将它们分成两部分，一部分是切割后的左半部分，另一部分是切割后的右半部分。再把这两部分，分别放入新建的两个新的Render渲染组件实例中去，就得到了切割后的模型。在切割后对这两个切割后的模型加入碰撞体和物理运动组件（或者说重力引擎Rigidbody），可以让画面表现的更真实，像是一个有重量的球体被切割后倒地分成了两半那样。

这其中核心的关键是如何拆分成两部分，我们要知道一个顶点在左半边还是右半边，以及切割中在哪里生成新的切割顶点，如何将这新的切割顶点与原来的顶点集合缝合。

我们首先面临的是怎么区分点在左半边还是右半边，其实我们不用区分是左边还是右边，只要区分顶点是否是在平面的同一侧即可，方法可以通过矢量的点积值判断是否在平面同一侧，点与平面的法线的点积(Dot)值可以来判断是否为相同一侧。一般来说我们在切割时应该会知道切割平面，比如像切水果游戏那样在屏幕上划一下代表切割平面，滑动时我们可以知道滑动起点和终点从而知道切割平面的法线，以及从摄像机碰面出发的平面方向，因此可以利用这两个数据得到点积需要的数据。

```c#
public float PointDotClipplane(Vector3 point)
{
	return Vector3.Dot((point - touchEnd), planeNormal);
}
```

上述函数中用指尖的结束的点位、平面法线、模型顶点这三个数据来计算点积，得出的结果如果大于0则为一侧，小于0则为零一侧。当然这三个数据在使用前都必须转换到同一个坐标系中才正确。

其次我们需要计算三角形三条线是否与切割平面相交，从而来判定是否有新交点。我们前面计算过点在切割平面左边还是右边的结果，如果一条线段的两个顶点在点积时的结果方向不一致就说明线段与切割平面有相交，这样我们就能很快判定出哪些线段需要计算交点。如果线段有相交则需要计算交点，看起来复杂其实不需要害怕，平面与线段的交点其实也在线段上，因此我们只要计算出一个交点在从起点向终点推进的比例就能得出交点的结果，即t为比例时最终结果x坐标为 x = (begin.x - end.x) * t + begin.x，另外的y和z也是同理。所以关键点到了比例值t怎么求，它有几种方法，其中一种是起点到平面的垂直距离与起点到终点的垂直距离的比例就是t，另外还可以在xyz轴方向任意轴上计算起点到切割线的距离，以及终点到切割线的距离，他们相加的值为整条线与切割线的垂直距离，起点到切割线的距离除以整条线的距离得到的值就是t。

切割后中空部分需要缝合，由于缝合面上所有点是在同一平面，所以缝合时只需要缝合新生成出来的交点部分就可以了，因为其他部分还是保留原来的样子。

缝合的算法有好几种，主要的目的是将多新生成出来的点，有规则的组成新的三角形进而形成一整个切割面。其中一种相对简单的算法步骤为，选一个点用这个点与其他所有需要缝合的点形成的线段算出夹角值，用夹角的大小进行排序，排序后的结果也就是顺时针或者逆时针的点位，然后按顺序先将靠最前面的前三个点形成一个三角形，后面的点位与它之前的两个点形成新的三角形，也就是第4个点与前两个点也就是第三个点和第二个点形成三角形，第5个点与第4个和第3个点形成新的三角形，类似于我们前面介绍的扇形三角形，这样依次类推缝合切割面。这种不筛选顶点的缝合算法在凸多边形的情况下没什么问题，但在复杂的凹多边形情况下就会出现问题，因此我们仍然要寻找出所有corner点，即角上的顶点，用角上的顶点来做为起点缝合三角形会表现的更加合适。详细请参考资料(github.com/hugoscurti/mesh-cutter)

### 网格变形

扭曲模型的操作相当于将3D模型变形，例如将模型凹陷进去，或拉长凸出来，甚至对部分区域放大或者缩小等。

有了上面介绍过的3D模型的基础知识，这里在编写模型的变形时就显得更加容易。模型网格由三角形组成的，三角形是由点组成的，要变形就得移动顶点的位置，不只一个顶点的位置，而是一片顶点的位置。

扭曲和变形在实际项目中也有很多应用，爆炸后的地面凹陷，拉某个球时球有个先被拉伸再恢复的过程，以及用3D模型来表现制陶工艺，也有些角色扮演类游戏中，操控的摇杆就是用可拉伸的泡泡糖网格表现的，这些都是对模型内某个范围或者某些顶点的进行位移后表现出来的。

顶点的点位的移动相对比较简单，就是取出顶点数组，修改坐标，再放回去而已。难点一是准确找出需要修改的顶点，二是不同的点修改的值不同，找出修改顶点偏移量。

我们这里拿爆炸凹陷，球体拉伸反弹，制陶工艺这三个技巧来简单分析下。

#### 爆炸凹陷

首先找出爆照范围的这块地面网格，并取出这块地面网格上所有顶点数据，对所有顶点求出在爆炸范围球体内的顶点，这些顶点就是需要修改的顶点。

其次来做顶点凹陷，凹陷算法的目的是把顶点位置修改到爆炸球体的球表面上，这个算法相当于，如何把一个点对应到一个球体的面上。

由于球面坐标可以用经纬度定位，经转化后公式为

```c#
x = cos(a)cos(b)

y = cos(a)sin(b)

z = sin(a)
```

其中a，b为经纬度，这样我们就能从原始顶点到球中心点计算出方向矢量，从而计算出经纬度，最后得到该顶点修改后的球面位置，计算出来后修改点位置再装入渲染的实例中，凹陷变形就完成了，顶点索引和uv都不需要任何变化。

#### 球体拉伸与反弹恢复

在拉伸球体时，计算所有顶点与要拉的那个点位的距离，距离越大顶点需要的偏移量越小，这个比例肯定不能是个正比关系，一定是一个衰减的曲线，假设距离是d，拉伸的距离为f，结果为res，那么最简单的衰减公式为 res = f/(d * d)，用这个公式对每个顶点进行计算，得到一个需要移动的数据res，这个数据是根据距离大小而衰减的，与拉伸点离得越近移动量越大，反之越小。修改完成所有顶点的坐标后，再推入渲染实例中去，就得到了球体拉伸的效果。

球体的拉伸后的放开恢复时，这里我们假定球体的屁股是被固定的。恢复和拉伸有点相似，拉的最远的反弹的快，也就是与原有的位置距离最大的点反弹的速度最大，也就是说，我们需要记录原来没被拉伸时的顶点的坐标位置，他们与原来的位置相减就是反弹速度的基础变量。

反弹力度肯定也不是正比关系，肯定也是类似衰减公式的增强公式，或者说是弧线比例，最简单的公式就做个平方，res = d * d，或者为了更平滑点，找个更好的曲线公式res = (d / max) * (d - 2) * k。

反弹恢复的力度，在不断得计算过程中，会由于顶点与原有的点位的距离缩小而减小，后又由于反弹过度而不断放大，有一个来回反弹的过程，最后恢复到平静不再移动的状态，用这个公式能就很好的体现出来，因为它与原顶点距离有关，力度在不断得衰减，最后形成稳定态。

#### 陶工艺的模拟

一个罐体模型在转盘上不停的转，当用手（鼠标或者触摸屏）去触摸它的时，在触摸的点会形成凹陷，或者拉伸，人们通过在这样不断的凹陷和拉伸过程中制作出了一个完整的陶瓷的模样，这就是制陶工艺的过程。

在一个叫做《釉彩》的手机App中有具体的表现，里面你可以用一个很丑的泥罐，通过来回、上下、左右的手指滑动制作出一个你喜欢的陶瓷品，制作出来的陶瓷品可以让别人定做，也可以通过里面的超市直接购买。

它的原理非常简单，就是在当你触碰时，根据你的手指滑动的方向，把范围内的顶点向手指滑动方向偏移，并且有一个衰减范围，离手指最近的点越近拉伸的距离越大，离得越远拉伸的距离越小。顶点选取的范围的判定可以认为是在一个矩形中的范围，比如认定的手指滑动的矩形范围，从而构建出一个相应的立方体范围，进而选出在立方体内的顶点，再进行衰减式的位移，最终构建出，可上下，左右，对陶瓷罐的拉伸变形操作。

## 3D模型的变与换2

### 简化模型

经常在项目中看到有模型有几万个面的情况，模型面数多的好处是能表现的更加精细画面更细腻，坏处却是加重了渲染压力，渲染的面数越多压力越重，帧率就会越低。所以一般都会对场景中的单个3D模型进行限制，或者对整体场景面数进行限制，前面我们在美术资源规范中讲述了规范的方法这里不做重述。

画面质量和性能需要权衡，通常都是要求模型降低面数而画面质量不变，LOD(Level Of Detail)经常可以在场景模型的质量与性能平衡中发挥巨大的作用，它的原理是随着镜头的靠近模型物体精细度会逐级更换更细腻的模型。

简化模型是LOD比较常用的方法，我们可以手动用3D模型软件简化每个模型，也可以用程序的方式简化模型。在实际的项目中，手动简化更加平滑但费时间，很多时候时间成本过大而选用程序工具去简化，因为用程序简化更加快速，缺点是不平滑。我们可以根据项目的需求，规模，画质等要求来权衡是否使用程序工具去简化模型，或者更加灵活点，一部分不太需要细致的模型使用程序工具简化，而另一部分比较需要细节化的模型使用手动简化，这样即照顾到了画质，又照顾到了工期。

这里我们来具体讲述下简化模型的算法。虽然市面上简化模型的插件和工具很多，但如果我们对原理有了更深入了解，在实际的项目中运用这些工具会更加自如且得心应手。

模型网格是由点，线，面组成。面由点和线组成，减面相当于减点和线，单纯的减去点和线容易引起模型变化不受控制，收缩线上的两顶点成为一个顶点则更加靠谱些。[Garland et al. 1997]提出了一种基于二次项误差作为度量代价的边收缩算法，其计算速度快并且简化质量较高。

该方法是去选择一条合适的边进行收缩时，定义一个边的收缩都是有代价的，每个顶点也有自己的代价。为了计算代价，对于网格中的每个顶点v，我们先定义一个4×4的对称误差矩阵Q，那么顶点v=[x y z 1]的代价为其二次项形式Δ(v)=vQ。

这样同时也定义了边收缩的代价公式，假设对于一条收缩边(v1,v2)，其收缩后v1，v2顶点收缩为v3，我们定义顶点v3的误差矩阵Q3为Q3=Q1 + Q2，也就说是v1，v2的这条边的收缩为v3后代价为Δ(v3) = v3(Q1 + Q2)，以此类推每条边都有一个代价。

有了上面的代价公式，下面的网格简化算法就容易理解多了：

```
	1，对所有的初始顶点都计算它们各自的Q矩阵.

	2，选择所有有效的边（这里取的是两点有连线的边，也可以将两点有连线且距离小于某个阈值的边归为有效边）

	3，对每一条有效边(v1,v2)，计算最优收缩目标v3.误差(Q1+Q2)是收缩这条边的代价（cost）

	4，将所有的边按照cost的权值都放在队列中从小到大进行排序。

	5，每次移除队列顶部的代价（cost）最小的边，也就是收缩最小代价的边，删除v1，v2，并用v3替换。

	6，重复1-5步骤，直到顶点数少于某个设定的值，或者所有cost代价大于某个值，则停止收缩算法。
```

似乎有点难理解，其实整个算法并不复杂，关键这里有两个核心问题需要解决，一个是每个顶点的初始Q矩阵如何计算，另一个是v1，v2收缩为v3时的坐标位置该怎么计算。在原始网格模型中，每个顶点可以认为是其周围三角片所在平面的交集，也就是这些平面的交点就是顶点位置，因此我们定义顶点的误差为顶点到这些平面的距离平方和。

由此定义我们可以计算出每个顶点的初始误差矩阵Q：Δ(v)为顶点误差值 = vQ = 0，这里的初始顶点的误差值为0，是因为它最初与相交平面的距离平方和为0，即没有误差，也就是说，Q为v的逆矩阵，于是初始顶点的误差矩阵Q就是v的逆矩阵。

至于v1，v2收缩为v3时如何选择最优的坐标，简单的方法就是取v1，v2，和中点(v1+v2)/2的三个中收缩代价最小的一个为最优选择，另一种策略则是数值计算顶点v3位置使得Δ(v3)最小，由于Δ的表达式是一个二次项形式，因此令一阶导数为0。

按照这个算法步骤，不停的收缩最小代价的边，直到顶点数量小于某个值时停止，最终将得到一个简化的模型。

### 蒙皮骨骼动画原理

场景中有了3D模型又会有3D模型动画，那么3D模型和3D模型动画之间到底多了哪些数据，这些数据又是怎么起作用的呢，我们来分析下。为了能更直观的了解模型与模型动画的不同，我们以 Unity3D 的 MeshRenderer 和 SkinnedMeshRenderer 这两个组件作为切入点来讲解。

在Unity3D中，MeshRenderer 与 SkinnedMeshRenderer 这两个组件分别用于渲染 3D模型 和 3D模型动画，他们两个的模型数据都存储在 MeshFilter 中，因此他们都依赖于 MeshFilter 组件。其中 MeshRenderer 只负责渲染模型，我们也可以称它为普通网格渲染组件，它从MeshFilter中提取网格数据顶点数据，而蒙皮网格(SkinnedMeshRenderer)虽然也渲染模型，也从MeshFilter中提取模型网格顶点数据，但蒙皮网格被引擎程序员编写出来主要是为了渲染动画服务的，所以蒙皮网格除了3D模型数据外还有骨骼数据以及顶点权重数据。

我们前面说过3D模型渲染的数据传递过程，这里 MeshRender 也同样遵循这种规则，即先从 MeshFilter 中取得网格顶点数据、uv数据、颜色数据、法线数据等，结合自己身上的材质球都发送给GPU，其中包含了许多OpenGL的状态设置，在指令最后是一个Drawcall调用告诉GPU按照传送的这些数据渲染(见渲染管线与图形学章节中详解讲解内容)。

蒙皮网格(SkinnedMeshRenderer)在渲染时也遵循了和 MeshRender 一样的渲染步骤，如果蒙皮网格上没存储任何骨骼数据，那么它和普通网格MeshRender的作用没有任何区别，渲染的都是没有动画的3D模型。

有很多人并没有理解骨骼动画的原理，所以在实际项目中对3D模型骨骼动画的运用有很多误区，这里我们有必要阐述一下骨骼动画的原理，以及在Unity3D的SkinnedMeshRenderer上骨骼动画是如何组装和组成的。通过对骨骼动画的原理解剖和对 SkinnedMeshRenderer 的解剖，我们能彻底的明白骨骼动画的计算和渲染其实并不复杂，揭开这层薄薄的面纱后是一片平坦的开阔地。

我们知道3D模型要做动作，首先是模型网格上的点、线、面要动起来，只有点、线、面动起来了，每帧渲染的时候才能在帧渲染时渲染不同的网格形状，从而才有看起来会动的画面。那么怎么让点，线，面动起来呢？对我们来说有两种方法，一种是用一个算法来改变顶点位置，我们通常叫它为顶点动画，另一种是用骨骼的方式去影响网格顶点，我们叫它为骨骼动画。这两种动画方式都是通过在每一帧里偏移模型网格上的各个顶点，让模型变形从而形成动画的效果的。当每一帧模型网格的形状不一样，播放时就形成了动画，两种方法虽然方式不同，但遵循都是同一个原理。

起初3D模型动画只有刚性层级式动画(rigid hierarchical animation)，它将整个模型拆分成多个部位，然后按照层级节点的方式安装上去，如下示意图。

```
	[根结点]
	--[躯干节点]
	----[右上臂]
	------[右上前臂]
	--------[右手]
	----[左上臂]
	------[左前臂]
	--------[左手]
	----[头]
	--[右大腿]
	----[右小腿]
	------[右脚]
	--[左大腿]
	----[左小腿]
	------[左脚]
```

这样模型以层级的方式布置在节点上，这样当父节点移动、旋转、缩放时子节点也随之而动。这种方式的动画问题很多，其中比较严重的是关节连接位置常产生‘裂缝’，因为它们并不是一个模型衔接而成而是由多个模型拼凑起来的，我们可以想象在节点旋转时模型与模型之间的衔接重合部分产生的问题，无论怎么摆放部件的位置在节点做动画时都会有这样或那样的‘裂缝’出现，因此当时的动画比较不自然。

除了刚性层级式动画(rigid hierarchical animation)，最初也是用过改变每个顶点的动画，意思为把每个顶点都记录下来每帧都告诉引擎怎么改变顶点位置，这种方式太过暴力也很少使用，但另一个变种叫变形目标动画(morph target animation)常使用在脸部动画技术，它将动画做成几个固定的极端姿势的模型，然后在两个模型之间的每个顶点做线性插值，脸部的动作大约需要50组肌肉驱动，这种复杂细微程度的动画用2个网格顶点之间的线性插值表现再适合不过了。更多时候会使用程序员们编写的顶点走向算法去改变每个顶点的位置，这与今天我们用着色器(Shader)在顶点函数中去改变顶点位置成为动画效果类似，这种方式的动画效果在很多游戏中都有在使用，当然它也已经成为优化骨骼动画性能开销的必要手段，比如草、树在风中的左右摆动，丝带或国旗在空中自然飘动等。

蒙皮骨骼动画简单易用，它的出现让3D模型的动画效果就变得越来越丰富多彩。骨骼动画数据主要由一些骨骼点和权重数据组成，游戏角色中通常骨骼动画的骨骼数量都不会超过100个，这个数量与动画制作速度有一定关系但更多的是跟性能有关。通过对这些骨骼点操作，在上3DMAX，Maya这样的好用的动画编辑工具，我们能够创造出许许多多丰富多彩的动画效果。骨骼数据是怎么起作用的，下面我们来分析下。

首先，骨骼动画由骨骼点组成，骨骼点我们可以认为是带有相对空间坐标点的数据实体，每个模型骨骼动画中可以有许多个骨骼点但根节点只有一个，我们在现代手机游戏中每个人物的骨骼动画的数量一般都会在30个左右，PC单机游戏中会更多点到达75个左右。骨骼数量越多，表现出来的动画就会越细腻越有动感，但同时也消耗掉更多的运算量。

其次，骨骼点是树形结构，一个骨骼可以有很多个子骨骼，子节点存在于父节点的相对空间下，每个子骨骼都与父节点拥有相同的功能，由于子节点在父节点的空间下，因此当父节点移动、旋转、缩放时子节点也随着父节点的一起移动、旋转、缩放，他们的相对位置、相对角度、相对比例不变。这与Unity3D中的 GameObject 的节点相似，父子节点有着相对位置的关系，因此骨骼点在Unity3D中的存在形式是以 Transform 形式存在的，这样我们可以直观的从带有骨骼的模型中看到骨骼点的父子挂载结构。我们在Unity3D的 SkinnedMeshRenderer 组件中就有 bones 这个变量用于存储所有骨骼点，骨骼点的存储形式在 SkinnedMeshRenderer 中就是 Transform 数组形式存在，这可以从 bones 这个变量就是 Transform[] 数组类型上得知。

另外，一个骨骼点可以影响周围一定范围内的顶点，单一一个顶点也可以受到多个骨骼的影响。其实除了骨骼数据，模型中每个顶点都有对它顶点本身影响的最多4个骨骼的权重值，在Unity3D中对这4个骨骼权重数据做了存储，它们存放在 BoneWeight 这个Struct结构中，每个 SkinMeshRender 类都有一个 boneWeights 数组变量来记录所有顶点的骨骼权重值，对于那些没有骨骼动画的网格就没有这些数据。

每个顶点都需要有一个BoneWeight 结构实例以确保每个顶点都知道被哪些骨骼点影响，在 BoneWeight 中变量 boneIndex0，boneIndex1，boneIndex2，boneIndex3分别代表被影响的骨骼点的索引值，而weight0，weight1，weight2，weight3则是分别代表被0、1、2、3索引的骨骼点所影响的权重值，权重最大为1，最小为0，所有权重分量之和为1。

```
[缺Unity3D的Quality Setting图]
```

如上图所示，在Unity3D中的 Quality setting 图形质量设置中，我们可以看到关于Blend Weights 参数，就是关于一个顶点能被多少骨骼影响的参数选项。其中选项中有，1 Bone，2 Bones，4 Bones，表达的意思为一个顶点能被1个骨骼影响，或者被2个骨骼影响，或者被4个骨骼影响，能被影响的骨骼数越多，CPU消耗在骨骼计算蒙皮的时间越长，消耗量越大。



## 3D模型的变与换3

### 顶点上的骨骼权重数据受哪些骨骼点影响，影响的程度有多少

我们在制作蒙皮动画时通常分三步：

第一步是用工具3DMax，Maya等3D模型软件在几何模型上建立一系列的骨骼点(bones)，并计算好几何模型的**每个顶点受这些骨骼点的影响的权重值**(BoneWeight)。

第二步则是动画师通过3D模型软件制作一系列的动画，这些动画都是通过骨骼点的偏移、旋转、缩放来完成的，每一帧都有可能有变化，包括关键帧与关键帧之间会补间一些非关键帧的动画，制作完毕后导出引擎专有的动画文件格式，我们在Unity3D中以FBX格式文件专有格式文件。

第三步则是在Unity3D中导入并播放动画，在动画播放时在动画数据中已经存储了动画师制作的骨骼点位每帧变化的情况，动画序列帧会根据每帧的动画数据持续改变一系列骨骼点，骨骼点的改变又导致了几何模型网格上的顶点产生相应的变化。

通常我们使用的都是关键帧动画，就是Unity3D里的Animation动画文件，在某个时间点上对需要改变的骨骼做关键帧，而并不是在每帧上都做关键帧的操作。使用关键帧作为骨骼的旋转位移点的好处是不需要每帧去设置骨骼点的位置变化，在关键帧与关键帧之间的骨骼位置，可以由Animation动画组件做平滑插值计算相应数据，这样可以大量减少数据大小，相当于关键帧之间做了‘补间动画’，‘补间动画’的目的就是对需要改变的骨骼做平滑的位移、旋转、缩放的插值计算，从而实时地得到相应的结果减少数据使用量。

补间动画‘在每帧都对骨骼动画做了位置、缩放、旋转的改变，然后蒙皮网格组件(SkinnedMeshRender)在每帧必须重新计算骨骼与网格的关系。最终‘补间动画’每帧改变一些列骨骼点，骨骼点被(SkinnedMeshRender)重新计算得到模型网格变化，从而每帧就呈现出不同的网格变化，最后有了3D模型网格动画。

**前面说了这么多，我们来总结下，骨骼点结构是父子关系的层级结构，每个骨骼点都由坐标和空间矩阵数据组成，每次计算都可以通过矩阵连乘得到，顶点最终的坐标计算通过多个骨骼点的权重和偏移量来决定。这样看来，由于蒙皮动画是每帧都通过骨骼点来计算网格的变化的，如果骨骼点越多，网格越复杂(顶点或者面数很多)那么消耗的CPU就很多，因为网格里的顶点都需要通过蒙皮算法来算出顶点的变化，一般情况下这些都是靠CPU来计算的。因此在制作模型动画的时候，特别要注意，同屏里有多少蒙皮动画在播放，以及每个蒙皮动画中，骨骼的数量有多少，网格的面数有多复杂，如果太多太复杂就会巨量的消耗CPU。**

### 人物3D模型动画换皮换装

1. 首先，为了达到模型动画的动态拼接，我们必须一个人物的所有动画和部件都只使用同一套骨骼。骨骼点的移动影响网格顶点，更换了模型的部分网格可以，但骨骼点是不能更换的否则骨骼点对顶点的权重影响就不对了动画就乱了套了，因此如果要一个人物不断更换局部模型后还能有一样的动画效果，那么骨骼点必须是同一套。

2. 其次，把骨骼和模型部件拆分开来，骨骼文件只有骨骼数据，每个部件的模型文件只包含了它自己的模型的顶点数据，同时它也必须包含了顶点上的骨骼权重数据。用Unity3D的术语来说就是，把一个人物模型拆分成有很多个Fbx，其中一个Fbx只有骨骼数据，其他Fbx是每个部件的模型数据，它们都带有已经计算好的骨骼权重数据。这样更便于更换和拼凑模型，每套部件都可以玩家自己拼凑，而骨骼点不变，以及每个部件上模型的顶点数据也始终映射到这一套骨骼上。每次在更换部件时，只要把原来的部分删除，更换成新的部件即可，其他数据依然有效，这便是拆分骨骼与模型部件的好处。

3. 然后，把骨骼数据和模型都实时的动态拼接起来。将骨骼Fbx模型数据实例化后成为了一个SkinnedMeshRenderer，这样基础的骨骼数据就包含在这个实例里，接着再把需要展示的各个部件Fbx模型实例化出来，它们拥有自己的SkinnedMeshRenderer，最后将骨骼信息从前面骨骼SkinnedMeshRenderer里取出来赋值给他们，包括所有骨骼节点以及变换矩阵。这样每个部件都进行了SkinnedMeshRenderer实例化，SkinnedMeshRenderer可以渲染出自己的模型效果，并且每个部件自己的SkinnedMeshRenderer都有骨骼数据，由于原本每个部件模型上也都一直存有骨骼的权重数据，这使得每个模型部件针对骨骼动画是有效的。

4. 接着在骨骼的SkinnedMeshRenderer上挂上Animator来播放动画文件，动画文件里的数据改变的是骨骼点，当动画播放时骨骼点会针对动画关键帧进行位移，由于部件模型的骨骼数据都是从骨骼的SkinnedMeshRenderer上映射过来的，所以当骨骼点动起来时就能带动众多的模型网格上的顶点一起动起来。当骨骼动画的SkinnedMeshRenderer上的动画文件开始播放时，每个部件模型上的顶点也会随着骨骼点的变动而不断的计算出网格模型的变动情况，进而在渲染上体现出部件模型的动画效果。这是由于动画播放时顶点偏移是由顶点上的骨骼权重数据决定的，如果骨骼权重数据没有问题，对应的骨骼点也没有被替换或删除，那么这就表明模型在动画表现上所对应数据的对应关系都是正确，因此他们所展现出来的动画效果也是正确的。

5. 最后，当我们需要更换人物上的某个部件模型时，只需要把原有的部件模型实例删除，再实例化出那个我们需要的部件模型，并把骨骼数据赋值给它就完成了操作。更换的操作很简单，从表现上看就是更换了人物的某个部件，脸，或腿，或手，或腰，或脚。

这种方式虽然是最简单的更换部件的方式，但它由个缺点就是需要的Drawcall比较多，由于人物拆分成了5个部件，头，手，身体，腿，脚，这样我们就需要6个SkinnedMeshRenderer来支撑渲染，除了5个部件模型外还需要1个为骨骼动画的SkinnedMeshRenderer，其他5个为部件模型的SkinnedMeshRenderer，这从效率上看上去很不友好，也就是说一个人物要至少5个Drawcall来支撑。骨骼动画已经很消耗性能了，还需要5个材质球去消耗5个drawcall，加重了性能消耗，一旦人物在场景中过多就会拖慢帧率。

我们有更好的办法，我们希望一个人物动画只使用一个drawcall，那么我们就需要把这5个部件合并成一个模型，他们都使用同一个材质球，模型合并好办，使用Unity3D的Mesh.CombineMeshes就可以实现。

那么贴图怎么办？也同样合并。在每次初始化拼接一个人物模型时，或者更换人物的部件模型时，将5张贴图动态的合并成一张，并在合并贴图的同时需要改变每个模型部件的uv，将他们的uv偏移到这张合并整图的某个范围内。

这样一来，每个人物模型只需要消耗1个drawcall，减轻了gpu的负担。从CPU消耗来看，拼接的操作只存在于人物初始化，和更换部件模型时才会有消耗，因此合并贴图和模型的实际消耗cpu的量并不多。不过所有这些合并的前提是，模型部件都可以使用同一个材质球。



## 3D模型的变与换4

### 捏脸

捏脸在网络游戏中泛指对虚拟角色样貌进行DIY的数据操作。捏脸看起来像是很复杂的技巧，在我们剖析一下后就你会觉得它并没有想象中的那么困难。

1. 首先，捏脸最重要的部分就是换部位。

   角色身上可以替换的部位有，不同形状的头，不同形状的上身，不同形状的腿，不同形状的脚，不同形状的手，其实还可以细分到更多，比如嘴，耳朵，胸，头发等，这些部件都可以从整体模型中拆分出来，单独成立一个模型，然后再选出来后拼装到整体模型上去。拆分出不同部位的模型，有了多个相同部位不同形状的模型后，我们就有了很多个模型部件可以替换，在捏脸时就可以选择不同的形状的部件。

   替换的过程就是上篇我们讲到的换装的过程，我们可以再来简单回顾下。

   我们必须所有模型都使用同一套骨骼，把骨骼以SkinnedMeshRenderer组件的方式实例化出来，我们暂时称它为‘根节点’，并挂上动画组件和动画文件，当播放动画时就可以看到骨骼会跟随每帧动画数据而变动。但此时还没有任何模型展示，我们把选中的部件模型也以SkinnedMeshRenderer组件的形式实例化出来，并挂载在‘根节点’下。

   现在挂载在‘根节点’下的部件模型只是静止的不会动的模型，虽然其自身有顶点的骨骼权重数据，但没有骨骼点的数据是无法计算出骨骼变化后的模型变化的。因此我们再把‘根节点’里的骨骼点数据赋值给这些模型部件，让他们能在每帧渲染前根据骨骼点的变化结合自身的骨骼权重数据计算出自身的网格变化情况。做完这些操作后，我们就算成功合成了一个由自己选择的人体部件并带骨骼动画的角色模型实例。

   当需要更换人体部件时，所需要的操作与合成一个角色模型的步骤一样，只是在这之上有了些小的变化，因为只替换某个部件，所以‘根节点’与其他没有更换的部件不需要被销毁，是可以重复利用的，只需要删除替换的部件实例。

   合成完模型看看这个角色，这么多部件都使用了SkinnedMeshRenderer，每个SkinnedMeshRenderer都有一定计算和drawcall的消耗，怎么办？合并。

   一种简单的办法就是仍然使用多个材质球进行渲染，在合并Mesh时使用子网格(SubMesh)模式，相当于只减少了SkinnedMeshRenderer组件的数量，并没有减少其他的消耗。另一种办法稍微复杂点，不使用子网格(SubMesh)模型，而是将所有模型合并成一个Mesh网格，使用同一个材质球。不过我们还是得保证有相同Shader的材质球进行合并，不相同的Shader的材质球不合并的原则，以保证角色渲染效果不变。

   把这么多材质球合并成一个的困难之处在于，贴图怎么办，uv怎么办？贴图我们需要采用实时合并贴图的方式。合并材质球实质上是为了降低Drawcall，我们的办法实质上就是内存换CPU的方式，每次合成角色、更换部件时都重新合成一遍贴图，同时把uv设置在合并贴图后的某个范围内，因为uv的相对位置是不变的，所以只要整体移动到某个范围内就可以正常显示。

   这样模型的更换与合并，让角色捏脸系统有了基础的功能，而材质球、贴图的合并，优化了性能效果让这个系统更加完美。

2. 其次是更换贴图

   不同颜色的头发，不同颜色的手套，不同颜色相同形状的衣服，不同贴图相同形状的眼睛等，这些可以简单的使用更换贴图来达到目标的动作，就直接更换材质球里的贴图就可以了，不需要太复杂的操作，如果是采用贴图合并的方式来做的合并，那么就再重新合并一次贴图，如果更换的贴图大小不一样uv也需要重新计算一次。

3. 再者是骨骼移动、旋转、缩放

   除了更换部件、更换颜色的操作外，捏脸还有一个重要的功能，就是用户可以自由随意的DIY去塑造模型。例如把鼻子抬高点，把嘴巴拉宽点，把腰压细一点，把腿拉长一点等。

   由于模型的网格(Mesh)是根据骨骼点来变化的，每个组成网格的顶点都有自己的骨骼权重数据，所以只要骨骼点移动了，它们也跟着移动，骨骼点旋转了，它们也跟着旋转，骨骼点缩放了，它们也跟着缩放。于是我们可以利用这个特性来做一些操作，来让‘捏泥人’更加容易，最后只要记录骨骼移动和旋转或缩放的数据就可以了，在重现时再次将数据重新导入到骨骼，就能呈现出原来玩家捏脸时的样子。

   不过问题也来了，骨骼点是随着动画一起动的，动画数据里的关键帧决定了骨骼点的变化，我们实时改变骨骼点位置是无法达到效果的，因为动画数据会强行恢复骨骼点，致使我们的操作变得无效。我们既要整个模型网格仍然依照原来的动画数据去变动，又要用某个骨骼点去影响某些网格怎么办？额外增加一些骨骼点，这些骨骼点是专门为用户可操作服务的骨骼点，并且这些骨骼点不加入到动画数据中。也就是说动画animation中的数据不会有这些特别骨骼点的存在，这也使得在动画播放时这些骨骼点是不会动的。

   然后为了能让网格随着操作这些骨骼点儿发生变化，在顶点的骨骼权重数据里给这些骨骼点一些权重，这个权重能达到玩家操作效果就可以了，其他都由动画去决定变化，SkinnedMeshRenderer会在每帧根据骨骼点的变化计算出所有顶点的位置，也就是网格的变化形状。

   这样操作下来，我们就达到了先前说的，既要整个模型网格仍然依照原来的动画数据去变动，又可以让用户自定义操作骨骼点去影响网格变化。

5. 用两个不同网格顶点的线性插值做脸部动画

   只操作骨骼点来改变模型的捏脸效果还是不够的，因为毕竟骨骼点数量不能太多，顶点的骨骼权重数据也是有限的，特别是脸部表情的网格变化比较复杂，它有50多块肌肉组成网格顶点变化又多又快，此时无法通过增加大量的骨骼点来达到脸部模型复杂变化的效果。于是只能再另寻它方，这次我们回到了最基础的网格变化，由于蒙皮网格在每帧都从原始的网格加上骨骼点的变化数据来计算现在网格的形状的，那么改变原始网格的顶点数据也同样可以改变网格在动画时的模型变化。

   还记得前面我们提到的最初在没有蒙皮骨骼时动画师们所用的办法么，用两个模型网格顶点的线性插值来做为网格变化的形状，即变形目标动画(morph target animation)。我们可以制作几个极端的脸部表情模样，用网格顶点插值形式对原始网格数据里的顶点进行变化，每个插值都带来顶点变化形成一个网格形状，从而形成不同脸部表情的动画。

### 动画优化

#### CPU Skinning

我们前面讲了关于蒙皮动画太消耗CPU的问题，所有蒙皮网格的变化都是由CPU计算得到的。

在Unity3D中有一个 CPU Skinning 的选项，开启后将使用多线程 + SIMD 对蒙皮计算做加速处理，由于每个顶点的变化都是独立于骨骼点之上的，相邻的顶点并不互相影响，因此可以使用多线程将一个模型的网格顶点拆分成多个部分顶点进行计算，多线程的使用将提高蒙皮计算的速度。

而这里的SIMD即Single Instruction Multiple Data，是指单指令多数据流，它能够复制多个操作数，并把它们打包在大型寄存器的一组指令。我们以加法指令为例，通常我们使用的单指令单数据（SISD）在CPU对加法指令译码后，执行部件必须先访问内存取得第一个操作数，之后第二次访问内存取得第二个操作数，随后才能进行求和运算。而在SIMD型的CPU中，指令译码后几个执行部件同时访问内存，一次性获得所有操作数进行运算。SIMD的这个特点使它特别适合于数据密集型运算，在我们游戏开发中SIMD特别适合矩阵运算，我们的蒙皮计算就是大量使用矩阵运算的地方。

但 CPU SKinning 并没有减少运算CPU的运算量只是加速了运算速度提高了运算效率，我们在游戏使用了大量的蒙皮动画来达到丰富效果的目的，而通常所有项目都会极致得用尽动画功能，让游戏看起来很生动，丰富，饱满，火热。这使得设备在游戏项目中承受了巨大压力，如果效果再好性能消耗太大，只有高端机才能承受渲染压力的游戏，就无法对普罗大众产生吸引力，也就无法开启吸引力效应，因此对每个项目来说动画的优化是重中之重。

#### 用着色器代替动画

蒙皮动画说到实质处，就是网格顶点的变化，根据骨骼点与权重数据计算网格变化，它到底是前人发明的一种每帧改变网格的方法，最终的目标都是怎么让网格每帧发生变化，并且这种形状的变化是我们所期望看到的。

其实无论用什么方法只要达到“变化是我们所期望看到的”这个目标都是可行的。想到这里，除了cpu中改变顶点坐标位置，我们还有另一种途径来改变顶点坐标位置，它就是着色器(Shader)中的顶点着色器，它也可以改变网格顶点的位置。于是我们可以用顶点着色器，加上一个适合的顶点变化算法就等于得到一个随着时间变化的模型动画。

用着色器制造的动画这种方式已经很久远了，它也在许多项目中用的比较频繁，最常见就是随风摆动的草，会飘动的旗子，飘动的头发，左右摇摆的树，河流的波浪等等。这些算法不在这里一一讲解，它们大部分这些算法都利用了，游戏时间，噪声算法(noise)，数学公式(sin、cos等)来表达顶点的偏移量。

除了顶点动画，我们还可以利用uv来做动画，比如不断流淌的水流就属于uv位移动画，又如火焰效果可以根据不断更换uv范围达到序列帧动画效果的uv序列帧动画，还如不停旋转的面片动画，就可以用uv旋转来代替面片旋转，把CPU的消耗转入到GPU消耗，使一部分计算更为高效。uv动画的具体算法也不再这里讲解。

用着色器代替动画实质上，就是用GPU消耗来分担CPU的计算量，因为部分计算在GPU中会更高效，这让两个芯片能更好的发挥其作用，而不是让某一个闲着没事干(GPU很闲或者CPU很闲)，另一个则忙的要死。用着色器动画就能充分利用GPU的计算优势，为CPU分担不少计算量。但用前面说的顶点动画，uv动画的算法来代替动画方式毕竟是有限的复杂度，当动画复杂到没有固定算法规律可寻时，就需要某求其他途径了，因此着色器动画的对模型动画的可优化范围是有限的。

#### 离线Bake每帧的模型网格

动画的实质是，每帧显示的内容不一样，而每帧显示的内容不一样，就需要每帧都计算出一个不一样的形状。那么我们能不能不计算呢？可以的。我们可以每帧都准备一个模型，每帧都展示一个已经准备好的不一样的模型，这样就有了每帧都有不同形状的模型渲染形成动画。

例如这一个5秒的蒙皮动画，每秒30帧，总共需要150个画面，我们需要最多准备150个模型来依次在每帧中播放。内存和硬盘的代价很大，原本一个模型只要一个模型网格就够了，现在要准备150个网格，内存的代价是巨大的。这就是内存换CPU的想法，到底值不值得这么做呢？

假设这个场景只有2-3个模型在播放这个动画，那么为了这2-3个模型动画，我们就需要额外准备150个模型来播放动画，本来只要一个模型+骨骼就可以办到的事情，我们却要用150个模型来代替，加载这150个模型也是需要时间的，更何况内存额外加大了150倍，确实不值得。那么我们又假设，这个模型同时播放的这个动画的数量非常多，例如20个以上，这20个模型都需要计算机每帧通过模型+骨骼的方式计算出一个模型的变化形状，而且要重复计算100次，这时我们再用150个模型来代替这每帧持续的CPU消耗就非常值得了。

用这种方式计算机不再需要大量计算相同模型网格的变化，而只是在读取这150个模型时内存消耗以及加载的消耗，换来的是持续的高效的动画效果，这样的方式用内存换CPU就非常值得。

将每帧的网格偏移数据导出到图片，在Shader中让GPU通过图片里的数据来偏移顶点。

#### GPU Instancing 

什么是GPU Instancing？这是GPU显卡一个特性，大部分图形API都提供的一种技术，其表象是假如我们绘制1000个物体，它只将模型数据以及1000个坐标提交给显卡，这1000个物体不同的位置，状态，颜色等等他们将整合成一个per instance attribute的Buffer给GPU，在显卡上区别绘制。这样做因为只需要提交一次，这大大减少提交次数，这种技术对于绘制大量的相同模型的物体由于有硬件实现，效率高，更灵活，也避免了合批而造成内存浪费。这样一来我们可以根据 GPU Instancing 来实现骨骼动画的多实例渲染。

GPU Instancing 最重要的一个特点是只提交一次就可以绘制1000个物体，把原本要提交1000次的流程，简化成了只需要提交1次，1000个Drawcall瞬间降为了1个。当然没那么简单，它是有条件的，首先条件是模型的着色器(Shader)要支持GPU Instancing，其次是这1000个模型他们位置、角度可以不一样，但都使用同一个网格数据。其实 GPU Instancing 的条件有点苛刻，Shader要相同，材质球要相同，网格要相同(就是传入的网格不能有变形的，就是不能有动画)。

对于我们来说，如果用GPU Instancing 来优化渲染就不能再使用 SkinnedMeshRender 和 Animator或Animation来计算蒙皮了，那怎么办呢？

前面我们提高离线制作模型的方法来准备150个模型，每帧都渲染一个从而省去了计算骨骼蒙皮的CPU消耗。现在我们把150个模型的网格顶顶啊数据换成贴图形式的数据，把这150个模型的网格顶点数据都一股脑放入一张贴图里去，让这张图总共有150行，每行都写入了一个的完整的网格顶点数据，让每个像素数据的 RGB 都分别代表 xyz 的顶点坐标，这样的话如果一个网格顶点总共有3000个顶点，那么每行就有3000个像素，总共150行，这张贴图就是 3000 * 150 大小。

将动画的所有帧下的模型网格顶点数据制作成一张贴图后，我们要让这张图在着色器中起作用，这相当于是将所有动画帧下的网格的顶点数据传入着色器(Shader)，着色器根据传入的图中的每个像素去偏移顶点，每帧都换一行从而形成了每帧都不一样的模型动画。我们用着色器去改变顶点坐标，就相当于让GPU去改变网格省去了CPU的提交渲染的消耗。就这样我们把贴图当做动画顶点数据交给着色器去渲染，每次渲染时所有模型都使用的是同一个模型，同一个材质球，同一个Shader着色器，符合了开启GPU Instancing的条件，即我们可以只要提交一次模型数据，就能渲染1000个模型并且有动画，瞬间降低1000个Drawcall到个位数字。具体 GPU Instancing 的工作原理我们将在渲染章节中讲解。

至此我们在实时渲染时不再需要计算骨骼了，同时也不需要SkinnedMeshRenderer了，只需要普通的MeshRenderer来渲染模型就可以了，动画里的顶点变化交给了着色器去做，将CPU的消耗从线上转移到了线下，同时利用 GPU Instancing 的特性更高效的渲染了图形。

这里用于 GPU Instancing 做动画的着色器并不复杂，只是比普通的顶点着色器在传入参数时多了个变量‘顶点索引’，根据这个’顶点索引‘变量来计算得到传入的贴图中的uv位置从而在RGB中得到顶点坐标。

```c#
v2f vert(appdata v, uint v_index : SV_VertexID)
{
        UNITY_SETUP_INSTANCE_ID(v); // gpu instance

        // 根据时间获得数据的y轴位置
        float f = _Time.y / _AnimLength;
        fmod(f, 1.0);

        // 计算 uv位置
        float animMap_x = (v_index + 0.5) * _AnimWidth;
        float animMap_y = f;

        //获得 顶点坐标
        float4 pos = tex2Dlod(_AnimTexture, float4(animMap_x, animMap_y, 0, 0));

        v2f o;
        //计算模型贴图uv
        o.uv = TRANSFORM_TEX(v.uv, _MainTex);
        //计算顶点位置
        o.vertex = UnityObjectToClipPos(pos);
        return o;
}

fixed4 frag (v2f i) : SV_Target
{
        // 根据uv上色
        fixed4 col = tex2D(_MainTex, i.uv);
        return col;
}
    代码来源于github
```

上述Shader代码就是对模型动画 GPU Instancing 的实现，它先计算得到当前需要展示哪一行帧数据，然后计算数据行中当前顶点的数据位置，即数据贴图中的uv，根据计算获得的数据uv位置提取顶点坐标，之后就是顶点着色器在传统意义上的贴图uv位置计算与顶点投影计算，在片元着色器上很简单只是根据uv位置从贴图中提取颜色而已。

顶点着色器中，用时间和动画长度计算出y的位置也就是数据在贴图中的行位置，再用顶点索引计算出数据在贴图中的列位置，从而得到动画数据贴图中属于自己位置的像素，取出这个像素信息就等于得到了这个顶点的坐标了，与世界坐标轴转换后即可使用。Shader中没有复杂的公式，就是从图片中取出值来作为坐标去传递。

#### 降低数据量

CPU端转移到了GPU端并达到了降低 Drawcall 的目的。但只是这样还不够，如果只是使用普通的材质球嵌入Meshrender的方式，就会使得每个人物的动画都是一样的，不会错开来，同一时间很多模型做相同的动作。如果这时使用不同的材质球实例来达到不同的动画时差后又会增加了drawcall，为了不增加drawcall，我们就需要用Unity3D的 GPU Instance 接口向着色器传入动画开始位置的数据。即用 Graphics.DrawMeshInstanced 将数据传入需要 Instancing 的 Mesh，在调用前，我们将准备好的所有模型的坐标数据、顶点贴图数据、动画状态数据等传入材质球中，从而实现不同的动画的时差。

除了各模型在动画播放时的差异数据，精度问题也值得关注，如果要求模型动画有好的表现，就必须提高图片的精度，因为每个像素RGB的颜色就代表了顶点坐标信息，如果要求GPU支持float类型的贴图，就需要Open GL ES 3.0以上级别的设备，虽然现在的手机设备的Open GL ES 3.0也算比较普遍，但还是有小部分低端手机设备无法实现，是否考虑降低动画精度，或者根据高中低端机的切换动画模块值得考虑。另外如果我们使用 GPU Instancing 优化模型动画，在融合动画方面则仍然束手无策，这使得动画表现会比较生硬。

#### 离线制作LOD动画与LOD网格

前面我们说了使用 GPU Instancing 来优化同一个物体在场景中渲染，这使得Drawcall降低了很多，但仍然无法避免网格面片数太多的问题，我们仍然要为100个模型在场景中的渲染付出很多渲染巨大数量面片的代价。这对于一个100个由1万个三角面组成模型来说，在场景中渲染时巨大的负担。

LOD就是一个很好的解决面片渲染负担过重的方案，我们可以根据不同的机型来加载’高、中、低‘不同等级的资源，从而实现降低面片渲染的负担。无论我们使用传统的骨骼动画实时计算网格顶点的方式，还是通过 GPU Instancing 来提高动画性能，LOD都可以做到让性能再次提升。

我们再一次回到基础知识的原点，传统骨骼动画计算的网格的变化是由，骨骼点与顶点的权重数据计算得到的。也就是说，顶点数量越多骨骼数量越多有效权重数据越多，CPU消耗的也就越多，CPU的消耗与这三者任何一个都成正比。反过来也是一样，顶点越少骨骼数越少有效权重数据越少，CPU的消耗的就越少。

不过我们仍然要注意的是，顶点数少了模型就不那么精细了，而骨骼数少了动画就补那么丰富了，而有效权重数据少了网格变化就不那么细腻了。因此我们需要对高、中、低设备进行判断，对于低阶设备则使用低档资源以保证性能优先画面流畅，对于高阶设备则使用高档资源以丰富画面。

当然高、中、低资源都需要我们离线制作，完成后在场景使用前选择并加载进来，如果使用传统的骨骼动画，则我们需要准备3套模型3套骨骼动画，如果使用 GPU Instancing 则使用需要3套模型3套动画数据贴图。

很多情况下场景内的静态物体都可以使用LOD来实时切换模型精细度等级，那么实时切换动画的高、中、低资源是否可取。传统的实时LOD(Level of Detail)用远近的视觉差来优化性能开销，用内存来换取CPU。LOD的视觉差是利用离摄像机太远的东西精细度无法分辨，这使得替换成更粗糙的模型，在距离远的情况下效果差别很小。

在实时切换动画LOD时，我们可以这么做：

第一，每套模型都分别有高、中、低三套模型与骨骼动画，在渲染时判断摄像机与物体的距离来决定使用哪一套模型。

第二，当切换模型时，把被切换的资源隐藏，将新的资源展示出来并初始化，初始化时要把当前的动画状态还原到新的LOD动画模型上，以保证动画无缝切换。

第三，当前动画状态一致还不够，还需要还原动画融合的表现，以使得切换前后表现一致，这可能是一个大的麻烦，我们需要先将动画切换到前置的动画再对后置动画进行融合。

这样看来LOD也可以用的很极致，LOD不只为了静态模型服务的，也同样可以为动画模型服务，虽然我们并没有用LOD降低任何Drawcall，但它仍然能降低了很大的CPU开销，和降低Drawcall相比也有着异曲同工之妙。