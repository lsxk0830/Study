# 第六章  网络层

## TCP和UDP的简介

### TCP（Transmission Control Protocol，传输控制协议）是面向连接的协议，也就是说在收发数据前，必须和对方建立可靠的连接。

一个TCP连接必须要经过三次“对话”才能建立起来，这里我们描述下这三次对话的形象过程：

```
    主机A向主机B发出连接请求数据包：“我想给你发数据，可以吗？”，这是第一次对话；

    主机B向主机A发送同意连接并要求同步的数据包（同步就是两台主机一个在发送，一个在接收的协调工作）：“可以，你什么时候发？”，这是第二次对话；

    主机A再发出一个数据包确认主机B的要求同步：“我现在就发，你接着吧！”，这是第三次对话。
```

三次“对话”的目的是使数据包的发送和接收同步，经过三次“对话”之后，主机A才向主机B正式发送数据。

TCP建立连接要进行3次握手,而断开连接却要进行4次，我们来看看它是怎样的一个过程：

```
    1，当主机A完成数据传输后,将控制位FIN置1，提出停止TCP连接的请求

    2，主机B收到FIN位置上的1信息后对其作出响应，确认这一方向上的TCP连接将关闭，将ACK置1

    3，B主机再提出反方向的关闭请求，并将控制位FIN置1，发送给A主机，并关闭连接

    4，主机A对主机B的请求进行确认，将ACK置1，并关闭连接，至此双方向的关闭结束.
```

由TCP的三次握手和四次断开可以看出，TCP使用面向连接的通信方式，大大提高了数据通信的可靠性，使发送数据端和接收端在数据正式传输前就有了交互，为数据正式传输打下了可靠的基础。

名词解释： ACK TCP报头的控制位之一,对数据进行确认.确认由目的端发出,用它来告诉发送端这个序列号之前的数据段都收到了。比如,确认号为X,则表示前X-1个数据段都收到了,只有当ACK=1时,确认号才有效,当ACK=0时,确认号无效,这时会要求重传数据,保证数据的完整性.

```
    SYN  同步序列号,TCP建立连接时将这个位置1
    
    FIN  发送端完成发送任务位,当TCP完成数据传输需要断开时,提出断开连接的一方将这位置1
```

我们来看看TCP的包头结构：

```
    源端口(source port) 16位

    目标端口(target port) 16位

    序列号(SYN) 32位

    回应序号(ACK) 32位

    TCP头长度(head size) 4位

    reserved 6位

    控制代码 6位

    窗口大小(size) 16位

    偏移量 16位

    校验和 16位

    选项  32位(可选)
```

这样我们把它们需要的空间位数都加起来得出了TCP包头的最小长度总共为：192-32位，最后32位的选项位可没有，所以最小长度为 160/8=20 字节。

上面描述的只是包头，也就是所有TCP数据包收到时的头部数据格式，头部数据后面跟着的才是真正的数据，后面具体跟着多少空间大小的数据由窗口大小(size)位置上的数据决定，也就是单个数据包最大能承受2^16-1=65535字节的容量。

这里有个有趣的概念，即TCP通过滑动窗口的概念来进行流量控制。由于在发送端发送数据的速度很快而接收端接收速度却很慢的时就很难保证数据不丢失，所以需要进行流量控制， 协调好通信双方的工作节奏。所谓滑动窗口概念，可以理解成接收端所能提供的缓冲区大小是有限的且是变化的。TCP利用一个滑动的窗口值来告诉发送端对它所发送的数据能提供多大的缓 冲区，以此来协调控制两边的传送节奏和速率。由于窗口只有16个比特的大小，所以接收端TCP 能最大提供65535个字节的缓冲。

### UDP（User Data Protocol，用户数据报协议）

下面我们来介绍下UDP，它最大的特点可以分6部分：

```
    （1）UDP是一个非连接的协议，传输数据之前源端和终端不建立连接，当它想传送时就简单地去抓取来自应用程序的数据，并尽可能快地把它扔到网络上。在发送端，UDP传送数据的速度仅仅是受应用程序生成数据的速度、计算机的能力和传输带宽的限制；在接收端，UDP把每个消息段放在队列中，应用程序每次从队列中读一个消息段。

    （2）由于传输数据不建立连接，因此也就不需要维护连接状态，包括收发状态等，因此一台服务机可同时向多个客户机传输相同的消息。

    （3）UDP信息包的包头很短，只有8个字节相对于TCP的20个字节包头信息，UDP的包头开销很小。

    （4）吞吐量不受拥挤控制算法的调节，只受应用软件生成数据的速率、传输带宽、源端和终端主机性能的限制。

    （5）UDP会尽最大努力去传输和接受数据且没有限制但并不保证可靠的数据交付，主机也不需要维持复杂的链接状态表（这里面有许多参数）。

    （6）UDP是面向报文的。发送方的UDP对应用程序传过来的报文，在添加包头后就向下交付给IP层。既不拆分，也不合并，而只是保留这些报文的边界，因此应用程序需要自己限制合适的报文大小，以免报文太大丢失率高。
```

我们经常使用“ping”命令来测试两台主机之间TCP/IP通信是否正常，其实“ping”命令的原理就是向对方主机发送UDP数据包，然后对方主机确认收到数据包，如果数据包到达的消息及时反馈回来，那么网络就是通的，并且可以通过返回回来的数据包计算响应时间。

其中UDP的包头结构为：

```
    源端口 16位

    目的端口 16位

    长度 16位

    校验和 16位
```

包头总共64位8个字节就足以。与TCP同样包头只是数据的头部，其真正数据是跟随在包头后面，具体长度由长度这个字段来决定，最大为2^16-1=65535字节的容量。

## 用TCP，还是用UDP？

TCP与UDP的它们的不同之处：

```
    1，TCP是基于连接的，UDP则是无连接；
    
    2，对系统资源开销，TCP开销较多，UDP开销少；
    
    3，TCP包头大各类状态多程序结构稍显复杂，UDP包头小没有状态程序结构较简单；

    4，TCP为流模式，UDP为数据报模式，相当于TCP是自来水那样需要管子以便把书举不断流入盆中，而UDP则不需要管子连接两端只要像机关枪一样不停扫射到目的地就可以。

    5，TCP保证数据正确性，UDP可能丢包，TCP保证数据顺序，UDP不保证。
```

从原理上，TCP的优势有，简单直接的长连接，可靠的信息传输，能确保数据到达有确认机制，并且数据到达后是有序的，数据包的大小没有限制，不需要自己切分数据包，TCP的底层程序本身就已经帮助我们做了数据包切分。UDP是基于数据包构建，这意味着在某些方面需要我们完全颠覆在TCP下的观念。

由于UDP只使用一个socket进行通信，不像TCP需要为每一个客户端建立一个socket连接，这虽然是UDP还不错的地方，但是大多数情况下我们需要的仅仅是一些连接的概念罢了，一些基本的数据包先后次序功能，以及传输时的可靠性。可惜的是这些功能UDP都没有办法简单的提供给你，而我们使用TCP却都可以免费得到。这也是人们为什么经常推荐TCP的原因之一，在用TCP的时候你可以不考虑这些问题。

UDP没有提供所有的解决方法，但这也正是UDP有巨大潜力的地方，它的吞吐量可以巨大但需要我们去控制它丢失率和可靠性。在某种意义上来说，TCP对UDP就好比是自动档汽车和手动挡汽车的区别，驾驶者需要掌握的技巧和关注度比自动档要多很多，但在效率上的潜力却是巨大的。

容易造成巨大的延迟问题是TCP的性质决定的，在发生丢包的时候，会产生巨大的延迟，因为TCP首先会去检测哪些包发生了丢失，然后重发所有丢失的包，直到他们都被接收到。虽然UDP也是有延迟的，但是由于它是在UDP的基础之上建立的通信协议，所以可以通过多种方式来减少延迟，不像TCP，所有的东西都要依赖于TCP协议本身而无法被更改。

那么为什么魔兽世界采用TCP呢？首先我们需要解释这个问题。这个问题其实是“为什么魔兽世界有的时候1000毫秒以上的延迟还能够运行？”魔兽世界以及其他的一些游戏是怎么处理延迟问题的呢？方法也很简单，他们能够隐藏掉延迟带来的影响。

我们看一下魔兽世界的战斗就会发现，玩家的攻击指令发送给服务器的操作，一些类似发起攻击动作和释放技能特效就能够在没有收到服务器确认的情况下就直接执行，比如展现冰冻技能的效果就可以在服务器没有返回数据前在客户端就做出来。客户端直接开始进行计算而不等待服务端确认是一种典型的隐藏延迟的技术。这也意味着，我们到底是使用TCP还是UDP取决于我们能否隐藏延迟。

UDP还是TCP参考：

```
    如果是由客户端间歇性的发起无状态的查询，并且偶尔发生延迟是可以容忍，那么使用HTTP/HTTPS吧。

    如果客户端和服务器都可以独立发包，但是偶尔发生延迟可以容忍（比如：在线的纸牌游戏，许多MMO类的游戏），那么使用TCP长连接吧。

    如果客户端和服务器都可以独立发包，而且无法忍受延迟（比如：大多数的多人动作类游戏，以及少部分MMO类游戏），那么使用UDP吧。
```



## 实现TCP

### 实现流程

```
	1， 建立连接

	2， 断线检测

	3， 网络协议

	4， 发送和接收队列缓冲

	5， 发送数据合并

	6， 线程死锁策略
```

上面6个方面是程序在建立和实现连接的必备要素，我们下文将依次讲解如何来对此作出程序上的实现。

TCP本身已经具备有数据包可靠性确认，以及丢包重发机制，数据包的大小也没有做限时，从TCP那里我们可以把免费得到的这些功能。所以在实现TCP的连接中不需要我们再做包括：包体的校验、包体的拆分，以及重发数据包，省掉了很大一部分麻烦。我们只需要做的就是建立连接，发送，以及接收，三个步骤，以及这三个步骤引起的一系列问题的对策。不过如果不对发送数据进行合并，就会有很多小的数据分批发送，导致发送效率降低。所以我们下文中会提到关于发送合并的问题。

### 介绍下TCP的API库

c#的.net库提供了 TCP 的 Socket连接API，我们来看看c#的.net库中的这些API的用法。

一般情况下我们不会去用阻塞方式连接和接收，因为我们不会让你的游戏卡住不动来等待连接，因为这有可能导致崩溃，所以连接，接收，断开都是异步的线程操作。同步阻塞的操作可能会在周边工具中会用到，比如编辑器的工具，回放工具，GM的工具等，但其他大部分时候都会更加平滑的异步操作作为网络连接和收发操作。

```
	BeginConnect，开始连接

	BeginReceive，开始接收信息

	BeginSend，开始发送数据

	BeginDisconnect，开始断开

	Disconnect(Boolean)，立刻断开连接
```

上锁接口中前四个都是异步的，调用后会开启一个线程来工作，最后一个为同步阻塞方式的断开连接接口。最后一个阻塞式大都在游戏退出时调用，但问题是APP没有退出事件，因此一般Disconnect都会用在Unity3D Eitor下或者windows版本上调用，以保证在开发时强制退出后编辑器不会奔溃。

### 线程锁

实际项目中网络模块中所有的操作都会以线程级的形式对待，而Unity3D的渲染和逻辑都是在主线程上运作的，这里就涉及到了主线程和子线程对资源抢占冲突导致我们需要做线程锁的问题。

当主线程与子线程一起工作到某时间点都需要某个内存块或者资源时，就会同时去读取或者写入资源，这就会造成资源读写混乱的情况。因此在所有线程上，在调用有冲突的资源时，都需要做锁的操作，以防止线程们在读取或写入操作时对资源错误的争夺。

我们拿网络接收数据的线程来举例，接收线程在接收到网络数据后将数据推入到队列里，在push操作上就需要做锁的操作：

```c#
lock(obj)
{
	mQueue.Push(data);
}
```

另一边当主线程在读取网络数据时，当需要推出一个数据时，在推出元素操作上也需要加一个锁的操作。

```c#
Lock(obj)
{
	data = mQueue.Pop();
}
```

由于两边的线程都需要对队列进行操作，所以每次对线程共享的资源进行操作时，都需要先进行锁确认的操作，以避免线程争夺资源而造成混乱。我们拿在海上航行的运输船来做比喻，每个线程都是一条船，每条船都在各自做着自己的事，直到两条船都要进港口卸货，港口几条卸货的通道，它们不得不排队等待前面的船只卸完才能轮到自己，每次它们(可以认为是线程)都会去查看是否有空出来的航线，如果有则先按下标记说我先占了，其他船只在查看时则会看到已被占用的标记则继续等待。

### 缓冲队列

在网络收发时，数据会远远不断进行发送和接收，很多时候程序还没处理好当前的数据包，就已经有许许多多的数据包从服务器已经传送到达了客户端。发送数据也是一样，会瞬间积累很多的需要发送的数据包，这些数据包如果没有保存好则无法进行重发甚至丢失，所以我们需要用一个队列来进行存储和缓冲，它就被称为缓冲队列。

一般我们会让负责接收的子线程把接收好的网络数据包放入接收缓冲队列，再由主线程通过Update轮训去检查接收队列里是否有数据，有的话则一个个取出来处理，没有的话继续轮训等待。

下面伪代码表达了，主线程每帧检查一下是否有收到信息，检测到就立刻处理，没有的话下一帧继续轮训检测。如果没有信息接收来时，子线程上会阻塞等待直到有消息接收到才会调用接收消息接口，将数据包解析后推入接收队列。

```c#
/////////////////////////////////////////////////////////
//接收线程等待接收数据并推入队列
try
{
	socket.BeginReceive( Receive_Callback );
}
catch (Exception e)
{
    Log(LogerType.ERROR, e.StackTrace);
    DisConnect();
}

void Receive_Callback(IAsyncResult  _result)
{
	PushNetworkData(_result); //将数据推入队列
	Receive();	//继续接收数据消息
}

///////////////////////////////////////////////////////////////
//主线程处理数据队列里的数据
void Update()
{
	While( (data = PopNetworkData() )!= null )
	{
		DealNetworkData(data);
	}
}
```

上面的伪代码中，首先有子线程的等待接收数据，接收到数据以后就立即将数据推入队列。另一面，主线程一直在轮询是否有已经接收到的网络数据，如果有就立即逐个处理全部数据。

其中接收数据时会有些细节在里面，因为数据包并不会按照我们希望的大小发送，所以它或多或少的都会拆分一些数据或者粘粘了其他的数据，导致我们需要识别是否是一个完整的数据包，然后再从中解析出正确的数据包。这部分的数据包格式定义我们把它挪到了后面的章节中，在网络协议格式章节中进行详细的讲解。

### 双队列结构

前面提到的缓冲队列是在多线程编程中常用的手段之一，不过它的效率还不够高，因为多个线程的锁的效率影响会被锁点卡住导致其他线程无法继续工作。双队列数据结构就能很好解决这个问题，它能增强多线程中队列的读写效率。

**双队列是一种高效的内存数据结构，在多线程编程中能保证生产者线程的写入和消费者的读出尽量做到最低的影响，避免了共享队列的锁开销。**

在大多数多线程工作时都需要对缓冲队列读写，其中接收数据的网络线程会将数据写入队列，而处理数据的主线程则会读取队列头部并删除(即我们所说的弹出)，两者都会读写队列导致资源争夺，因此通常会增加锁机制来规范它们的行为。但是锁机制导致线程会常常处于等待状态，因为占用的线程需要处理些复杂的逻辑导致其他线程需要暂停很久才能继续工作，因此加入了线程锁的机制后，仍然没能很好的解决两个线程顺畅操作一个队列的问题。实际项目中处理响应数据逻辑的主线程需要花很久的时间去处理网络数据使之反应到画面上，这时接收数据的线程因为接收队列被主线程锁住而不能继续自己的工作去接收数据，所以子线程只能等待资源使用完毕后才能使用资源，当这个接收到数据所需要处理的逻辑很多很复杂时，那么子线程就要等很少时间，大大降低了线程了效率。

用双队列的形式就能让线程处理队列时解放出来，让线程的效率大大增加，使得各线程能够各自处理调用各自的队列处理而不用因为资源锁而等待。双队列与普通的缓冲队列在接收数据包部分的逻辑操作都是一样的，即接收数据线程接收到数据时直接推入接收数据的队列，不一样的地方在当处理数据的线程轮询时，先将接收数据的队列拷贝到处理数据的队列中并清空接收数据的队列，然后主线再对拷贝后的数据队列进行处理，这时子线程无需等待主线程的逻辑处理时间就能够顺利的继续接收数据。这样就解放了两个线程各自工作的冲突时间，即两个队列分别理解为了接收数据队列和处理数据队列，当主线程需要处理数据时，先把接收到的数据队列中的数据置换为处理数据队列上，最后各自继续处理自己的工作因为队列已经分开。

我把最关键部分提取出来用伪代码描述，如下：

```c#
/////////////////////////////////////////////
//子线程中，接收数据线程
void Receive_CallBack(Data _result)
{
	Pushdata(_result);
}

/////////////////////////////////////////
//处理数据的主线程
void SwitchQueue()
{
	lock(obj)
	{
		Swap(receiveQueue, produceQueue);
	}
}

void Update()
{
	SwitchQueue();
	while( (data = PopQueue()) != null )
	{
		Deal_with_network_data(data);
	}
}
```

上述伪代码中，首先是对子线程的接收部分描述，当接收到数据包时与普通的接收一样只需将数据推送到接收队列中即可，当主线程需要处理数据时，先切换队列防止对队列占用过多时间，切换完毕后，再对队列中的全部数据进行处理。

这样一来两个线程在锁上的时间变短了，原本要在处理期间全程上锁导致其他线程无法使用，现在只在切换那一瞬间锁上资源即可，其他时间各线程都能顺畅得各自做自己的工作，这样大大提高了多线程的工作效率。

### 发送数据

我们前面说的都是接收时的队列，发送数据时也需要队列来做缓冲。当发送的数据包会很多时，也有可能很短时间内会积累过多数据包导致发送池溢出。如果发送时大多数的数据包都是很小很小的数据包，如果每个数据包都发送一次等待接受后再发送就会导致发送效率过低，发送太慢导致延迟过大。而如果一下子把全部数据都发送的话，发送的数据可能会太大，导致发送效率很差，因为数据包越大越容易发送失败或丢包，TCP就会全盘否定这次发送的内容，并将整个包都重新发送一次，效率极其糟糕。

因此我们需要自己建立发送缓冲来保证发送的有序和高效，发送队列以及对发送数据的合并就是很好的策略。其具体步骤如下：

```
	1，每次当你调用发送接口时先把数据包推入发送队列，发送程序就开始轮训是否有需要发送的信息在队列里，有的话就发送，没有的话就继续轮训等待。

	2，发送时合并队列里的一部分数据包，这样可以一次性发送多个数据包以提高效率。

	3，对这种合并操作做个限制，如果因为合并而导致数据包太大，也会导致效率差。发送过程中，只要丢失一个数据就要全盘重新发送，数据包很大的话，发送本来就很缓慢的情况下，又重新整体重新发送，就会使得发送效率大大降低，合并的数据的大小限制在窗口大小的范围内(2的16次字节内)。
```

我们既要合并数据包，又不能让数据包太大，这样才能保证发送的效率比较高。比如我们做个合并后的数据包大小限制不得超过10K。这样每个数据包大小都处于10K以下的大小，除非单个包大于10K就让他单独发送，且每次发送包含了多个数据包，这样发送效率就有了一定的保证。

### 协议数据定义标准

在网络数据传输中协议是比较重要的一个关键点，它是客户端与服务器交流的语言。

协议简单来说就是客户端和服务器端商讨后达成一个对数据格式的协定，是客户端与服务器进行交流的语言，假如两边都用Json格式的协议来传输数据，两边都能用根据协议的格式来知道对方传达了什么信息，以及我的信息如何传达给对方。这样两边在发送和收到数据时，都能够按照一定的规则识别数据了。

我们在实现TCP的程序里需要对协议进行商讨，下面讲一下在制定协议过程中的几个关键点：

1. 选择客户端和服务器都能接受的格式。

并不是所有的格式都适合，我们最好选择前后端都能接受的协议格式是最重要的，因为合作最重要，个人力量和一个协议格式的力量与团体来说都是渺小的。在团队都理解和一致的情况下，再对协议进行精进，选择更好更高效的协议。

2. 数据包体大小最小化。

为了尽可能的减少包体的大小，我们应该选择一些能节省包大小空间的格式，比如google protocol buffer 或者其他变种，具体还是要看团队和项目的情况。也可以对已经确定的协议格式，对其协议包的主体部分使用压缩算法，我不建议只加入压缩算法而不改变协议本身，因为这样会导致对压缩算法过度依赖进而省略了协议本身的浪费空间，比如你用了压缩算法后发现xml或json格式的协议也还过得去就不再更改协议本身了，这样就会导致后期数据量大时数据包变得很大很沉重，传输效率降低。但很多老旧的项目和一些为了加快速度而不去更换更好的改协议的项目情况也时常发生，它们只启用压缩算法而不改变协议本身很多时候也是无奈之举。

3. 要有一定的校验能力。

当数据包体不完整时或者本身包体后面连接着另外的数据包时(即粘包情况)，我们要能识别。很多时候我们在传输数据的时候，收到的并不是一个完整的包体，或者因为网络关系，收到了错误的，甚至被攥改过的数据，我们要有能力去校验他们。因此在数据包完整性上，我们要能有校验能力和识别完整包体范围的能力。

我们这里主要聊一下网络数据包的校验能力，各种包体的协议格式会在后面章节中详细讲解。

在接收数据的时候，有时候会是一个不完整的包或者一个包后面跟着另一段不完整的包，我们怎么识别哪里是头部数据，并且数据块是哪些？为了解决这些问题就有了数据格式的意义，通常两端通信的协议数据格式，分为包头和数据块两部分组成，这和我们前面介绍的TCP和UDP的包头数据一样，我们自己定义的格式也需要包头用来作为我们业务层的协议格式。

通常头部数据由4-8个字节组成，里面通常包含了数据包大小，加密方式，广播方式等数据位。其中比较重要的是数据包大小，一般数据大小为4个字节，这4个字节代表的是数据块得大小size，有了这个数据后面数据块得大小就能知道了。因为每次拿到网络数据的时候我们先取头部规定好的几个字节，这样就知道了后面数据块的大小，接着再读取size大小的数据块，这样就拿到了数据信息，如果接收到的数据块大小部满足size大小，则需要继续等待。

比如再做的复杂点，把数据块的标示也融入头重，每个标示为一个2字节的正整数，为了确定调用的是哪个逻辑具柄的，我们可以把数据包分成，头、固定标识信息、数据块，三个部分。头部存储包体大小、加密位、广播方式等信息，标识信息则存储例如句柄编号、序列号、特殊命令编号、校验码等的标识信息；数据块则存储具体的数据信息。

TCP本身有做一些校验的工作，为了防止数据被人为攥改、以及逻辑本身的错误检测，我们有时也需要做额外的校验工作。通常的校验方法有几种：

#### MD5校验。

这种校验方式比较直接，将数据块整个用MD5散列函数生成一个校验字符串，将校验字符串保存在数据包中。当服务器收到数据包时，也对整个数据块做同样的MD5操作，将数据块用MD5散列函数生成一个校验字符串，与数据包中的校验字符串进行比较，如果一致，则认为校验通过，否则就认为被人为修改过。

算法可以用下面的代码表示：

```c#
bool CheckData(byte[] data, string data_md5)
{
	string str_md5 = MD5(data);

	if(str_md5 == data_md5)
	{
		return true;
	}

	return false;
}
```

上述代码中data和data_md5来自数据包中是由发送方计算的值，收到数据后对数据块进行md5操作并与传过来的data_md5字符串进行比较，如果相同则认为校验一致。

#### 奇偶校验。

奇偶校验与MD5有点类似，只是所用的函数方法不同。对每个数据进行异或赋值成一个变量，将这个变量保存在数据包中。当服务器收到数据包时，也对整个数据块做同样的操作，将数据快中的数据进行异或操作并转换成一个变量，然后将这个变量值与数据包中的校验值进行比较，如果数据一致则认为校验正确，否则则认为数据被人攥改过。

这种方式校验相对于MD5比较简单快速，但重复性也比较高，这个校验算法如下：

```c#
unsigned uCRC=0;//校验初始值
for(int i=0;i<DataLenth;i++)
{
	uCRC^=Data[i];
}
```

上述代码中，每个Data中的数据都会与前面操作过的数据进行异或，最终得出一个值就是校验值，客户端与服务器都做同样的操作，如果得出的值时相等的则认为是正确的数据。

#### CRC循环冗余校验。

循环冗余校验是利用除法及余数的原理来进行错误检测的.将接收到的数据组进行除法运算，如果能除尽则说明数据校验正确，如果未除尽，则表明数据被认为攥改过。

该算法步骤如下：

```
	1，	前后端约定一个除数。

	2，	将数据块用除数取余。

	3，	将余数保存在数据包中。

	4，	服务器收到数据后，将余数和数据块相加，并进行取余操作。

	5，	余数为0则认为校验正确，否则则认为数据被攥改过。
```

在数据数组中，对每4个字节的数据合并后除余，得到一个1个字节以内的余数，每4个字节得到1个字节的余数，最终得到一组余数数组。校验时反向操作，先取4个字节的数据组成一个正整数加上对应的余数，再除余操作，如果不为零则校验失败，如果全部为零则校验成功。

4. 加密。

为了保证网络数据包不被篡改和查看，导致外挂破坏整个游戏平衡，我们需要对发送的网络数据包中的主体部分进行加密。加密算法很多，包括RSA，公钥私钥，以及非对称加密等，其中最简单也是最快的加密方式就是对数据做异或处理，由于数据两次异或处理就能使得数据回到原形，所以算法中常使用异或的操作来做加密。通常做法是发送时对数据做异或处理一次，收到时再做一次异或处理，这样就能简单快速加密解密数据。

前面说的这种方式密钥Key是同一个，通常大多数加密都使用秘钥的概念，秘钥的Key常常会暴露在外界导致一些不怀好意的人会在客户端上破解并查看秘钥从而知道网络数据协议的格式进而可以进行一些捣乱，所以前后端同使用一个秘钥Key会比较危险，于是非对称加密是加密会比较安全，这样前后端两边的密钥Key不同且各自保存，即使当前端密钥泄漏了也可以随时替换。但仍然无法避免前端的秘钥暴露在外面被人破解，于是如何隐藏这个秘钥键值成了重要关键，很多人写入代码中编译进程序里，如果是C#代码由于它是先翻译为IL语言的，因此很容易用IL翻译的方式反向得出代码内容，也有人把秘钥用c或c++编译放入额外的so文件中，这种确实加大了破解的难度但也不是没有办法破解。所以我们仍然需要不断加大破解的门槛，比如把秘钥分为几段分别用几种方式隐藏在项目文件中，用多种加密方式对秘钥加密，让关键秘钥在获取前再做加密等等，我们应该详尽办法用各种手段达到通常人能想到的解密思路，加大了破解的门槛最好能让黑客望而生畏。

最后还是要关注下加密导致的性能损耗问题，如果加密的性能损耗过大那就得不偿失了，所以我们仍然希望加密的过程是快速的，在不损耗大量CPU前提下，不影响项目性能的情况下对协议数据做最大化的加密工作。

### 断线检测

TCP本身就是强连接，所以自身就有断线的检测机制，但是它本身的检测机制还不够好，时常会因为网络问题导致断线的判断不够及时，所以我们在编写TCP长连接的程序时需要加强断线检测机制，让断线判断变的更加准确及时。

为了能有效检测TCP连接是否正常，我们需要服务器和客户端共同达成一个协议来检测连接，我们把这个共同达成的协议取名叫心跳包协议。在心跳包协议中，每几秒服务器向客户端发送一个心跳包，包内包含了服务器时间、服务器状态等少量信息，然后由接收到这个心跳协议的客户端做反馈，发送给服务器一个心跳回应包，包内也包含客户端的少量信息例如客户端状态、用户信息等。两边的终端上的逻辑可以就此达成共识，认为当收到心跳信息时认为连接时存在的，当服务器30秒没有收到任何反馈心跳包的信息则认为客户端已经断线，这时主动断开客户端的连接。客户端这边也是同样的协定，当客户端30秒内没有接收到任何数据包时则认为网络已经断开，客户端最好主动退出游戏重新登陆重新连接服务器。

通常当网络异常时，客户端和服务器都很难断定连接是否依然存在，因此需要用这种机制来加以判定，例如在ios中APP可以随时切出屏幕并不关闭游戏，或者直接关闭应用不给服务器任何解释，服务器自然收不到断开连接的请求。面对各种异常的情况，我们制定的心跳包和心跳回应来判定是否仍处于连接的状态，倘若没有收到心跳包和心跳回应包，就表示连接存在问题了，有可能已经断开。为了规避一些时候网络的波动，我们可以设置一个有效判断断开连接的时间间隔，比如，10秒内没有收到心跳包和心跳回应包，就表示连接已经断开，这时服务器和客户端主动断开连接，客户端可以根据游戏的逻辑先退出游戏再重新登陆寻求再次与服务器连接。

心跳协议在TCP之上，加强了断线检测的准确性，能更有效快速的检测到断线问题。

## 实现UDP

### 连接确认机制

TCP有连接的三次握手协议，相当于在连接过程中跟服务器端协商后敲定我们已经建立了连接这个一致预期，而UDP是无状态链接，它并没有三次握手的协议，所以可以说UDP的连接其实是一厢情愿的，客户端并不知道是否真正连接成功了，如果由于网络异常原因没有连接上，就会导致收发失败。其实怎么确认UDP连接上了服务器，这才是我们想要得到的反馈，我们需要准确的得知UDP连接是否已经成功连接上服务器，因此这个连接确认机制必不可少。

发送和接收如果建立在连接确认的基础上则会更加牢靠，因此我们必须先确认知道我们是否连接成功。能够判断连接是否成功是整个实现UDP的第一步，只有这样才能顺利得进行下面的数据包收发操作。

我们应该怎么确认连接成功

很简单我们可以模仿TCP的确认连接机制，我们来看看TCP连接的三次握手在数据包上是怎么做的。

1. 首先客户端向服务器端发送一个数据包，里面包含了Seq=0的变量，表示当前发送数据包的序列号为0，也就是第一个数据包。

2. 务器端收到客户端的数据包后，发现Seq=0，说明是第一个包是用来确认连接的，于是给客户端也发送了一个数据包，包含了Seq=0，和Ack=1，表示服务器端已经收到客户端的连接确认包了，并且回应包Ack序列标记为1。

3. 当客户端收到服务器端给的回应数据包后，知道了服务器端已经知道我们想要并对方已经建立连接，于是向服务器端发送了一个数据包，里面包含了Seq=1，Ack=1，表示确认数据包已经收到，连接已经确认，开始发送数据。

以上就是TCP的三次握手来确认连接的流程在数据包中的体现。

在UDP下它自身并没有三次握手机制，为了建立更好的确认连接机制，我们可以模仿TCP三次握手的形式来确认连接。不过第3次握手稍微有点多余，我们可以省去最后一次握手的数据包，改为2次握手。步骤如下：

首先在UDP打开连接后，在确认连接前不进行任何的其他类型的数据发送和接收，我们将这种发送数据包以确认连接成功与否的数据包称为握手包。

在打开连接后，客户端先向服务器端发送一个握手数据包，代表客户端向服务器端请求连接确认信号的数据包，包内的数据仅仅是一个序列号Seq=0，或者不是序列号也行，它可以是一个特殊的字段。只要当服务器端收到这个握手数据包后能够识别该数据包为连接确认的握手包，也就是实现了第一次握手。

服务器端在收到第一次握手数据包后，需要向客户端反馈一个握手数据包，里面同样带有客户端能识别的连接确认信号。当客户端接收握手数据包时说明发出去给服务器端的连接确认数据包有了反馈，并且收到了服务器握手数据包的反馈，也就是说第二次握手成功。在接收到了这个第二次握手连接确认数据包时，双方都可以认为是连接已经成功建立。

整个UDP确认连接的握手过程，就相当于客户端和服务器端的一次交流，相互认识一下并且示意双方后面的交流即将开始。

经过与服务器端数据包的来回，UDP完成了2次握手的确认机制，已经可以认定为连接已经成功建立，这里是正常数据包处理过程，包括识别，装载，推入队列，检测是否丢失，是否需要重发等。

### 检测连接是否依旧存在

UDP自己不能判断连接是否断开，因为它是无状态的连接，打开即完成连接关闭即完成断开，因此需要我们自己来做断线检测，检测的方式也与我们前面说的如何主动检测TCP连接状态的心跳包类似，因为这种方式是花费最小的代价并且能够及时准确的确认连接的方式。因此UDP检测连接的判定机制，也可以用数据包来回的形式，不过这次不像握手数据包那样只是单一一个数据包，而是持续的心跳包的形式来做持续的判断连接状态。

首先，我们要与服务器端有个协定，每隔X秒（比如5秒）发送一个心跳数据包给服务器端，这个客户端发送的心跳数据包里包含了一些客户端信息，包括ID，角色状态，设备信息等，包体不能太大，否则会就加重了宽带负担。

当服务器端收到心跳数据包时，也立刻回复一个心跳数据回应包，里面包含了，服务器端当前时间，服务器端当前状态等信息。客户端收到此数据包时，说明连接尚在，也能同时同步服务器端的时间和一些基础的信息。

如果客户端很久没有收到心跳数据回应包时，就表明，连接已经断开了，比如30秒没收到心跳包，可以判断连接已经断开。服务器端也是一样操作，当没有收到心跳包很久，就表明客户端的连接已经断开。这时客户端就可以开启相应的重连程序，或重连提示以及步骤。

步骤可以分为如下4步：

```
    1.每隔X秒向服务器端发送心跳数据包。

    2.服务器端收到心跳数据包后回复心跳响应数据包。

    3.如果客户端和服务器端都很久没有收到心跳数据包，比如30秒，则判定连接断开。

    4.当判定为连接断开，则主动断开连接并发起断开连接事件，通知客户端提示用户，或者重新创建连接，服务器端则是处理与之相关的数据处理操作。
```

这里不只是客户端主动发送数据包给服务器，也可以反过来服务器主动发送数据包给客户端的形式检测连接是否断开。

### 数据包校验与重发机制

我们前面说UDP相当于是TCP的阉割版，其中UDP最关键的阉割部分就是校验和重发机制。没有校验和重发机制，意味着发送端无法知道数据包的发送是否到达，丢失了也无法重新发送的机制来补充丢失的数据包，因此我们需要自己编写增加对数据的校验和重发机制来确保数据的可靠性。

TCP已经有校验和重发机制，我们可以模仿它的校验和重发机制，把它搬到UDP上，并在此基础上加以改进，这样我们即有了UDP的速度，又有了TCP的可靠性。

我们先来看看TCP是如何做数据包的校验和重发的：

先解释几个英文名词Seq和Ack。Seq即Sequence Number，为源端（source）的发送序列号；Ack即Acknowledgment Number，为目的端（destination）的接收确认序列号。

1.首先A端向B端发送数据包，TCP的包头中里面包含了字段Seq(sequence number)序列号值为1(即已经发送的数据包的累计大小)，比如这次A向B发送的数据包大小为264，则size大小为264。

2.B端收到传过来的数据包后，知道了当前连接的这个数据包的序号为1，也就是连接后第一个数据包。于是向A端发送了一个确认包，确认包中包含了的Ack=264(接收到的数据包的累计大小)，告诉A端我B端已经收到了数据包，现在累计接收大小为264的数据包。

3.A端收到B端发来的确认数据包时，会检测累计发送大小和累计接收大小是否一致，如果发现累计接收大小与累积发送大小不一致则认为传输错误启动重传机制，退回到最后一次正确的的数据包位置进行重传，以保证可靠性。

4.如果大小比较一致，则认为B端准确收到了数据包，A端可以继续发送其他数据包，当再次发送时里面包含的Seq序列号更改为了265，意思为累计发送数据大小，假如这次发送的数据包大小为100，则size字段填写100，B端接收到后再向A端发送确认包，确认包中包含了Ack=365，意思是已经累计收到数据包大小为365。当A端收到确认包时会先对比一致性，如果累计大小错误，请启动重传机制，确保可靠性。以此类推

5.如果是由B端向A端发送数据也是同样的步骤。B端向A端发送数据也是同样的方法和步骤。数据包中包含了B端的Seq(已经发送的数据包大小)，比如累计发送了1，seq=1，这次数据包大小为585，A端接收到B端的数据包后，向B端发送确认包，包中包含了B端发过来的Ack =586，B端收到确认包后，就知道了累计接收的数据包大小已经到了585，也就是说当前的数据包已经发送成功。如果累积发送和累积接收数据不一致则启动重发机制，从最近的正确确认点开始发送数据。

序列号确认机制是TCP可靠性传输的保障，除了累积接收大小和累积发送大小的比较外，若在规定的时间内收到确认数据包就表明该报文发送成功，可以发送下一个报文，如果超过时间则启动重传（TCP Retransmitssion）。

我们可以借鉴TCP的方法，UDP也可以用此方法来做检测和重传。不过TCP接收和发送累积大小的检测方式使得重传量比较大，一旦会导致失败重传整个数据，重传内容太多。因此它不能准确快速的定位重传的数据包，由于中间数据包的丢包，导致已经到达的数据也需要重传，这种类型的可靠性保证的依赖于消耗大量的带宽消耗。

因此我们在实现UDP的检测和重传时，我们可以进行如下的改进。

1.A端向B端发送数据包，数据包中包含Seq=1(表示数据包的发送序列)，发送后将此数据包推入到已经发送但还没有确认的队列里。

如果B端接收到Seq=1的数据包，就回应客户端一个确认包，包中Ack=1，表示Seq=1的包已经确认收到。

如果B端没有接收到数据，客户端X秒后发现仍然没有收到Seq为1的确认包，判定为Seq=1的数据包传输失败，从已经发送但未确认的数据包队列中取出Seq=1的数据包，重新发送。

2.例如A端向B端发送了10个数据包，分别是Seq=1，2，3，4，5，6，7，8，9，10，服务器收到的序列是，1，3，4，5，7，8，9，10，其中有2，6，没有收到数据包。

A端在等待确认包超时后，对2，6进行重传。在B端接收到数据包后，处理数据包时，如果数据包顺序有跳跃的现象就表明数据包丢失，就等待A端重传，这时就在断开的序列处停止处理数据包，等待重传数据包的到来。

3.B端也可以做加快重传确认时间的处理。A端向B端发送5个数据包，分别是Seq=1，2，3，4，5，B端收到的包的序列是1，3，4，5，当收到3时，发现2被跳过1次，当收到4时发现2被跳过2次，立刻向A端发送确认包要求启动2的重传，这样就加快了丢包重传的确认速度。

### 丢包问题分析

UDP丢包多是很正常现象，这是UDP牺牲质量而提高速度的代价。UDP丢包的原因很多，我们这里做个分析。

1. 接收端处理时间过长导致丢包：

当调用异步接收数据方法接收到数据后，处理数据会花去一些时间，处理完后再次调用接收方法，在这二次调用间隔里发过来的包可能会丢失。

要解决接收方丢包的问题其实很简单，首先保证程序执行后马上开始监听（如果数据包不确定什么时候发过来的话），其次要在收到一个数据包后最短的时间内重新回到监听状态，其间要尽量避免复杂的操作。

对于这种情况可以修改接收端，将包接收后存入一个缓冲区，然后迅速返回继续开启接收线程。或者使用前面提到的双队列机制，来缩短锁队列的时间从而解放了处理包的时间和接收数据包的线程之间的冲突，让两个线程能迅速回到自己的‘岗位’上做自己的事。

2. 发送的包巨大导致丢包概率加大：

虽然Send方法会帮我们做大包切割成小包发送的事情，但包太大也不行。例如超过50K的一个udp包，不切割直接通过send方法发送也会导致这个包丢失。

发送的数据包较大是个危险的行为，如果超过接收者缓存将大概率导致丢包，一般当包超过MTU大小的数倍就会增大丢包的概率。

什么是MTU，即Maximum Transmission Unit的缩写，意思是网络上传送的最大数据包。大部分网络设备的MTU都是1500，如果本机的MTU比网关的MTU大，大的数据包就会被拆开来传送，这样会产生很多数据包碎片增加丢包率，从而增加重发概率导致降低网络速度。

报文过大的问题可以通过控制报文大小来解决，使得每个报文的长度小于MTU。以太网的MTU通常是1500 bytes，其他一些诸如拨号连接的网络MTU值为1280 bytes，如果使用speaking这样很难得到MTU的网络，那么最好将报文长度控制在1280 bytes以下，这些都是经验之谈。

3. 发送的包频率太快：

虽然每个包的大小都小于MTU大小但是频率太快，例如40多个MTU大小的包连续发送中间不休眠，也有可能导致丢包。

这种情况可以通过建立Socket接收缓冲队列解决，以及通过建立发送缓冲队列来解决，并且在发送频率过快的时候考虑线程Sleep休眠一下作为时间间隔。

这里有些人会不理解发送速度过快为什么会产生丢包，原因是UDP的发送数据是不会造成线程阻塞的，也就是说UDP的发送不会像TCP中的发送数据那样直到数据完全发送才会返回回调用函数，UDP并不保证当执行下一条语句时前面的数据是否被发送，它的发送接口是异步的。

如果要发送的数据过多或者过大，那么在缓冲区满的那个瞬间要发送的报文就很有可能被丢失，一般一秒钟几个数据包不算什么，但是一秒钟成百上千的数据包就不好办了。

## 封装HTTP

### HTTP协议原理

HTTP俗称短连接，由于其平均连接的时间较短，不受前端所控制，所以在游戏圈内通常被冠以‘短’字开头。

在Unity3D中编写短连接可以用.NET库来编写，也可以用Unity3D的内置API的WWW来写，差别不是很大。WWW对.Net做了封装，其功能已经完全够用在游戏开发上了，即使有情况不够用再用.NET补充也是相对容易的事。然而作者在编写书本时，WWW已经在2018及以后的版本中都被废弃了，取代它的是UnityWebRequest，Unity3D对网络请求重新做了封装。

WWW与.NET两者的区别主要还是WWW把.NET库封装后再加了层协程的封装，这会使我们开发者在使用时更加的便捷，而.NET库则直接用了线程，开发者需要关注主线程与子线程的资源抢占情况。总的来说WWW经过封装后使用更佳便捷，使用.NET编写HTTP则需要我们自己关注更多细节。

**不管协程还是线程，其实两边都需要用到缓存和队列这样的缓存机制，倘若没有缓存机制当网络请求量放大时就会出现混乱以及数据丢失的情况，因此缓存机制在网络层是不可或缺的。**

我们所说的HTTP，最形象的描述就是网页(Web)形式的请求与回调，它被运用最多的就是网页(Web)请求上。HTTP是一种 请求/响应式 的协议。也就是说，请求通常是由像浏览器这样的用户代理User- Agent发起的，当用户接收到服务器的响应数据后，通过这些数据处理相应的逻辑再反应到画面上，其特点为每个请求都是一一对应的，一个请求有且最多只能得到一个响应。

我们来看看浏览器是如何用HTTP工作的，当我们要展示一个网页内容时，浏览器首先向服务器发送一个HTTP请求并且带上参数，目的是从服务器获取页面的HTML内容，获得HTML美容后再解析其中的资源信息接着发送获取这些资源信息的请求，例如获取可执行脚本、CSS样式资源的请求，以及一些其它页面资源（如图片和视频等）。最终浏览器会将这些资源通过HTML语言规则的形式整合到一起，从而展示一个完整的网页。除了这些浏览器执行的脚本JavaScript也可以在之后的阶段不断发起更多的请求来获取更多信息和资源，不断的叠加、更新到当前的网页内容上。

我们常常会在游戏项目中把这套 请求/响应式 协议搬到了游戏中运用，其最重要的原因是HTTP简单易用，程序员们上手的成本低，功能扩展难度也低，因此被广大互联网程序员所喜爱。

HTTP是应用层上的协议，它需要底层的传输层协议是可靠的，因此 HTTP 依赖于面向连接的TCP协议进行消息传递。HTTP是应用层上的协议就是因为它本身并没有检测是否连接，数据是否传输准确，是否有数据到达等的机制，这些都依赖于传输层的协议TCP协议，由TCP协议来做这些传输层的事情，而HTTP只是在TCP之上制定了自己的规则。

### TTP 在TCP之上制定了的规则：

HTTP制定了自己的协议格式，协议分为**HEAD和BODY**两块

```
    GET /root1/module?name1=value1&name2=value2 HTTP/1.1
    Host: localhost:8080
    Accept-Language: fr

    //这里 HEAD 和 BODY 用空行隔开

    body content
```

如上协议所示其中 GET 为向服务器请求的参数方式，HTTP有2种参数请求方式，分别是GET 和 POST。**GET请求方式把参数值以 Key-Value 的键值对形式放在地址中传输给服务器**，它的格式是

```
    ?Key1=Value1&Key2=Value2&...
```

以问号’?’开头作为Get参数格式的开始，接下去每个Key=Value之间用与’&‘符号作为分隔，所有的表达式都是以字符串形式存在。如上文中

```
    GET /root1/module.php?name1=value1&name2=value2 HTTP/1.1
    Host: localhost:8080
    Accept-Language: fr
```

就是个很好例子，表达了访问的客户端要访问 Host地址为 localhost:8080 的服务器，采用GET形式传参，访问子地址为 /root1/module 并且参数为 ?name1=value1&name2=value2，采用HTTP1.1的协议逻辑，最后 Accept-Language: fr 客户端支持法语。

**POST则是把参数值放在协议数据包中**，存放也同样以Key=Value的字符串形式存在，不一样的地方为**POST可以使用二进制作为参数值并且存放在Body上**，body content是主要存储请求内容的，POST内容都放在这里，而GET则必须以字符串形式明文显性的展示在地址上。

```
    POST /root1/module.php HTTP/1.1
    Host: localhost:8080

    name1=value1&name2=value2
```

如上述POST例子所展示的那样，其实两者的实质是一样的，都是以Key1=Value1&Key2=Value2的形式作为请求内容，并且请求的参数都会被写入请求包体中，只是Get必须暴露在地址上而已。

服务器在收到客户端请求并处理相应逻辑后发送响应数据，其数据格式为：

```
    HTTP/1.1 200
    Date:Mon,31Dec200104:25:57GMT
    Server:Apache/1.3.14(Unix)
    Content-type:text/html
    Last-modified:Tue,17Apr200106:46:28GMT
    Content-length:xxx
    
    //这里HEADS 和 BODY用空行隔开
    body content
```

例子是服务器端响应客户端请求的处理后的应答数据，里面包含了HTTP的版本，Date日期，Server服务器类型，Content-type内容类型，Content-length内容长度，body content内容主体，其中200为响应后代表请求成功的错误码，其他常用的错误码可以简单理解为 404 找不到请求页，500 服务器程序报错，400 访问请求参数错误，403 被拒绝访问。

### HTTP1.0，1.1，2.0的简述

上文的例子中 HTTP/1.1为HTTP协议的版本号，我们现在常用的协议为1.1，也有少部分仍然在使用HTTP1.0。我们常用的HTTP1.1兼容了1.0，并且在1.0之上改进了诸多内容，比如同一个地址不同host，增加了cache特性，增加Chunked transfer-coding标志切割数据块等。而2.0由于和1.1差别比较大，它并不能兼容1.0和1.1，因此HTTP的世界就像被分成了两块，HTTP2.0被运用在HTTPS上，而HTTP1.1和1.0则运行在原有的HTTP上。

腾讯高级工程师杨良聪在他的一篇文章中对HTTP不同版本的问题做了很好的解释。在HTTP1.0中，一个请求就独占一条TCP连接，要并行的获取多个资源就需要建立多条连接。HTTP1.1则引入了持久连接和管线化，允许在应答回来之前就按顺序的发送多个请求，但是服务器端按照请求的顺序发送应答。在同一个TCP连接上，及时后面的请求先处理完，也必须等待前面的应答发送完毕后，才能发送后面的应答，这就是HTTP1.1的队首阻塞问题。HTTP1.0，1.1都是用了文本形式的协议，也就是所有数据都是以字符串形式存在，这样做的导致协议传输和解析效率不高。不过对于这种文本形式的协议体，我们可以通过压缩来减少数据传输量，但对于协议头我们无法压缩，这使得对于那些Body内容比较少的应答数据来说，很可能协议头的传输成为了首要的性能瓶颈。

HTTP2.0则引入了Sream概念，这使得一个TCP连接可以被多个Stream共享，每个Stream上都可以跑单独的请求与应答，从而实现了TCP连接的复用，即单个TCP连接上可以并行传输多个请求与应答数据。另外HTTP2.0不再使用文本协议而采用了二进制协议这使得协议更加紧凑，协议头也可以做到压缩后再传输，减少了数据传输带来的开销。不仅如此，HTTP2.0还可以支持Server端的主动Push，进一步减少了交互流程，以及支持流量控制，并引入了流的优先级和依赖关系，这使得我们能够对流量和资源进行较为细致的控制。

### HTTP无状态连接

HTTP的无状态是指对于事务处理没有记忆能力，前后两次的请求并没有任何相关性，可以是不同的连接，也可以是不同的客户端，服务器在处理HTTP请求时，只关注当下这个连接请求时的可获取到的数据，不会去关心也没有记忆去关联上一次请求的参数数据。

HTTP的访问请求一般都会有软硬件做负载均衡来决定访问哪台物理服务器，进而两次同样地址的访问请求，有可能处理这两次请求的服务器是不同的。而无状态很好的匹配了这种近乎随机的访问方式，也就是说HTTP客户端可以任意选择一个部署在不同区域的服务器进行访问，得到的结果是相同的。

### HTTP每次请求访问结束都有可能断开连接

在HTTP1.0和1.1中，HTTP是依据什么来断开连接的呢？答案是content-length。content-length为 heads 上的标记，表示 body 内容长度。带有content-length 标签的请求，其body内容长度是可知的，客户端在接收服务器回应过来的数据body内容时，就可以依据这个长度来接受数据。在接受完毕后这个请求就完毕了，客户端将主动调用close进入四次挥手断开连接。假如没有content-length 标记，那么body内容长度是不可知的，客户端会一直接受数据，直到服务端主动断开。

HTTP1.1在这个断开规则之上又扩展了一种新规则，即增加了Transfer-encoding标记。如果Transfer-encoding为chunked，则表示body是流式输出，body会被分成多个块，每块的开始会标识出当前块的长度，此时body不需要通过content-length长度来指定了。如果HEADS上带有Transfer-encoding:chunked 就表示body被分成很多块，每块的长度也是可知的，当客户端根据长度接受完毕数据后再主动断开连接。假如说Transfer-encoding 和 content-length 这两个标记都没有，那么就只能一直接受数据直到服务器主动断开连接。

那么可不可以使用HTTP协议又不断开连接的方式？还有HEAD里的keep-alive标识，keep-alive标识会让客户端与服务器的连接保持状态，直到服务器发现空闲时间结束而断开连接，在结束时间内我们仍然能发送数据。也在就是说，可以减少多次的与服务器3次握手建立连接的消耗，以及多次与服务器4次握手断开连接的消耗，提高了连接效率。

另外一面在服务器端上，Nginx的 keepalive_timeout，和Apache的 KeepAliveTimeout 上都能设置 Keep-alive 的空闲时间大小，当httpd守护进程发送完一个响应后，理应马上主动关闭相应的TCP连接，但设置 keepalive_timeout后，httpd守护进程会说：”再等等吧，看看客户端还有没有请求过来”，这一等，便是 keepalive_timeout时间。如果守护进程在这个等待的时间里，一直没有收到客户端发过来HTTP请求，则关闭这个HTTP连接。不过也不一定说使用 keep-alive 标识能提高效率，有时也会反而降低了效率，比如经常会没有数据需要发送，导致长时间的Tcp连接保持导致系统资源无效占用，浪费系统资源，巨量的保持连接状态就会浪费大量的连接资源。

倘若我们客户端使用keep-alive做连续发送，则需要在连续发送数据时使用同一个HTTP连接实例。并且在发送完毕后要记录空闲时间，以便再次发送时，可以判断是否继续使用该连接，因为通常服务器端主动断开连接后并没有被客户端及时的得知，所以自行判断是否有可能已经被服务器端断开连接为好。还有一个问题是，如果网络环境不好导致发送请求无法到达时，则要尽可能的自己记录和判断，哪些数据是需要重发的。这几个问题增加了HTTP作为keep-alive来保持连接的操作难度，将本来简单便捷的HTTP，变得使用更加困难，因此这也是keep-alive并不常使用在游戏项目中。

### 在Unity3D中的HTTP封装

Unity3D的2018版本中将原本经常用的WWW类废弃了，取而代之的是UnityWebRequest。其实API改了但功能都是一样的，我们主要还是围绕HTTP的原理来写程序，也只有这样才能真正写出程序的精髓。

UnityWebRequest里有几个接口对我们来说比较重要，一个是

```
    Post(string uri, WWWForm postData)接口
```

用来创建一个带有地址和Post数据的UnityWebRequest实例，一个是

```
    SendWebRequest()
```

用来开始发送请求和迭代请求的接口，另一个是

```
    SetRequestHeader(string name, string value)
```

调用它可以设置HTTP的标签头，其中Unity3D官方说下面这些HEAD标记在UnityWebRequest中并不支持：

```
    These headers cannot be set with custom values on any platform: accept-charset, access-control-request-headers, access-control-request-method, connection, date, dnt, expect, host, keep-alive, origin, referer, te, trailer, transfer-encoding, upgrade, via.
```

我们来看看这些标签都是代表什么功能：

```
    accept-charset: 用于告诉服务器，客户机采用的编码格式

    access-control-request-headers: 在预检请求中，用于通知服务器在真正的请求中会采用哪些请求首部

    access-control-request-method: 在预检请求中，用于通知服务器在真正的请求中会采用哪种 HTTP 方法

    connection: 处理完这次请求后是否断开连接还是继续保持连接

    date: 当前时间值

    dnt:  (Do Not Track) 表明了用户对于网站追踪的偏好。

    expect: 是一个请求消息头，包含一个期望条件，表示服务器只有在满足此期望条件的情况下才能妥善地处理请求。服务器开始检查请求消息头，可能会返回一个状态码为 100 (Continue) 的回复来告知客户端继续发送消息体，也可能会返回一个状态码为417 (Expectation Failed) 的回复来告知对方要求不能得到满足。

    host: 请求头指明了服务器的域名(对于虚拟主机来说)，以及服务器监听的TCP端口号。

    keep-alive: 允许消息发送者暗示连接的状态，还可以用来设置超时时长和最大请求数。

    origin: 指示了此次请求发起者来自于哪个站点。

    referer: 表示当前页面是通过此来源页面里的链接进入的，与origin相似。

    te: 指定用户代理希望使用的传输编码类型

    trailer: 允许发送方在分块发送的消息后面添加额外的元信息，这些元信息可能是随着消息主体的发送动态生成的，比如消息的完整性校验，消息的数字签名，或者消息经过处理之后的最终状态等。

    transfer-encoding: 指明了将 entity 安全传递给用户所采用的编码形式。transfer-encoding是一个逐跳传输消息首部，即仅应用于两个节点之间的消息传递，而不是所请求的资源本身。一个多节点连接中的每一段都可以应用不同的Transfer-Encoding 值。

    upgrade: 升级为其他协议

    via: 代理服务器相关的信息
```

以上这些由HEAD扩展的HTTP功能都不能进行自主的选择，其中包括了我们比较关心的标识 connection 和 keep-alive 保持连接的功能，这同时说明我们无法用UnityWebRequest来实现一次连接发送多次数据的需求。另外我们比较关心的content-length也不能被自定义设置，它会由API本身来自动设置。与原来WWWW的API不同的是，UnityWebRequest更加简洁方便，但也失去了一些自定义的功能。接下来我们就使用UnityWebRequest来封装HTTP网络层。

我们先设计一个类，假如建个名称为HTTPRequest的类，它最重要的功能是向指定服务器发送请求并接受响应数据，每次请求服务器都调用这个类的方法来处理一个请求的操作。我们可以通过 HTTPRequest 这个类把地址、参数、回调句柄传进去，然后等待服务器响应数据，当收到响应数据时就调用相应游戏逻辑做处理从而反应到画面上。

HTTP需要的接口相对较少，其中POST(以POST方式发送数据)、GET(以GET方式发送数据)、HEAD(修改某个HEAD标签值)、Start(开始发送请求) 这几个接口比较重要，这些我们都可以在 UnityWebRequest 中对应的是函数句柄。

```c#
POST: UnityWebRequest UnityWebRequest.Post(string uri, WWWForm postData) (静态函数)

GET: UnityWebRequest UnityWebRequest.Get(string uri) (静态函数)

HEAD: UnityWebRequest.SetRequestHeader(string name, string value) (非静态函数)

Start: UnityWebRequest.SendWebRequest() (非静态函数)
```

用这四个API实现HTTP基本的发送与接收足以。

在使用 UnityWebRequest 发送请求时可以用协程也可以在逻辑更新中进行判断收发过程。只是根据我个人经验在协程中不太可控，每次都起一个协程来发送请求数据也有点浪费，在一些特殊需求下协程结束时随着函数调用结束而结束的，而我们时常会有需要暂停、而后继续操作等无法满足。所以一般都会把HTTP的收发判断移到脚本更新函数Update里去，这样做更容易掌控也更容易理解。

下面我们建立一个类来封装 UnityWebRequest 的收发过程：

1. 建立实例开始连接和发送请求，设置好这次请求回应的回调句柄。

```c#
void StartRequest(string url, Callback _callback)
{
    this.web_request = UnityWebRequest.Get(url);
    this.Callback =  _callback;
    this.web_request.SendWebRequest();
}

or POST

void StartRequest(string url, WWWForm wwwform, Callback _callback)
{
    this.web_request = UnityWebRequest.POST(url, wwwform);
    this.Callback =  _callback;
    this.web_request.SendWebRequest();
}
```

上述代码中我们实例化了一个HTTP请求，并且把地址和参数内容传给了实例，然后设置数据响应时的回调句柄，最后发送请求。

2. 判断是否完成或者说发送请求是否完毕,并且调用回调函数

```c#
void Update()
{
    if(web_request != null)
    {
        if(web_request.isDone)
        {
            ProcessResponse(web_request);
            web_request.Dispose();
            web_request = null;
        }
    }
}
```

这里我们在脚本更新函数 Update 中不断去判断当前的请求实例是否完成并有响应数据，当收到响应数据时则调用处理函数对数据进行逻辑处理。

3. 处理数据，收到响应数据后先判断是否有错误存在，没有错误再对数据进一步处理。客户端与服务器之间的数据传输都需要有协商好的协议，通常HTTP上使用Json格式的比较多，我们在收到响应数据后对数据进行解析然后变为了具体实例，再传给相应的函数句柄进行调用，所以数据格式协议也是比较重要的关键，关于数据协议我们会在下面的章节中详细的讨论。

```c#
void ProcessResponse(UnityWebRequest _WebRequest)
{
    if(_WebRequest.error != null)
    {
        NetworkErrorReport(_www.error);
        return;
    }

    NetData net_data = ParseJson(_WebRequest.downloadHandler.text)

    CallbackResponse(net_data);
}
```

以上是用UnityWebRequest做HTTP请求的基本步骤。在具体项目中看似简单的连接、发送、接收过程有不少事情需要我们扩展，特别是游戏逻辑中大量多次频繁发送HTTP请求导致的效率问题需要我们更多的关注。

### 多次请求时连续发送HTTP请求引起的问题

多次或者连续请求HTTP在具体项目中比较常见，例如客户端向服务器请求角色信息，并同时请求军团信息，并同时请求每日任务信息，收到所有数据后将数据呈现在主界面上。像这样的连续多次的发出HTTP请求，会同时触发多个线程向服务器做请求操作，每个请求都包括建立连接、发送数据、接受数据、关闭连接这几个步骤，多个请求导致多个线程最后得到服务器响应的返回数据时，却不知道哪个在先哪个在后，例如军团信息有可能先得到响应，然后再是每日任务信息得到了响应，再是角色信息得到了响应，因为是多个线程发起的多个连接，服务端接收到的数据也会因为受到网络的干扰而导致顺序不正确，即使服务器端接收的请求数据顺序刚好没有被打乱顺序，在处理和回调的数据时也是不可知的，这导致回调的顺序不可知，所以多连接导致不能确定响应的顺序与请求的顺序是否一致。

当接收响应数据的顺序无法确定时，我们还用顺序接收数据的方式处理就会发生问题，例如前面我们说的在发送，军团，任务，角色数据请求后，希望能够在三者都到齐的情况下执行某个程序逻辑，倘若得到的数据是顺序的话，我们在收到角色数据后就能确定所有数据都已经到齐，到时我们再执行逻辑程序也会是正确的。

那么怎么在多开请求连接的情况下保证顺序呢？

**解决方案1：多个连接同时发送请求数据，等待所有数据到齐后再调用执行逻辑。**

每个HTTP(也可以认为是UnityWebRequest)请求都会开一个线程来向服务器请求数据，多个HTTP请求同时开启，相当于多个线程同时工作这样能提高网络利用率，但同时也有数据响应顺序混乱的隐患。多个请求后等待数据全部到齐后再处理逻辑，是一个比较普遍的解决多请求数据响应的方式。不过我们仍然要假设多次请求之间没有且不需要逻辑顺序，逻辑只需要它们收集齐数据后再做执行操作，只有这样我们才可以使用同时发起多次HTTP请求后等待所有请求结束后再做逻辑处理。

多次请求的响应数据后等待处理的解决方案其本质是‘如何判断我们需要的多条数据是否已经都到达’。为了能更快的、更高效的得到HTTP请求数据，在同一时间同时向服务器发起多个HTTP请求，并且等待所有请求都得到响应后再执行逻辑程序。

这种方式我们可以用伪代码及注释来表述得更清楚些：

```c#
class Multiple_Request
{
    void StartRequest( request_list, call_back )
    {
        lst_req = new List<UnityWebRequest>();
        for( url,wwwform in request_list )
        {
            //开启多个HTTP请求
            UnityWebRequest req = UnityWebRequest.Post(url, wwwform);
            req.SendWebRequest();

            //记录请求实例
            lst_req.Add(req);
        }

        //记录回调函数
        Callback = call_back;
    }

    void Update()
    {
        if(lst_req == null || lst_req.Count <= 0) return;

        for( UnityWebRequest req in lst_req)
        {
            //判断是否完成该请求，只要有一个没完成就继续等待
            if(!req.isDone)
            {
                return;
            }
        }

        //当全部请求都完成时，执行回调
        Callback(lst_req);

        //请求结束并清空
        lst_req.Clear();
    }
}
```

上述伪代码中同时开启多个HTTP连接来向服务器请求数据，提高了网络传输效率和服务器端的CPU利用率，请求彼此之间没有顺序关系，只有这样服务器端的执行顺序才无序担心。

如果请求之间是有顺序要求的，服务器端执行顺序无法保障则容易出现逻辑顺序混乱的问题。例如我们同时发起多个如下这样的请求，先购买物品、再出售物品、最后使用物品，这三个请求同时一起被发起，由于网络波动原因服务器接受到的请求顺序有可能是，使用物品，出售物品，再购买物品，当顺序不同时就有可能存在逻辑问题，这与我们原本设想的逻辑存在偏差，实例物品可能先被使用或出售，而不是被先购买，导致没有物品可被使用或出售，逻辑错位混乱是必然的。

我们在同时发起多个HTTP请求连接时，虽然提高了网络效率和服务器的CPU利用率，却无法保证预期的逻辑顺序，这会使得一些业务遭遇问题。因此这种解决方案在需要逻辑顺序严格执行的业务上无法正常运作，它只能运用在不需要逻辑顺并且需要同时发起多个请求的业务上。

**解决方案2：逐个发起请求，保证顺序**

为了解决顺序问题，我们可以逐个发起请求，这种方式比较普遍。在网页端、安卓原生端、苹果原生端都会使用这种方式来做请求，即每次只处理一个请求，当这个请求结束后再发起下一个请求，每个请求对应一个功能模块，结束当前功能模块后再发起下一个模块的请求逻辑。

我们再用前面所描述的例子来描述当前的解决方案，我们对HTTP做请求角色信息、再请求军团信息，再请求每日任务信息，这次我们不再同时发起请求，而是每次只做一件事，在收到角色信息数据后，再发起请求军团信息，收到军团信息后，再发起请求任务信息，收到任务信息后再显示在界面，每个请求收到响应数据后再处理当前请求的业务逻辑，当某个请求得到响应后都处理各自的事情。

也就是说在我们的例子中，请求角色信息的得到响应后处理角色信息相关的逻辑，请求任务信息的得到响应后处理任务信息相关的逻辑，以此类推由于客户端按顺序发送，结束时每个数据也都可以独立运行，结束后再继续下一个请求，并且所有请求响应的逻辑都可以程序来实时的自定义。可以理解为如下伪代码为：

```c#
void on_button_click()
{
    //请求角色数据
    function_request_roleinfo( callback_function1 ) 
}

void callback_function1( data )
{
    //记录角色信息
    role_info.Add(data);

    //请求军团信息
    function_request_groupinfo( callback_function2 )
}

void callback_function2( data )
{
    //记录军团信息
    group_info.Add( data );

    //请求任务信息
    function_request_task( callback_funciton3 );
}

void callback_function3( data )
{
    //记录任务信息
    task_info.Add( data);

    //展示UI
    show_ui();
}
```

上述伪代码描述了发送请求的逻辑顺序，这种逐个发送请求的方式，保证了逻辑顺序，同时也满足了对多样化功能的扩展，同一个请求可以在不同逻辑处拥有自己的自定义的处理逻辑。

我们说的单个连接的方式确实保证了顺序，但也降低了网络连接效率，多个请求时需要逐个发起TPC连接，每个连接都需要等待上一个连接请求完毕后才能开始下一个请求，并且在每次收到消息后都会发起4次TCP挥手来断开连接，在每次发起请求时又必须进行3次握手来建立连接，这种方式消耗了网络资源降低了收发效率。

除了上面我们说的这种自定义式的逐个发送请求外，另外还有一种逐个发送请求的方式，它为了保证请求的顺序进行，使用了发送队列和接收队列来确保发送与接收的顺序。其中为发送所做的队列在请求和响应中起到了缓冲的作用，在连续使用HTTP请求和连续收到HTTP响应时，能够做到依次处理相应的逻辑。

这种方式全程只有1个线程在做请求处理，所以并不需要线程锁之类的操作。发送时向队列推送请求实例，在逻辑更新函数Update上判断是否有请求在队列里，有的话推出一个请求做HTTP连接操作，同时将当前请求的信息暂时存放在内存中，当得到服务器响应时调用请求信息中的回调函数处理回调数据。

我们也用伪代码来描述这种发送和接收队列的过程:

```c#
//将请求推入队列
void RequestHttp(Request req)
{
    ListRequest.Push(req);
}

//逻辑更新
void Update()
{
    //是否完成HTTP
    if( IsHttpFinished() )
    {
        //开始新的请求，推出一个请求数据，存起来，并开始发送HTTP连接
        Request  req = ListRequest.Pop();
        mCurrentRequest = req;
        StartHttpRequest(req);
    }
    else
    {
        //是否收到响应
        if(HttpIsDone())
        {
            //根据响应数据处理逻辑
            ProcessResponse(data);

            //完成HTTP
            FinishHttp();
        }
    }
}

//根据数据处理逻辑
void ProcessResponse(Response data)
{
    if(mCurrentRequest != null
        && mCurrentRequest.Callback != null)
    {
        //回调句柄，根据数据处理相关逻辑
        mCurrentRequest.Callback(data);
        mCurrentRequest = null;
    }
}
```

以上过程阐述了在发送HTTP请求时的推入队列操作和在收到请求后的句柄响应操作，队列使我们能够逐个请求以及逐个响应。

**解决方案3：多连接与逐个发送的混合使用。**

多连接提高网络请求效率但没有一致的响应顺序，逐个发送有一致的响应顺序网络请求效率则不够好。两者之间其实没有排斥关系，我么可以混合使用，这样既提高了网络效率又保证了顺序。

我们来看看该如何混合使用它们，我们仍然使用前面解决方案1中的类 Multiple_Request ，原本的 Multiple_Request 类可以传入多个请求数据，并等待全部数据响应结束后再执行回调，接着我们在回调逻辑中也可以用 Multiple_Request 来执行下一组请求。我们用伪代码描述一下：

```c#
//界面按钮
void on_click()
{
    //新建一个请求对象
    request1 = new request();
    request1.url = url1;
    request1.wwwform = new wwwform();
    request1.wwwform.AddField("name1","value1");

    //加入请求列表
    lst_request.Add(request1);

    //兴建一个请求对象
    request2 = new request();
    request2.url = url2;
    request2.wwwform = new wwwform();
    request2.wwwform.AddField("name21","value21");

    //加入请求列表
    lst_request.Add(request2);

    //新建一个请求对象
    request2 = new request();
    request2.url = url3;
    request2.wwwform = new wwwform();
    request2.wwwform.AddField("name22","value22");

    //加入请求列表
    lst_request.Add(request3);

    //新建多请求实例
    multiple_request req = new multiple_request();

    //开始多个请求对象开启HTTP请求
    req.StartRequest(lst_request, callback_function1);
}

void callback_function1(lst_request)
{
    //做些逻辑
    do_some_function(lst_request);

    //新建一个请求对象
    request1 = new request();
    request1.url = url1;
    request1.wwwform = new wwwform();
    request1.wwwform.AddField("name1","value1");

    //加入请求列表
    lst_request.Add(request1);

    //兴建一个请求对象
    request2 = new request();
    request2.url = url2;
    request2.wwwform = new wwwform();
    request2.wwwform.AddField("name21","value21");

    //新建多请求实例
    multiple_request req = new multiple_request();

    //开始多个请求对象开启HTTP请求
    req.StartRequest(lst_request, callback_function2);
}

void callback_function2(lst_request)
{
    //将信息展示到UI
    show_ui(lst_request);
}
```

上述伪代码描述了如何多请求与逐个请求的并行使用，将多个请求看成一个请求的变体，将多个请求看成一个完整的功能块，就有了多请求与逐个请求的混合使用过程。在现实项目中，我们可以为每个网络功能新建一个类，即继承 Multiple_Request 类，并且将所有参数写进子类中后一并发送，并且可以多次使用在多个业务逻辑中。我们用伪代码描述这种情况:

```c#
//新建个父类继承 multiple_request 专门用来做某个功能，这个功能里需要请求多条数据
class do_something : multiple_request
{
    void StartRequest( int val1 , int val2, int val3, call_back )
    {
        //新建一个请求对象
        request1 = new request();
        request1.url = url1;
        request1.wwwform = new wwwform();
        request1.wwwform.AddField("name1","value1");

        //加入请求列表
        request_list.Add(request1);

        //兴建一个请求对象
        request2 = new request();
        request2.url = url2;
        request2.wwwform = new wwwform();
        request2.wwwform.AddField("name21","value21");

        //加入请求列表
        request_list.Add(request2);

        //新建一个请求对象
        request2 = new request();
        request2.url = url3;
        request2.wwwform = new wwwform();
        request2.wwwform.AddField("name22","value22");

        base.StartRequest(request_list, call_back);
    }
}

//ui上的按钮
void on_click()
{
    //实例化功能对象
    do_something = new do_something();

    //开始请求
    do_something.StartRequest(1,2,3, call_back_function1);
}

//回调1
void call_back_function1(lst_request)
{
    //做点事
    do_something(lst_requset);

    //实例化功能2的对象
    do_something2 = new do_something2();

    //开始请求
    do_something2.StartRequest(3,2, call_back_function2);
}

//回调2
void call_back_function2(lst_request)
{
    //展示UI
    show_ui(lst_request);
}
```

上述伪代码描述的，在实际项目中可以用子类继承父类功能的方法复用了请求的步骤，使得需要某个功能时使用起来更加便捷。

**解决方案4：合并请求，并逐个发送合并后的请求包。**

多个请求与逐一发送混合的解决方案，确实既提高了发送效率，又保证了顺序，但任然有几个缺点。

```
    缺点1，多开连接导致连接数增多，频繁的建立连接与断开连接导致网络效率仍然不够高。

    缺点2，虽然自定义空间很大但必须手动建立新功能类，逻辑变得庞大后分层不容易清晰。

    缺点3，多功能间的顺序必须手动排列顺序。
```

客户端程序员在使用时更希望的是多次请求能够被同时发出，同时收到的响应顺序也要按原来请求的顺序响应，并且要可以满足自定义回调句柄满足多样化的扩展需求。

如此一来合并请求就成了更适合的解决方案，即合并多个请求的数据为一个请求，当发起请求时一次性打包多个请求，只用一个连接就能全部发送并响应所有数据，这样一来发送这个合并数据包可以做到与发起多个连接同样的效果，并且响应也可以做到顺序一致性。

合并请求的方式做HTTP，减少了连接数量也提高了网络效率，同时还保证了请求顺序与响应顺序的准确性。

那么如何实现呢？这次我们需要服务端程序员同学一些配合，服务端同学需要将原本多个地址，每个地址对应的功能块的模式，改为同一个地址，并且改为使用ID(我们暂且称它为Commoand ID) 字段来对应不同的功能块。

这里我们以Json数据协议为例来说明这个过程(因为Json格式比较好理解)，HTTP请求数据使用Json格式，服务器响应数据也是Json格式(通常都是这种做法，并且这在互联网非常普遍)。客户端发送Json格式的请求数据给服务器，服务器收到后解析Json格式数据提取数据后处理逻辑，接着将要返回的数据反序列化为Json格式给客户端。

现在为了合并Json数据，我们在对多个请求发起时，将多个Json请求格式推入到一个大的Json数据中，同时在合并时为每个合入进去的Json数据添加一个序列号，代表合入前的顺序，请看如下Json合并过程：

```c#
//请求1
{
    "request-order" : 1,
    "command" : 1001,
    "data1" : "i am text",
    "data2" : "i am num",
}

//请求2
{
    "request-order" : 2,
    "command" : 2011,
    "book" : "i am text",
    "chat" : "i am num",
    "level" : 1，
}

//请求3
{
    "request-order" : 3,
    "command" : 3105,
    "image" : "i am text",
    "doc" : "i am num",
}

//将1，2，3合并后的请求数据为
{
    "data":
    [
        {
            "request-order" : 1,
            "command" : 1001,
            "data1" : "i am text",
            "data2" : "i am num",
        }
        ,
        {
            "request-order" : 2,
            "command" : 2011,
            "book" : "i am text",
            "chat" : "i am num",
            "level" : 1;
        }
        ,
        {
            "request-order" : 3,
            "command" : 3105,
            "image" : "i am text",
            "doc" : "i am num",
        }
    ],
}
```

上述中合并时多个Json被推入到Json数组中，接着将它们一并发送给服务器端，服务器端程序接受到数据后对data字段中的数据进行提取、解析、处理，并且处理顺序按照request-order从小到的顺序来做，每个数据块都有一个command字段，用这个字段来判断使用哪个程序功能模块来处理逻辑，接着将数据传给该功能模块处理。

在每个功能模块处理完毕后，将所有响应数据都推入同一个Json实例中，同时附上与请求数据中相同的request-order，以便客户端识别与请求数据对应的响应数据，最后把整个响应数据一并发送给客户端。当客户端收到数据时，通过request-order就能知道响应数据的顺序，以及是哪个请求发起后响应的数据，于是客户端在按照request-order从小到大的顺序排序后进行解析和回调，得到了与请求顺序一致的响应顺序。

我们来看看客户端收到服务器端的合并响应数据是怎样的：

```c#
//响应数据1
{
    "response-order" : 1,
    "command" : 1001,
    "data1" : "response text",
    "data2" : "response num",
    "error_code" : "0", 
}

//响应数据2
{
    "response-order" : 2,
    "command" : 2011,
    "data1" : "response text",
    "data2" : "response num",
    "error_code" : "1",
}

//响应数据3
{
    "response-order" : 3
    "command" : 3105,
    "data1" : "response text",
    "data2" : "response num",
    "error_code" : "2",
}

//合并后的响应数据
{
    "error_code" : 0,
    "data":
    [
        {
            "response-order" : 1,
            "command" : 1001,
            "data1" : "response text",
            "data2" : "response num",
            "error_code" : "0", 
        }
        ,
        {
            "response-order" : 2,
            "command" : 2011,
            "data1" : "response text",
            "data2" : "response num",
            "error_code" : "1",
        }
        ,
        {
            "response-order" : 3
            "command" : 3105,
            "data1" : "response text",
            "data2" : "response num",
            "error_code" : "2",
        }
    ]
}
```

如上所描述的，在得到合并后的响应数据后，客户端要先提取data数据中的所有数据，以respose-order为基准从小到大进行排序，从头上最小序号的开始处理。

到现在合并请求的部分我们描述了单个连接多个请求的方式，如果多个合并请求一同发送也会遇到大麻烦，同样会遇到顺序问题，因此我们依然需要用队列来规避这个问题。用了队列的方式保证多个请求的有序性，与前面用队列逐个发送的方式相比，我们除了用队列暂时存储请求数据外还在队列之上进行操作请求合并，这样能更有效更方便的做到合并以及有序发送。

我们来看看队列与合并数据包相结合的方式用伪代码描述:

```c#
//将请求推入队列
void RequestHttp(Request req)
{
    ListRequest.Push(req);
}

//逻辑更新
void Update()
{
    //是否完成HTTP
    if( IsHttpFinished() )
    {
        //推出多个请求进行合并
        lst_combine_req.Clear();
        for(int i = 0 ; i<10 ; i++)
        {
            Request  req = ListRequest.Pop();
            lst_combine_req.Add(req);
        }

        //合并多个请求
        combine_request = CombineRequest(lst_combine_req);
        StartHttpRequest(req);
    }
    else
    {
        //是否收到响应
        if(HttpIsDone())
        {
            //按ID从小到大排序
            sort(combine_request.lst_response);

            //循环处理每个响应逻辑
            for(int i = 0 ; i<combine_request.lst_response.count ; i++)
            {
                //根据响应数据处理逻辑
                data = combine_request.lst_response[i];
                ProcessResponse(data);
            }

            //完成HTTP
            FinishHttp();
        }
    }
}

//根据数据处理逻辑
void ProcessResponse(Response data)
{
    if(mCurrentRequest != null
        && mCurrentRequest.Callback != null)
    {
        //回调句柄
        mCurrentRequest.Callback(data);
        mCurrentRequest = null;
    }
}
```

来看看从按钮点击事件开始的具体逻辑的操作：

```c#
//按钮事件
void on_click()
{
    //请求玩家数据
    request_roleinfo( call_back_function1 );

    //请求军团数据
    request_groupinfo( call_back_function2 );

    //请求任务数据
    request_taskinfo( call_back_function3 );
}

//先回调的是这个句柄
void call_back_function1( data )
{
    //保存玩家数据
    save_roleinfo(data);
}

//再回调的是这个句柄
void call_back_function2( data )
{
    //保存军团数据
    save_groupinfo(data);
}

//最后收到任务数据时，表明前面的数据都已经收到了，就可以做一些逻辑处理
void call_back_function3( data )
{
    //保存任务数据
    save_taskinfo(data);

    do_something();
}
```

上述伪代码中描述的在具体业务逻辑中，我们客户端在编写网络请求时可以随意的调用发送请求而不再需要关心顺序和发送效率的问题，大大提高了程序员的网络逻辑编程效率。

我们对多个HTTP请求进行了合并数据的操作后减少请求的次数，对速度的提升很有大的效果，但这里还有一些细节问题需要我们关注，比如多少个开始进行合并，或者多少时间内合并一次。

为了让HTTP最大效率的得到提升，必须每次请求得到响应后就应该立即进行下一次HTTP请求，如果有等待合并间隔，反而减低了网络效率。不过每次合并数量需要做一些限制，如果有100个请求同时被发起，我们不能统统合并了，这也是为了保证发送数据大小和回调数据大小合适，数据包越大丢包重发的概率也就越大，因此我们必须限制一次性合并的个数，我们可以选择每次最多合并10个请求数据包，以保证减少连接次数减少的情况下，发送和接收的数据包不会过大。

## 剖析数据协议原理

### JSON

JSON原本是JavaScript 对象表示法（JavaScript Object Notation），后来慢慢在被大家所接受普及开来成为一种协议数据的格式。它是存储和交换文本信息的语法，类似于 XML 但又比 XML 更小、更快，更易解析。

JSON 本身是轻量级的文本数据交换格式由字符串组成，它独立于语言且具有自我描述性，这些特性导致它非常容易被人理解。与同是纯文本类型格式的XML相比较，JSON不需要结束标签，JSON更短，JSON解析和读写的速度更快，在JavaScript中能够使用内建的 JavaScript eval() 方法进行解析，JSON还可以使用数组，且不使用保留字（&，<，>，’，”）。

我们来看看 JSON 的语法规则，JSON 数据的书写格式是：名称/值对。名称/值对包括字段名称（在双引号中），后面写一个冒号，然后是值：

```
"firstName" : "John"
```

JSON数据由逗号分隔，它的值可以是数字、字符串、真假逻辑值、数组、对象，我们来看看它们在文本中的具体格式：

数字（整数或浮点数）

```
{
  "number" : 1,
  "number2" : 11.5
}
```

字符串（在双引号中）

```
{
  "str1" : "1",
  "str2" : "11"
}
```

逻辑值（true 或 false）

```
{
  "logic1" : true,
  "logic2" : false
}
```

数组（在方括号中）

```
{
   "array1" : [1,2,3],
   "array2" : [{"str1",1},{"str2",2},{33,44}]
 }
```

对象（在花括号中）

```
{
  "obj1" : {1, "str1", true},
  "obj2" : {"str2", 2, false},
  "obj3" : null
}
```

其中对象在花括号中书写，其对象可以包含多个名称/值对：

```
{ "firstName":"John" , "lastName":"Doe" }
```

数组在方括号中书写，数组可包含多个对象：

```
{
    "employees": [
        { "firstName":"John" , "lastName":"Doe" },
        { "firstName":"Anna" , "lastName":"Smith" },
        { "firstName":"Peter" , "lastName":"Jones" }
    ]
}
```

JSON 文件的文件类型通常是 “xxx.json” 用来扩展名用来说明是json格式的文本文件。在HTTP协议中还定义了Json格式的MINE类型以方便终端逻辑识别，JSON 文本的 MIME 类型是 “application/json” (MIME (Multipurpose Internet Mail Extensions) 是描述消息内容类型的因特网标准。其他MIME 消息包含文本、图像、音频、视频以及其他应用程序专用的数据。

我们在平时的编程中 JSON 解析器也比较多，例如simpleJson，MiniJson，DataContractJsonSerializer，JArray，JObject等等，都是非常通用高效的插件，也可以自己’造轮子‘做一个JSON解析器，做时也要多考虑下效率和性能方面的问题。

### 自定义二进制流协议格式

大部分的网络协议都具有一定的通用性，JSON是最典型的案例，其他的包括 XML，MessagePack，Protobuf都是相对通用的，但我们所要说的自定义二进制流协议则不是，理论上说它完全不通用，其原因是它被设计出来就不需要顾及通用性。

我们在存储一串数据的时候，无论这串数据里包含了哪些数据以及哪些数据类型，当我们拿着这串数据解析的时候我们应该首先知道数据如何解析，这是定义协议格式的目标。简单说就是，当我们收到一串数据的时候，我们用什么样的规则知道这串数据里的内容的，这就是协议规则的目标。JSON就制定了这么一个规则，这个规则以字符串 KEY-VALUE 简单配对的形式，以及一些辅助的符号‘{’,’}’,’[’,’]’组合而成，这个规则比较通用且易于理解，这使得任何人拿到JSON数据都能一眼知道里面有什么数据。

自定义二进制协议格式则不具有通用性，并不是任何人拿到数据都能知道里面装的是什么的，有且只有两端协定的双方才知道该如何解析收到的数据，对于破解自定义二进制流的内容也只有靠猜因为协议格式只有制定时的双方才知道(虽然猜的难度也不是很大，很多外挂都靠经验猜测数据内容)。

一个自定义二进制流协议格式，分成三部分：

```
数据大小|协议编号|具体数据
```

用代码结构可以表示为:

```c#
class Mssage
{
  uint Size;
  uint CommandID;
  byte[] Data;
}
```

数据大小、协议编号、具体数据，这三者构成了一个完整的协议内容，当然很多时候command id 可以放入具体的数据中去。

现在假设我们客户端有这样一个数据结构需要传输到服务端去：

```c#
class TestMsg
{
  int test1;
  float test2;
  bool test3;
}
```

服务端拿到数据时，其实是完全不知道当前拿到的数据是什么，也不知道数据是否完整，有可能只拿到一半的数据，或者一部分的数据。因此首先我们要确定的是，我们收到的数据包它的完整的大小有多大，只有知道完整的包体大小才能确定我当前收到的数据在大小上是否完整，我们是要等待继续接受后面的数据，还是现在就可以进行解析操作了。

为了确定包的完整性，我们必须先向二进制流中读取4个byte，组合成一个无符号整数，整数总共32位，也就是说我们的数据包的大小最大可以为2的32次减1个byte，这个整数让我们知道了接下来数据的大小。例如我现在接收到了20个byte后，读取了前4个byte，组成一个整数后这个整数为24，说明后面16个byte是一个不完整的包体，我应该继续等待后续的数据到来。

其次我们要确定的是收到的数据包是属于哪个协议格式。于是我们再读取4个byte大小的数据，组成一个无符号整数CommandID，用来确定协议号。假如这个无符号整数的协议号为1002，就代表是接下来的数据是编号为1002的协议的数据格式。假设我们上面这个TestMsg类就是协议号1002的数据体，那么接下来连着这个协议号的所有数据直到包体大小的末尾都是这个TestMsg的数据，我们可以提取后解析为该类实例。

在解析这个具体数据的时候，我们需要根据生成这个数据的顺序来解析，写入数据的顺序和读取数据的顺序是一致的。假设在生成这个二进制流数据时，我们的顺序是，先推入test1变量，再推入test2变量，再推入test3变量。其中test1变量为4个byte的整数，test2变量为4个byte的浮点数，test3变量为1个byte的布尔值，于是就有了如下byte数组结构：

```
xxxx|xxxx|x
```

| 这样一个形状的二进制流，每个‘x’为一个byte，前两次4个byte组成一个int和float数据，最后1个byte组成布尔数据，‘ | ’只是为了解释说明用的分隔符不存在于数据内，这个数据是由9个byte组成，其中前4个byte为test1，中间4个byte为test2，后面1个btye为test3。 |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
|                                                              |                                                              |

在向网络传输的中整个数据包TestMsg的格式为如下：

```
13|1002|test1|test2|test3
```

| 上述格式中13为接下来的数据包大小，1002位协议编号，test1 | test2 | test3为具体数据。我们在解析的时候也需要按照生成时的顺序来解析，先读取前4个byte组成一个整数赋值给test1，接着再读取4个byte组成一个浮点数赋值给test2，接着再读取1个byte赋值给test3，完成数据解析。 |
| ------------------------------------------------------- | ----- | ------------------------------------------------------------ |
|                                                         |       |                                                              |

对于数组形式的数据则要在原来的基础上多增加一个长度标志，比如 int[]类型数据，在生成时先推入代表长度的无符号整数数据，再连续推入所有数组内容，在解析的时候做同样的反向操作，先读取4个byte的长度标志，再对连续读取N个具体数据，N为提取的长度。我们举例int[]为3个整数数组则二进制为如下效果：

```
xxxx|xxxx|xxxx|xxxx
```

前4个byte为长度数据，接着3次4个byte为数组内的整数数据。

自定义二进制流协议格式为最不通用的格式，但可以成为最节省流量的协议方式，因为每个数据都可以用最小的方式进行定义，比如协议号不需要4个byte，2个byte大小代表2的16次-1也就是65535就够用了，长度有可能也不需要4个byte，只要2个甚至1个byte就够用了，有些数据不需要4个byte组成int整数，只需要2个byte数组ushort就够用了，甚至有些可以组合起来使用，比如协议结构中有4个bool，可以拼成一个byte来传递，这些都可以完全由我们来控制包体的大小不受到任何规则的限制，这也是自定义二进制协议格式最吸引人的地方。

自定义二进制流协议格式最大的缺点是不通用和难更新，当我们需要更换一个协议格式的时候，旧的协议格式就无法解析了，特别是当新的协议解析旧的协议时就会报错。不过我们也可以做些补救这种问题的措施，为了能让旧的协议格式还能继续使用，我们在每个数据头部都加入一个2个byte的整数代表版本号，由版本号来决定该读取哪个版本的协议，这样旧的协议也照样可以兼容新的协议，只是处理起来的时候需要注意些初始化问题，那些旧协议没有的而新协议有的数据则要尽可能的初始化成默认值以免造成逻辑报错。

### MessagePack

MessagePack 是一个介乎于JSON和自定义二进制流之间的协议格式，他的理念是 ‘It’s like JSON. but fast and small.’ 。

与JSON相同的是MessagePack也有采用Key-Value形式的Map映射类型，不同的是MessagePack用byte形式存储data部分的数据，包括整数、浮点数、布尔值等，并且在Map映射类型外加入了更多独立类型（非KEY-VALUE形式）的数据类型，其中也包括了自定义二进制流的数据类型。

Map映射类型在MessagePack中也是比较常用的数据类型，它是比较通用的存储形式类型，也因为通用性被很多程序员所喜爱。在使用过JSON的程序员知道JSON易懂且易用，MessagePack使用起来能和JSON用起来一样，并且数据大小比JSON小，解析速度又比JSON快，这也是作者所说的 “It’s like JSON. but fast and small.”。

| 非Map类型的数据部分其实和自定义二进制流的存储方式差不多，只是把自定义二进制数据流中的‘数据大小 | 数据’的形式改为了‘类型 | 数据’，比如我们存储一个4个byte的32位的整数： |
| ------------------------------------------------------------ | ---------------------- | -------------------------------------------- |
|                                                              |                        |                                              |

```
+--------+--------+--------+--------+--------+
|  0xd2  |ZZZZZZZZ|ZZZZZZZZ|ZZZZZZZZ|ZZZZZZZZ|
+--------+--------+--------+--------+--------+
```

第一个byte的值0xd2代表32位整数类型，它表示后面4个byte组合起来是整数类型的数据。再比如32位的浮点数的存储格式：

```
+--------+--------+--------+--------+--------+
|  0xca  |XXXXXXXX|XXXXXXXX|XXXXXXXX|XXXXXXXX|
+--------+--------+--------+--------+--------+
```

第一个byte的值0xca代表32位浮点数类型，它表示后面4个byte组合起来是浮点数类型的数据。以此类推，nil，bool，8位无符号整数，16位无符号整数，32位无符号整数，64位无符号整数，8位有符号整数，16位有符号整数，32位有符号整数，64位有符号整数等，以及32位浮点数，64位浮点数，都用这种类似的方式表示。

其实用MessagePack并不是冲着这些单独的数据类型去的，因为这些单独的数据类型完全可以用自定义二进制流代替，我们关心的是它的Map类型数据的格式定义。我们先来看看，MessagePack的Map类型的存储机制和Json有什么区别，它为什么就比JSON快，为什么就比JSON小，它是如何存储和解析的。

在Map之前我们看看数组类型的格式：

```
+--------+--------+--------+~~~~~~~~~~~~~~~~~+
|  0xdc  |YYYYYYYY|YYYYYYYY|    N objects    |
+--------+--------+--------+~~~~~~~~~~~~~~~~~+
```

第一个byte的值0xdc代表是个总共可以存储16位长度的数组，也就是它的最大存放个数为2的16次-1个元素的数组，后面2个byte组合起来成为一个无符号的整数代表后面有多少个元素，接着后面N就是相同类型的元素的数据。

假设说这N个元素是32位整数类型的数据，那么上述的数组类型具体格式就是如下：

```
+--------+--------+--------+~~~~~~~~~~~~~~~~~+
|  0xdc  |00000000|00000011|  0xd2|00001001|0xd2|00001101|...(3 objects)
+--------+--------+--------+~~~~~~~~~~~~~~~~~+
```

| 我们看这个数组中指定了数组类型，0xdc就代表数组，以及后面2个byte拼起来表示数组元素的个数为11，接下来的数据就是单个元素的数据，即有11个整数数据组成的数组，每个数据都以‘类型 | 数据’格式的存储。其实Map类型就是数组类型的变种，我们在数组类型基础上每个元素，多加了个KEY字符串就成了Map类型的数据格式，我们来看下Map的具体格式： |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
|                                                              |                                                              |

```
+--------+--------+--------+~~~~~~~~~~~~~~~~~+
|  0xde  |YYYYYYYY|YYYYYYYY|   N*2 objects   |
+--------+--------+--------+~~~~~~~~~~~~~~~~~+
```

第一个byte的值0xde代表的是最大个数为16位(即2的16次减1个)的map类型数据，接着2个byte组合起来表示有多少个元素，最后部分N乘2个元素为数据元素，以每2个元素为一个Key-Value组合，第一元素一定是字符串Key，第二个元素为任意的单独数据类型。

我们用官方的例子来分析下，例如一个JSON类型的数据为：

```
{"compact":true, "schema":0}
```

这个数据在MessagePack中是以Map类型数据存在的其格式为：

```
82|A7|'c'|'o'|'m'|'p'|'a'|'c'|'t'|C3|A6|'s'|'c'|'h'|'e'|'m'|'a'|00|
```

数据中头部的‘82’这个数据，前半个byte的值即8代表是个最多拥有15个元素的map类型数据，后半个byte的值即2，代表总共有2个元素。接着第二个数据‘A7’，‘A’为前半个byte的值代表接下去是个31个字符以内的字符串，后半个byte值为7代表这个字符串拥有7个字符。接着7个元素都是字符元素及Key位置的字符串。接着‘C3’是Key-Value的Value类型数据部分，这个Value是一个bool型的ture值。接着‘A6’开始为第二个Key-Value数据组合，其中A为前半个byte代表是接下去是个31个元素以内的字符串，后半个byte为6代表这个字符串有6个长度大小。接着6个元素都是字符作为Key数据。最后的‘00’，前面0为前半个byte，表示类型为7位以内的整数，接着的0位后半个byte，代表数据为0。这样整个数据分析下来，MessagePack数据与Json的{“compact”:true, “schema”:0}数据对应上。

| MessagePack整个Map就是以这种“类型 | 数据”或者”类型 | 大小 | 数据”的方式存储。由于存储的方式是顺序，所以在解析的时候不需要排序，不需要解析符号和类型，数据的类型直接可以用byte来表示，能用byte存储绝不用字符串形式存储，如能减少byte使用个数的尽量减少byte的使用个数，如能合并的尽量合并为一个byte。因此MessagePack对于JSON来说，减少了大量的解析，同时也减少了大量的数据占用空间，使得MessagePack能比起JSON来更快并且更小，就像它自己所说的那样 ‘It’s like JSON. but fast and small.’。 |
| --------------------------------- | -------------- | ---- | ------------------------------------------------------------ |
|                                   |                |      |                                                              |

### Protocol Buffer

虽然Proto3在Proto2之上又做了更多的改进，但我们这里仍以Proto2为基准来讲解Protocal buffer的内在机制。MessagePack在JSON之上做了很多数据空间和序列化以及反序列化上的优化，其实可以看做是把JSON和自定义二进制的混合的做法，既吸收了JSON这种Key-Value(键值对)简单易懂通用性的优点，又吸收了自定义二进制流格式序列化与反序列化性能高和存储空间小的特点。不过话说回来，MessagePack的Map形式数据存储格式毕竟是Key-Value形式的，其Key值仍然使用了字符串，还是逃脱不了字符串string占用太多存储空间的弊端。

Google Protocol Buffer 的出现就弥补了MessagePack的这个缺点，但是Google Protocol Buffer也有自身不可忽视的缺点，我们来看究竟Google Protocol Buffer是怎么的一种数据协议。

Google Protocol Buffer( 简称 Protobuf) 是 Google 公司内部的混合语言数据标准，它们用于 RPC 系统和持续数据存储系统。Protobuf 是一种轻便高效的结构化数据存储格式，可以用于结构化数据串行化，或者说序列化。它很适合做数据存储或 RPC 数据交换格式。可用于通讯协议、数据存储等领域，是语言无关、平台无关、可扩展的序列化结构数据格式。常有人推崇说 Protocol Buffer 比JSON、MessagePack要好，那么它究竟好在哪里呢？我们就来分析下。

我们选择数据协议的目的主要关注的点是，它是否能更简单易上手，序列化与反序列化数据性能是否高效，存储空间占用是否更小，更改协议后的兼容性是否能更强。对于这些特点，Protocol Buffer 是否能都做到，下面我们就来的对它剖析一番。

### Protocol Buffer消息定义

Protobuf 的消息定义需要创建一个文件然后把消息结构写进入，然后再通过Protobuf生成工具将定义好的消息文件生成为指定语言的程序文件，我们在编程时可以通过调用这些生成的程序去序列化和反序列化Protobuf。

我们先来创建一个扩展名为.proto的文件，假设文件名为 MyMessage.proto，并将以下内容存入该文件中。

```
message LoginReqMessage {
  required int64 acct_id = 1;
  required string passwd = 2;
}
```

上述消息定义是一个简单的登陆消息定义，我们来说明下里面的结构。

1. message是消息定义的关键字，等同于C#中的struct/class。
2. LoginReqMessage为消息的名字，等同于结构体名或类名。
3. required前缀表示该字段为必要字段。即在序列化和反序列化之前该字段必须已经被赋值。

与required相似的功能还存在另外两个类似的关键字，optional和repeated。optional表示该字段为可选字段，即在序列化和反序列化前可以不进行赋值。相比于optional，repeated主要用于表示数组字段，它代表数组。(required和optional字段已经在Protobuf3中取消，所有未定义类型都是optional)

1. int64和string分别表示64位长整型和字符串型的消息字段。

其实在Protobuf中存在一张类型对照表，这张对照表用于Protobuf中的数据类型与其他编程语言(C#/Java/C++)中所用类型的一一对应。该对照表中还将给出在不同的数据场景下，使用哪种数据类型更为高效。

1. acct_id 和 passwd 分别表示消息字段名，等同于C#中的域变量名。
2. 标签数字 1 和 2 表示不同字段序列化后在二进制数据中的布局位置。

LoginReqMessage结构的实例数据在序列化时，acct_id先被推入数据流中再是passwd，passwd 字段在序列化后的数据一定位于 acct_id 之后。我们需要注意数字标签的值代表二进制流中的位置，该值在同一message中不能重复。

另外Protocol Buffer有个优化规则我们需要在定制消息的注意，它在标签值为 1 到 15 的字段上序列化时会对其进行优化，即标签值和类型信息仅占有一个byte，标签范围在 16 到 2047 的则占有两个byte，而Protocol Buffer可以支持的字段数量则为2的29次方减1个即536870911个数据变量。鉴于此优化规则，我们在设计消息结构时，可以尽可能考虑让repeated类型的字段标签位于1到15之间，这样便可以有效的节省序列化后的字节大小。

### 多层嵌套Protocol Buffer

除了定义单个消息，我们也可以在同一个.proto文件中定义多个message，这样便可以实现多层嵌套消息的定义，我们来看看具体案例：

```c#
    message Person {
      required string name = 1;
      required int32 id = 2;
      optional string email = 3;

      enum PhoneType {
        MOBILE = 0;
        HOME = 1;
        WORK = 2;
      }

      message PhoneNumber {
        required string number = 1;
        optional PhoneType type = 2 [default = HOME];
      }

      repeated PhoneNumber phones = 4;
      repeated float weight_recent_months = 100 [packed = true];
    }

    message AddressBook {
      repeated Person people = 1;
    }
```

我们在proto文件中定义了三个消息结构和一个枚举结构，其中AddressBook消息的定义中包含了Person消息类型作为其字段变量，Person又包含了PhoneNumber消息类型作为字段变量，这与我们平时编程的数据结构嵌套方式很相似。除了这些数据结构被集中定义在一个proto文件中以外，它们也可以被分开来定义在各自.proto文件中。

由于Protocol Buffer提供了另外一个关键字，‘import’关键字，它相当于 C++ 的Include，这样我们在编写Proto结构时便可以将很多通用的message定义在同一个.proto文件中，而每个模块功能的消息体定义可以自己管理分别定义在自己独立的proto文件中或者以其他更清晰的方式分开定义，最后我们可以通过import关键字以动态导入的方式将需要的结构体文件导入进来，如：

```c#
    message Person {
      required string name = 1;
      required int32 id = 2;
      optional string email = 3;

      enum PhoneType {
        MOBILE = 0;
        HOME = 1;
        WORK = 2;
      }

      message PhoneNumber {
        required string number = 1;
        optional PhoneType type = 2 [default = HOME];
      }

      repeated PhoneNumber phones = 4;
      repeated float weight_recent_months = 100 [packed = true];
    }
```

例如上述我们先写好一个常用的数据结构体消息，将它放入Person.proto文件中。

```c#
    import "myproject/Person.proto"

    message AddressBook {
      repeated Person people = 1;
    }
```

然后再我们写我们自己模块里的结构消息，定义好自己的需要的数据类型字段，再将Person这个proto文件里的所有消息结构都导入进来。通过‘import’我们可以轻松而且清晰的表达项目中的数据分块与分层。

### 限定符 required、optional、repeated 的规则

在Protobuf2中有这3个限定符，并且在每个消息中必须至少有一个required类型的字段，保证数据中一定有至少一个数据。

required限定符表示该字段为必要字段。即在序列化和反序列化之前数据中该字段必须已经被赋值。而每个消息中可以包含0个或多个optional类型的字段。optional限定符表示该字段为可选字段，即在序列化和反序列化前可以不进行赋值，如果没有赋值则表示该数据为空。repeated限定符则表示的字段可以包含0个或多个重复的数据，即数组类型符号。注意 repeated 代表是重复的数据，等价于我们常使用的数组和列表，并且可以不赋值，如果不赋值则表示0个数组数据。

### Protocol Buffer 原理-序列化和反序列化

Protocol Buffer 是怎么识别和存储数据的是理解它序列化和反序列的关键。JSON 和 MessagePack 都使用了字符串Key键值作为映射到程序变量的连接桥梁，用变量的字符串名字去查看对应的Key键值是否存在，这样避免不了因Key键值字符串太多的空间浪费。

Protocol Buffer 则用数字编号来作为Key键值与变量映射的连接桥梁，每个变量都必须有个不重复的标签号(即数字编号)，用Protobuf结构中的变量字段后面跟着的数字编号来映射到数据中的数字编号，进而读取数据。Protocol Buffer为每个结构变量都定义了一个标签号(即数字编号)，这个数字编号就代表了程序变量与指定编号数据的映射关系。

其实有了这个规则还不够，因为程序在读取的时候，是不知道某个变量到底对应哪个标签号的，比如上面的Person的 name 变量，在程序里的 name 变量并不知道到底自己该读取哪个编号的数据的，除非在程序里写死说 name 变量就读取编号为1的数据。Protobuf 就是使用了这种简单粗暴的方法，‘在程序里写死’的这种方式让事情变得更简单。‘在程序里写死’这种粗暴的方式最讲究周边工具了，因为‘在程序里写死’本身是件危险的事，然而如果这个程序是我们通过工具生成的话就会好很多，它相当于我们使用了一些规则并配置了一些数据让生成的程序符合我们的预期并可以随时通过配置来改变它们。Protobuf 的周边工具就为很多种语言定制了生成序列化和反序列化程序代码的工具，我们可以视 .proto 文件为配置文件，Protobuf 根据 .proto 配置文件来生成序列化程序文件。我们只需要通过提供.proto文件就能生成不同语言的程序代码，其代码中的变量的读取与存储编号就是通过周边工具的方式‘写死’在程序中，我们所说的这些代码都是通过周边工具生成的，而我们只需要关心.proto文件中的结构就可以了。

简要总结下，当 Protobuf 生成的用于序列化和反序列化的代码在读数据的时候，通过 .proto 文件中的内容把变量名与数字编号‘写死’绑定在代码中，一旦读取到某个编号的数据时，就把该编号的数据解析给指定变量，例如前面我们提过的Protobuf数据结构案例中，当程序读取到编号为1的数据时，就会把数据写入 name 变量中去，当 name 变量需要写入到数据文件时都是先将编号1这个数字写入进去，而编写这些操作的代码由Protobuf工具完成我们无需担心。

#### AddressBook 数据结构来序列化一个 Protocol Buffer 数据。

我们将数据序列化代码为：

```c#
AddressBook address_book;
Person person = address_book.add_people();
person.set_id(1);
person.set_name("Jack");
person.set_email("Jack@qq.com");
Person.PhoneNumber phone_number = person->add_phones();
phone_number.set_number("123456");
phone_number.set_type(Person.HOME);
phone_number = person.add_phones();
phone_number.set_number("234567");
phone_number.set_type(Person.MOBILE);

person->add_weight_recent_months(50);
person->add_weight_recent_months(52);
person->add_weight_recent_months(54);

//将数据写入数据流中
address_book->WriteStream(stream);
```

上述代码生成出来的二进制数据流如下：

```c#
0a    // (1 << 3) + 2 = 0a，1为people的标签号,2为嵌入结构对应的repeated类型号
3c    // 0x3c = 60，表示接下来60个字节为Person的数据

// 下面进入到 repeated Person 数组的数据结构
0a    // (1 << 3) + 2 = 0a，Person的第一个字段name的标签号为1，2为string(字符串)对应的类型号
04    // name字段的字符串长度为4
4a 61 63 6b    // "Jack" 的ascii编码

10    // (2 << 3) + 0 = 10，字段id的标签号为2，0为int32对应的类型号
01    // id的整型数据为1

1a    // (3 << 3) + 2 = 1a，字段email的标签号为3，2为string对应的类型号
0b    // 0x0b = 11 email字段的字符串长度为11
4a 61 63 6b 40 71 71 2e 63 6f 6d        // "Jack@qq.com"

    //第1个PhoneNumber，嵌套message
    22    // (4 << 3) + 2 = 22，phones字段，标签号为4，2为嵌套结构对应的类型号
    0a    // 0a = 10，接下来10个字节为PhoneNumber的数据
    0a    // (1 << 3) + 2 =  0a, PhoneNumber的number，标签号为1，2为string对应的类型号
    06    // number字段的字符串长度为6
    31 32 33 34 35 36    // "123456"
    10   // (2 << 3) + 0 = 10，PhoneType type字段，0为enum对应的类型号
    01   // HOME，enum被视为整数

    // 第2个PhoneNumber，嵌套message
    22 0a 0a 06 32 33 34 35 36 37 10 00  //信息解读同上，最后的00为MOBILE

a2 06   // 1010 0010 0000 0110 varint方式，weight_recent_months的key
        //  010 0010  000 0110 → 000 0110 0100 010 little-endian存储
        // (100 << 3) + 2 = a2 06，100为weight_recent_months的标签号
        //  2为 packed repeated field的类型号
0c    // 0c = 12，后面12个字节为float的数据，每4个字节一个数据
00 00 48 42 // float 50
00 00 50 42 // float 52
00 00 58 42 // float 54
```

上述二进制数据是一个紧凑的byte数组，我们在剖析时将它拆解开来，这样会更加清晰。第一行的0a由 (1 « 3) + 2 = 0a 生成，其中1为people的标签号,2为嵌入结构对应的repeated类型号。紧跟其后的第二行中3c 表示 0x3c = 60，代表接下来有60个字节大小的数据是 Person 的数据。于是接下来下面进入到 repeated Person 数组的数据结构内容。其遇到的第一个数据 0a 由 (1 « 3) + 2 = 0a 生成而来，1代表Person的第一个字段name的标签号为1，2代表string(字符串)对应的类型号为2。后面的 04 表示为name字段的字符串长度为4，其后紧跟着就是 name 字段字符串的具体数据了，4a 61 63 6b 即为 “Jack” 的ascii编码。后面的数据 10 由 (2 « 3) + 0 = 10 生成而来，其中2代表字段id的标签号为2，0代表int32对应的类型号为2。接着就是int32的数据内容，即 01 表示数据结构中字段变量id的整型数据为1。接下来由是一串email字符串内容，先标志标签号+类型号，再紧跟一个数据大小，再是字符串的具体数据。

再后面就是 PhoneNumber 的数组类型，先是22 表示标签号与类型号， (4 « 3) + 2 = 22，4代表phones字段标签号为4，2代表嵌套结构对应的类型号为2。接着 0a = 10，表示接下来10个字节为PhoneNumber的数据。接着 0a 由 (1 « 3) + 2 = 0a 生成而来，1代表PhoneNumber的number标签号为1，2代表string对应的类型号为2。接着是字符串长度 06 表示number字段的字符串长度为6。接着 31 32 33 34 35 36 为字符串 “123456” 的ascii编码。后面是一个 enum 类型，10 由 (2 « 3) + 0 = 10 生成而来，2代表PhoneType type字段的标签号，0为enum对应的类型号。接着是enum的具体数据，01 表示枚举值HOME，所有的enum被视为整数。第二个PhoneNumber也是同样的数据格式。

最后这些数据为浮点数数组weight_recent_months字段，a2 06 由(100 « 3) + 2 = a2 06 生成而来，100为weight_recent_months的标签号，2为 packed repeated field的类型号。后面的 0c 是 0c = 12的意思，表示后面的12个字节为float的数组数据，每4个字节一个数据。于是接下来三个数据，每个数据4个字节都直接表示浮点数，00 00 48 42 表示float 50，00 00 50 42 表示 float 52，00 00 58 42 表示 float 54。

这个例子来自《Protocol Buffers：阅读一个二进制文件》整个二进制数据分析下来都是遵循了简单的规则，即，标签号 + 类型号，其头部的标识和数据大小标识，作为可选标识放入具体数据，即如下格式：

```
标签号 + 类型号|数据大小|具体数据
```

| 如果具体数据中再嵌套不同种类的数据，也同样遵循 ‘标签号 + 类型号 | 数据大小 | 具体数据’ 这样的规则。 |
| ------------------------------------------------------------ | -------- | ---------------------- |
|                                                              |          |                        |

#### 反序列化的过程。

二进制数据流中反序列化为程序对象数据过程中，标签号与变量的映射关系是由程序‘写死’在代码中的，我们仍然拿上面的protobuf结构来举例，我们重点看看其中 Person 结构的反序列过程：

```c#
public void MergeFrom(pb::CodedInputStream input) {
  uint tag;
  while ((tag = input.ReadTag()) != 0) {
    switch(tag) {
      default:
        _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
        break;
      case 1: {
        name = input.ReadString();
        break;
      }
      case 2: {
        id = input.ReadInt32();
        break;
      }
      case 3: {
        email = input.ReadString();
        break;
      }
      case 4: {
        phones_.AddEntriesFrom(input, _repeated_phones_codec);
        break;
      }
      case 100: {
        
        weight_recent_months_.AddEntriesFrom(input, _repeated_weight_recent_months_codec);
        break;
      }
    }
  }
}
```

上述Protocol Buffer生成的代码我们了解到，所有的对象变量都通过.proto文件中的标签号来识别数据是否与该变量有映射关系，当拿到具体数据时，先用标签号来判定映射到的是哪个变量名，再针对该变量的类型读取数据并赋值。

#### Protocol Buffer 更改数据结构后的兼容问题

在实际的开发中会存在这样一种应用场景，即消息格式因为某些需求的变化而不得不进行必要的修改，但是有些仍然使用原有消息格式的应用程序由于各种原因玩家暂时不能愿意升级客户端程序，这便要求我们在更新消息格式时要遵守一定的规则，从而可以保证基于新老消息格式的新老客户端程序中都能够顺利运行。我们应该注意的规则如下：

1. 不要修改已经存在字段的标签号，即.proto文件中结构消息变量字段后面的编号数字不应该被轻易改变，这保证旧数据协议能够继续从数据中读取指定标签号的正确数据。如果我们更改了标签号，则新老数据不能在新旧客户端中被兼容。
2. 任何新添加的字段必须使用optional和repeated限定符，这保证在旧数据无法加入新数据字段的情况下，新的协议数据还能够在旧数据协议之下顺利解析。如果我们不使用optional或repeated标签则无法保证新老程序在互相传递消息时的消息兼容性。
3. 在原有的消息中，不能移除已经存在的required字段，虽然optional和repeated类型的字段可以被移除，但是他们之前使用的标签号必须被保留，不能被新的字段重用。因为旧协议在执行时还是会在旧的标签号中加入自己的数据，新协议如果使用了旧的标签号，就会导致新旧协议数据解析错误的问题。
4. int32、uint32、int64、uint64和bool等类型之间是兼容的，sint32和sint64是兼容的，string和bytes是兼容的，fixed32和sfixed32，以及fixed64和sfixed64之间是兼容的，这意味着如果想修改原有字段的类型时，为了保证兼容性，只能将其修改为与其原有类型兼容的类型，否则就将打破新老消息格式的兼容性。

#### Protocol Buffer 的优点

Protobuf 全程使用二进制流形式，用整数代替了Key键值来映射变量，比 XML、Json、MessagePack它们更小也更快。

我们可以定义随意的创建自己的.proto文件在里面编写自己的数据结构，然后使用Protobuf代码生成工具生成的protobuf代码，用于读写我们需要序列化和反序列化的protobuf数据结构。我们甚至可以在无需重新部署程序的情况下更新我们的数据结构，只需使用 Protobuf 对数据结构进行一次重新描述，就可利用各种不同语言或从各种不同数据流中对我们的protobuf数据轻松读写。

使用 Protobuf 也无需学习复杂的文档对象模型，因为Protobuf 的编程模式比较友好简单易学，同时它拥有良好的文档和示例，对于喜欢简单易用的工具的人来说，Protobuf 比其他的技术更加有吸引力。

Protobuf 语义也更清晰，无需类似 XML，JSON 解析器的东西，简化了解析的操作，减少了解析的消耗。

Protobuf 数据使用二进制形式，把原来在JSON,XML里用字符串存储的数字换成用byte存储，大量减少了浪费的存储空间。与MessagePack相比，Protobuf减少了Key的存储空间，让原本用字符串来表达Key的方式换成了用整数表达方式，不但减少了存储空间也加快了反序列化的速度。

#### Protocol Buffer 的不足

Protbuf 与 XML、Json类型的数据格式相比也有不足之处，它功能简单无法用来表示复杂的数据概念。XML和Json已经成为多种行业标准的编写工具，明文的表达方式让数据格式显得更加友好，Protobuf 只是运用在数据传输与存储上，在各领域的通用性上还差很多。由于 XML和Json 具有某种程度上的自解释性，它可以被人直接读取和编辑，Protobuf 却不行，它以二进制的方式存储，除非你有 .proto 定义，否则你没法直接读出 Protobuf 的任何内容。

## 网络同步解决方案

### 状态同步法

为什么要状态同步？同步机制主要目的**模拟**，倘若我们每帧(以每秒30帧为标准)都将自己的信息**同步给所有人**，那么需要传输和广播的信息量就太大，因此我们需要尝试**更节省流量的方式**。游戏角色通常可以用**状态形式来代表某一段时间的行为**，因此如果我们使用状态信息作为同步信息广播给其他设备去模拟的话就会比较节省流量，这样当我们收到同步的广播信息后，就可以在一段时间内不需要其他信息就能模拟出这些角色的动作、位移、以及特效。

为了能更逼真的模拟其他玩家的行为，我们把每个人的行为方式抽象成若干个状态，每个状态都有一套行为方式将，有时尽管3D模型不一样但所调用的程序是一样的。比如空闲状态，所有人都会站在某个位置循环播放站立动画，这时我们只要告诉玩家说我在某个位置进入了空闲状态，只要我们的状态不变，其他玩家就可以在不收到任何同步数据的情况下知道我就是一直在原地并循环播放着站立动画。当然这是最简单的状态，我们也可以有其他比较复杂的状态，比如包括攻击状态、追击状态、防御状态、奔跑状态、技能状态、寻路状态等。

在状态同步里，角色身上每个状态就相当于一个具有固定逻辑的行为模式，这个固定行为模式就像个黑盒，只要给到需要的数据，就能表现出相同的行为，比如攻击状态，就会播放一个攻击动画并在某个时间点判定攻击效果，攻击动画完毕后结束攻击状态。比如打坐休息状态，就会循环播放一个打坐动画，并每隔一段时间恢复一次血量。又比如寻路状态，就会从某点到某点做A星的寻路计算，边播放行走动画边跟随路线向各个路线节点移动，最终到达到目地完成寻路状态。最复杂的应该属于技能状态，技能有很多种很多个，每种技能都有不一样的流程，同一种技能还有不通的动画和特效，一些复杂的技能更是需要配备复杂的逻辑，但有一点是可以肯定的也必须做到的，那就是向技能状态输入相同的数据应该展示出相同的表现，例如向技能状态中，输入火球技能ID，目标对象，施法速度，角色在收到数据后就需要展示火球技能的动画，在等待吟唱时间后向目标发射火球。

这些状态都有一个共同的特点就是只要我们给予所需的相同的数据就能展现出相同画面的个体效果。现在我们要让这些状态连贯起来拼凑成一个拥有一系列动作的角色，当我们向这个角色发送各种各样的指令时，就是在告诉它你应该触发这个状态然后触发那状态，由于指令中包含了状态需要的数据，这些数据广播给每个需要看到的玩家，收到这些状态信息的设备就需要通过这些同步数据去模拟角色的行为，从而让画面看起来像是很多玩家在操控自己的角色。

在状态同步中，我们说的通俗点，服务器端扮演了幕后操纵木偶人的那个大老板，而客户端里渲染的对象就是那个木偶人，服务器端发出指令说ID为5的木偶人开始攻击，客户端就执行它的指令，找到那个ID为5的木偶人并开始进入攻击状态的相关逻辑。当动画播放到一半服务器端又发来指令说，被攻击的那个ID的怪兽受伤了并受到500点伤害，这时客户端就会在指定的怪物头上冒出500点的伤害值并且让怪物进入受伤状态播放受伤动画。

现在当攻击动画播放完毕时，服务器又发来指令说继续攻击，客户端又根据这个指令找到ID为5的木偶人将它从站立状态切换到了攻击状态，不过这次攻击状态快结束时服务器发来指令说，这个怪物受到600点伤害并且死了，于是客户端根据这个指令找到这个怪物并在头上冒出600点伤害的数字，然后让怪物进入死亡状态播放死亡动画。木偶人也在播放完攻击动画后，进入了空闲状态循环播放了站立动画。

服务器扮演着发送指令操控木偶人的角色，这个木偶人也包括玩家自己的角色，即当玩家操控’我‘自己的在游戏中的角色时，也同样遵循经过服务器的同意并发送指令给玩家的过程，当玩家收到同步信息指令时当前的角色才会进行状态的切换和模拟。

不过也未必要一定要经过服务器同意才做模拟渲染，为了让玩家能够在网络环境糟糕的时候也能够看起来比较顺畅，我们在制作网络同步逻辑时，让玩家可以随意操控自己的角色，并不受限于服务器的延迟指令，但是在稍后的服务器校验时再对玩家进行矫正，最明显的例子就是我们在玩传奇类游戏中时的状态同步，在网络环境不太顺畅的情况下我们任然能操作自己的角色不停的移动，但在过一段时间后，当客户端接收到服务器发来的正确的数据后，客户端对角色进行了位置和状态的矫正。

状态同步的是根据角色拥有不同的状态，每个状态在某一段时间下的行为可以根据数据被预测，除非状态被改变，否则相同的状态数据得到的是相同的个体状态结果，这样角色实体的行为就可以通过状态切换来模拟表现画面。

### 实时广播同步法

在一些FPS类型的竞技游戏中，**人物的行动速度和旋转速度在不断的变化而且频次比较高**，如果想要模拟不同玩家在游戏场景中的位置与旋转角度就要实时更新这些信息，这时状态同步就不能满足这样需求，由于我们移动的速度和旋转的变化太快频次太高，因此无法做到拆分同步状态来模拟。不过**状态同步依然可以用于除了移动和旋转以外的同步方式**，因为除了移动和旋转，其他信息都没有这样快速、多样的变化，并且角色很多数据仍旧遵守状态的规则，对于这些数据我们可以继续用状态来划分，**因此状态同步常常与实时广播同步同时存在**。

实时广播同步方案的主要**特点**是，**位置和旋转信息由客户端决定**。**客户端将自身的位置、旋转信息发给服务器端，再由服务器端分发给其他玩家，当其他玩家收到位置、旋转信息后根据收到的位置和旋转信息预测其当前的位置、速度、加速度，以及旋转速度，旋转加速度并进行模拟和展示**。

在这种竞技性比较强，移动速度比较快的游戏中，通常都需要玩家不停的改变移动速度和旋转角度来体现其控制角色的灵活性。比较常见为枪战类游戏CS，玩家不停在变化自己的位移速度和旋转角速度以适应战斗的需要。除了FPS类型的游戏，赛车类游戏也是类似的情况，在跑跑卡丁车游戏中，玩家要在高速移动下，不停的调整自己的方向和速度，让自己能够躲过众多障碍，同时在急弯处要旋转自己的车进行漂移等。魔兽世界也会使用实时广播同步法，这种开放世界下的RPG游戏，需要不停的改变自己的速度与旋转角度来让战斗显得更加丰富和灵活，不过魔兽世界在实时广播之上加了些验证机制让客户端不能为所欲为的决定自己的位置。

**为了能更加逼真的同步模拟这种变化频率很高的人物移动和旋转，我们不得不让客户端来决定其位置和旋转角度，这将牺牲一些数据的安全性来让画面模拟的更加真实流畅。**

**每个玩家设备上的客户端会在1秒内向服务端发送15-30次左右自身的移动和旋转数据**，为的就是让其他玩家在收到广播数据时能更加顺畅的模拟玩家在游戏中的移动旋转的表现，也只有这样才能让其他的游戏客户端不停的更新玩家的位置、移动速度和旋转角度。**不过只是单纯的更新位置和旋转数据，会导致玩家在屏幕中不停的闪跳，因此我们用速度的方式表示它们的移动方式会让角色模拟运动得流畅些。** **当我们收到广播的玩家实时数据时，先计算速度和预测速度，以及加速度，让模拟的对象按速度和加速度的形式在屏幕中运动，而不是只更新位置，这让角色在画面中模拟行走的位置和方向时更加流畅。**

**实时广播同步的算法和公式**

1. 首先要取得已经收到的该玩家的位置信息前5个除以间隔时间，就能得到一个平均的速度

2. 再取这样5个一组的3-5组，就能得到一个平均的加速度，根据这个速度和加速，就能让角色在屏幕中模拟出相对准确的跑动位置、速度和方向。
3. 不只是速度和加速度，我们还需要角色当前的面向的角度，以及旋转的角速度，在角度的同步上也可以按照这种速度和加速度的方式去预测，取最近5个角度的值得到平均旋转速度，再取5个一组的3-5组这样的数据计算得到旋转加速度。

虽然我们用前面的数据计算当前的位置、速度、加速度、旋转角度、旋转角速度，但还是**会有偏差**，由于网络延迟大且不稳定的关系，很容易造成位移的偏差，所以我们依然需要**定时的矫正**。矫正会比较生硬，比如由于网络宽带关系，我们很久没有收到实时广播数据了，一下子收到了很多广播数据，这时由于位置相差太远就会一下子将角色置于最后定位的位置，这种看起来矫正会比较生硬。我们可以在生硬的基础上加入一些当前数据的预测，让矫正不是直接飞到那个位置而是加速移动过去，速度取决于延迟的时间大小。这也正是为什么我们在玩CF穿越火线，跑跑卡丁车这类游戏时，假如对方的网络比较卡，就会看到对方角色不停的一闪而过，因为预测数据和矫正数据偏离的太多了，客户端在不断的矫正角色的位置和速度。

### 帧同步

状态同步既能控制数据计算的安全性，也能保证所有客户端的同步性，不过在位置和角度变化很快的竞技游戏中，状态同步无法承受这样又多又快的位置和旋转变化，所以就加入了实时广播同步的解决方案。**实时广播同步解决方案放弃了玩家的位置和旋转角度的强校验**，使得各个客户端能更加顺利和准确的模拟其他玩家的位置和旋转角度。

更加严格的同步要求既能做到移动与旋转的准确定位也同时能同步角色状态还能有比较强的同步校验，这时实时广播同步已不能满足需求，实时广播同步解决方案虽然能预测模拟玩家的位置与速度，但不能做到强校验，无法保证数据的正确性就容易被专空子作弊。由于每个玩家的手机和电脑端的设备好坏都不一样，网络环境也不同，一台好的机子和手机，在同一时间段能位移的距离可能也不一样，在差异性巨大的设备和网络通信之间做到精准的同步比较困难，前面我们说的状态同步是基于状态可拆分的模式，把角色分为几种状态，每个状态都做自己的事，当玩家改变状态时发送数据给周围的人让他们各自去模拟改变后的状态信息，但是状态同步的问题是当我们需要频次高且精确的同步时它就无能为力了。

**帧同步解决方案就很好的解决了状态同步和实时广播同步解决不了的问题。**

在同步性和安全性要求很高的游戏中，例如王者荣耀，拳皇类格斗游戏，游戏中的每一帧都是非常关键的，一两帧的计算就有可能决定双方的胜负，所以不能有分毫之差，对于这种类型的游戏，同步的要求特别高而且精确计算的要求也很高，帧同步的解决方案正好契合这种类型游戏。

与状态同步和实时广播同步法不同的是，帧同步的逻辑不再由客户端本身的逻辑帧Update来决定，而是转由从网络收到帧数据包来驱动执行逻辑更新，这也是帧同步最大的特点。**其所有逻辑更新都放在了收到帧数据包时的操作中**，包括人物角色的移动，攻击，释放技能等，每收到一个服务器发过来的帧数据包，就会更新一帧或更新前面因延迟累积的帧数。

**帧同步的服务器需要向每个客户端每秒发送15-30个帧数据包**，每隔0.033-0.05秒发送一个，**即使没有任何信息也会发送空的帧数据**，因为**客户端要根据这些帧数据包来‘演算’游戏逻辑**。因此帧数据的集合被认为是一条时间线，平时我们用秒来计算时间，现在我们帧来代替，例如某个动作做5帧而不是5秒，这颗子弹向前滑行10帧而不是XX秒，其实质是用整数的方式来计量时间线上的位置而不再使用浮点数因为这样更准确。

为什么要说‘演算’呢，**一个比较容易理解的比喻是原来在客户端的Update里角色每帧移动xx米的逻辑，转移到了从网络收到的帧数据包的时刻，每收到一个帧数据包角色就调用一次移动逻辑(**当然不只是移动逻辑，也不只会收到一个帧数据包，确切的说应该是更新逻辑)，这样使得不同的游戏设备在拥有不同的帧率的情况下，执行相同数量的逻辑帧的同时也执行了相同次数的逻辑指令。指令存储在帧数据里，不同设备收到的帧数据一致，执行顺序一致，执行结果也将一致(这里有精度问题导致结果不一样将在本节后面讨论)。

**帧数据中主要存储的就是指令以及指令相关的参数**，一个帧数据可能有很多个指令分别指向不同的角色。**当玩家通过屏幕或摇杆操作时将操作指令发给服务器**，**服务器在随后广播的帧数据中带就有我们上传的指令数据，除了有指令数据外的帧数据，其他没有任何指令的帧数据其内容是空的，空帧也需要被传达到每个客户端，因为这关系到逻辑的更新。**

我们客户端的执行步骤为，随着客户端不断收到从服务器端广播的帧数据，每帧都执行一次更新逻辑，执行到某一帧其带有指令数据就执行该帧内的所有指令，同时也更新逻辑。比如帧数据中指令为某角色以每帧1米速度向前移动，那么客户端就开始启动移动状态执行该指令，在接下来收到的帧数据中客户端每每执行逻辑更新都会执行每帧1米的逻辑，比如后面总共收到20帧的网络空数据帧，那么就执行了20次每帧1米的行走逻辑，直到玩家再次操作停止了移动指令，并把该指令发送给服务器端，服务器端再以帧数据的形式广播给所有玩家，任何玩家设备收到这个带有停止指令的帧数据时执行停止指令停止了移动。

上述描述的客户端执行帧数据的逻辑步骤中，会有渲染与逻辑的差异。其原因是渲染时我们通常会一直在10-60帧范围内变化，而帧数据的频率则是固定的每秒15帧，这导致了帧数据的逻辑计算和渲染的差异。

假如我们移动中帧数据在逻辑更新时不断的计算当前的位置以此来作为渲染帧中位置的依据，则我们将看到角色在一跳一跳一顿一顿的逐级向前’跳动‘。**为了能更加平滑的模拟帧数据中的移动内容，我们在渲染时也要进行预测和模拟**。移动时我们知道每个数据帧中角色的位置，一帧代表多少秒，这样至少2个帧数据就能知道当前的速度，至少3个帧数据就预测加速度，这和我们前面介绍的实时广播同步在模拟角色速度与位移时的方法一样，用最近3-5个点位数据来预测当前的速度和加速度以及旋转角度和角速度。当网络原因帧数据延迟的很厉害时，我们就应该能从收发的数据中得知网络有较大的延迟，例如距离最近一个帧数据收到已经是5秒前的时间了，那么我们就知道网络造成了严重的堵塞，现在的预测和模拟已经不再准确了应该停止才对，等待帧数据的到来再重新矫正位置和速度。

现在的逻辑运算在网络收发的数据帧中执行，这就相当于服务器控制了所有玩家设备上的播放帧的速率和帧数长度，让所有玩家拥有相同的帧数据，执行相同的指令数量以及相同的指令顺序，由于执行逻辑的时间点(我们前面说过时间已经不再被用秒计算了而是用帧的数量计算)，执行的逻辑的次序和次数相同，从而使得所有收到帧数据的客户端做出的表现也是相同，这就是帧同步的最大特点。它由服务器发送的帧数据来完成所有客户端的同步执行操作，在每个客户端设备中所使用来‘演算’的算法一致，最终在所有设备中执行的结果一致，反应到屏幕画面上表现的出来的行为也是一致的。

### 同步快进

现实中网络环境不太稳定特别是手机设备，不是所有客户端的网络都是流畅的，通常的网络环境都是时好时坏的，客户端在接收帧数据时经常都是波动的，时而会有一堆帧数据涌过来，或者又忽然完全收不到了帧数据，时常会有在两个极端之间的状况。因此如何预测和模拟延迟部分的表现，以及**快速同步落后的很多帧的客户端画面成了客户端解决同步问题的关键**。

当网络造成延迟，帧数据一下子收到很多，为了能同步帧数据的逻辑，我们可以使用最简单的方式，**瞬间执行全部堆积在队列里的帧数据**，这样我们一下子就能到达逻辑数据中的最后一帧，接着继续正常接收和模拟画面。但是这样一次性执行所有的很多帧数据的方式会有问题，**如果堆积的数据帧太多，会导致因执行逻辑更新太多而让游戏卡住很久**，画面会因此停止不动一段时间，游戏体验会比较差。**解决这个问题我们可以在执行帧逻辑时每次执行N帧(N大于10)来使画面快速推进**，这样一来玩家又能看到动态的画面，又能快速的跟上最后的同步帧数据，同步完所有的帧数据后，再把执行速度恢复到正常，从而继续接收数据帧来做正常的同步工作。

如果落后的太多太多，比如我们掉线后重连时相当于落后了整个数据帧，如果是一场20分钟的比赛相当于落后了20*60*15=18000帧，这时快进的方法也不管用了，因为执行的帧数落后太多导致按普通快进的节奏得要快进很久才能跟上大部队，如果快进的速度太快则执行的帧数上升也会导致画面卡顿感太重。无论如何执行全部的帧逻辑消耗的CPU太多时间过久，如果是手机设备有可能会因消耗过大而发热发烫。

这时我们可以用内存快照的方式做快进操作，快照在很多领域都有这样的概念，特别是硬盘快照，就是将硬盘里的数据全部复制一份作为备份，当下次要构建一个一模一样的新机器时就不用这么费力了，直接从快照中复制一份就可以完成装机工作。内存快照也是同样的理念，只是与硬盘快照不同的是内存快照做的内存备份，意思是把内存中关于战斗的所有数据包括玩家，怪物，可破坏的障碍等等都备份一份在文件上存储在本地或服务器中，当客户端需要所有帧数据时其实需要的是最后一帧数据计算后的内存数据，这时客户端就可以直接使用该快照数据获得内存数据的结果，以此为依据渲染画面。由于这一帧的快照离最后需要同步的帧数最近，中间可能跨越了几千或上万的帧数，从该帧数据开始快进到最近的数据帧，相对于从头开始快进来说要快了许多也节省了许多CPU的消耗。

上面讲的都是模拟帧数据的画面表现，我们在发送操作指令时也需要注意一些问题，如果发送的指令过于频繁也会造成网络数据的灾难，比如玩家控制角色不断释放技能或者不停的旋转奔跑，就会让客户端以渲染帧的速度每帧大量的向服务器发送指令数据像机关枪一样扫射式的发射，这种方式就会造成帧数据混乱，一帧数据中当前玩家的指令应该最多只有1个，每个玩家的指令在1个帧的数据中只能有一个，只有这样才能不造成逻辑的混乱。

为了在不让发送过多的指令混乱帧数据，我们可以选择把需要发送的指令存起来，等到收到一个从服务端来的网络帧数据时再发送，如果有很多指令则不断替换未发送的指令直到收到网络帧数据才发送最后一个替换的指令。这也符合多端帧同步的规则，其实是我们规定了每帧只能有一个操作，因为我们需要遵循’不能在同一帧有多个操作’的规则。这个规则确保了我们在逻辑计算时不能在同一帧中既前进又后退，也不能在同一帧中既释放技能又取消技能，确保了游戏逻辑的简单化。

在实际操作中摇杆的在旋转和位移的变化以及技能的释放这些操作在用户端是非常快的，如果客户端等到有网路数据帧接收到时再发送当前的指令，那么用户操作的指令会被自己的指令覆盖好几次。实际确实是这样，很多手速非常快的玩家受到了网络数据帧频率的限制，为了解决这个问题很多游戏会提前模拟玩家的操作，客户端模拟玩家可以根据自己的操作自由行走甚至攻击或释放技能，而后再由网络接收到的数据来矫正位置与角度，或者先把指令序列存储起来，等到网络帧来的时候再将指令序列发送出去，这样的话可能是另一种网络延迟体验。

### 精度问题

帧同步的核心战斗的计算逻辑放在了玩家各自设备的客户端中进行，我们前面说了由于所有设备执行的帧数一致，执行的指令和时间点一致，执行的算法一致，就能得出相同的结果。理论上确实是这样，但是这里会出现一个问题，由于不同设备上的浮点数精度损失结果不同，导致同样的浮点数公式在不同设备上计算出来的结果有细微的差别，经过多次并长时间的计算后这种误差会扩大到不可接受的地步。

浮点数在各不同设备上的计算结果有细微的差异，随着计算量的增多差异会变得越来越大，即使我们逻辑业务的执行次数、时间、算法都一致，最终计算出来的结果还是会由于浮点数计算结果不同而不同。因此浮点数的精确计算也是帧同步在各设备同步问题上的一大关键，其根源是因为帧同步方案把计算过程交给不同设备而导致的问题。

其实也并不是什么难题，我们有很多用浮点数精度问题的解决方案，定点数就是其中之一。所谓定点数，就是把整数和小数部分分开存储，小数部分用整数来计算，整数部分继续用整数，这样计算起来就不会有误差了。

通常的浮点数在计算机中的表示法为 V = (-1)^s x (1.x) x 2^(E-f) 也就是说浮点数的表达其实是模糊的，它用了一个数的指数来表示当前的数。而定点数则不同，它把整数部分和小数部分拆分开来并都用整数的形式表示，这样计算和表达可以用整数的方式。整数的计算是确定的没有误差的，这样就不会存在不同设备上的误差，缺点是变量占用的内存空间多了一倍，计算的量也多了一倍，同时计算范围缩小了。

用定点数来替换浮点数计算就能保证在各设备上的计算结果一致性，C#自带的decimal类型就是定点数，它在金融和会计领域的使用比较多，在游戏项目中使用的多，因为也并不顺手，比如无法和浮点数随意的互相转换，在计算前也依然需要进行封装，又比如无法控制末尾小数点，使得精度还是无法根据项目需求来控制，同时它占用128位数据来存储，游戏中很少需要这么多的位数，这会大量增加内存的负担。

因此大部分项目都会自己去实现定点数的重新封装，把整数和小数拆开来都用32位整数表示封装在某个类中，再写一些关于定点数之间以及定点数与其他类型数字的数学计算库。数学库内的函数没有我们想象的那么多，其实就是把定点数与其他类型数字的加减乘除重写一下，如果涉及到更多的图形学运算的，则加入一些图形学的基本运算公式，比如线段交叉、点积、叉乘等，参数用我们封装的定点数代替。

最最最快速简单，性价比最高的的方式，其实是将所有浮点数改为整数并乘以1000或者10000表达完整的数，以整数的方式来计算结果就不会有问题。把所有需要计算的数字都以这种方式存储，只有在需要在UI界面上展示小数点的时候才除回来变成浮点数再进行展示，但也仅仅是展示的用途不涉及逻辑运算。这样即控制了精度的一致性，也不用这么麻烦去实现定点数的封装。只是这样做，原本能表达的精度范围就减少了，整数部分缩小到了2000万或200万以内，小数部分只保留了3位或4位小数点精度，不过仍然能在部分游戏中使用，因为在很多帧同步游戏中，200万的数字都已经是足够大了，所以有时他们无需劳心费神的去封装一个定点数以及定点数数学库，而且封装后还难以与表现层有很好的过渡。直接乘一下就能达到一样的效果，大大降低了研发成本。不过两者各有优势利弊，不一定说哪种方式一定好或者坏，按照项目的需求做不同的决策是应该的也是必要的。

我们这里也了解下同步锁的机制。在更加严格的同步类游戏中，比如星际争霸1中，如果有玩家网络环境不好，希望能够等待该玩家的进度，就会使用同步锁的机制。同步锁的机制，要求每个客户端每隔一段时间都发送一个锁帧数据，类似‘心跳’数据包，服务器端在帧数据中嵌入心跳包，用这样的方式告诉其他玩家该玩家仍然在线并正常游戏中，如果客户端在接受帧数据时超过50帧没有收到某个玩家的锁帧数据的话则停止播放网络帧数据，等待该玩家跟上大部队后，再所有客户端同时从最近的一次锁帧数据点开始，以该点为最后一数据帧，一起继续各自演算。